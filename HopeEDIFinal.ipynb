{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zu5ZtPEjvq1n",
        "outputId": "9332ed4e-c700-4f5f-ef1f-56c2121cc6c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8POSCiHv1km",
        "outputId": "4d0aa23b-0b6e-4499-efc2-2d79b35bf992"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Feb  3 19:16:15 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuFTPaHX2qtt"
      },
      "outputs": [],
      "source": [
        "# Importing the libraries needed\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import seaborn as sns\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VVtKwqiv3PP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "train=pd.read_csv('/content/drive/MyDrive/HopeCodalab/Hope_ENG_train.csv',names=['text','label'])\n",
        "test=pd.read_csv('/content/drive/MyDrive/HopeCodalab/Hope_ENG_dev.csv',names=['text','label'])\n",
        "eval=pd.read_csv('/content/drive/MyDrive/HopeCodalab/Hope_ENG_test.csv',names=['text'])\n",
        "neweval=pd.read_csv('/content/drive/MyDrive/HopeCodalab/newTest.csv',names=['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "L8zr6jLkUYBC",
        "outputId": "bade2b9e-3436-4c38-d21f-a01b2e90bcc5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-756ec671-e426-46cd-89de-da262904e55c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>these tiktoks radiate gay chaotic energy and i...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@Champions Again He got killed for using false...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It's not that all lives don't matter</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Is it really that difficult to understand? Bla...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Whenever we say black isn't that racists?  Why...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22735</th>\n",
              "      <td>It's a load of bollocks every life matters sim...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22736</th>\n",
              "      <td>no say it because all lives matter! deku would...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22737</th>\n",
              "      <td>God says her life matters</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22738</th>\n",
              "      <td>This video is just shit. A bunch of whiny ass ...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22739</th>\n",
              "      <td>Mc Fortnut2821 she did 4 months ago in west ch...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>22740 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-756ec671-e426-46cd-89de-da262904e55c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-756ec671-e426-46cd-89de-da262904e55c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-756ec671-e426-46cd-89de-da262904e55c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                    text            label\n",
              "0      these tiktoks radiate gay chaotic energy and i...  Non_hope_speech\n",
              "1      @Champions Again He got killed for using false...  Non_hope_speech\n",
              "2                   It's not that all lives don't matter  Non_hope_speech\n",
              "3      Is it really that difficult to understand? Bla...  Non_hope_speech\n",
              "4      Whenever we say black isn't that racists?  Why...  Non_hope_speech\n",
              "...                                                  ...              ...\n",
              "22735  It's a load of bollocks every life matters sim...  Non_hope_speech\n",
              "22736  no say it because all lives matter! deku would...  Non_hope_speech\n",
              "22737                          God says her life matters  Non_hope_speech\n",
              "22738  This video is just shit. A bunch of whiny ass ...  Non_hope_speech\n",
              "22739  Mc Fortnut2821 she did 4 months ago in west ch...  Non_hope_speech\n",
              "\n",
              "[22740 rows x 2 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bMo0UAvw_4J"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def simple_text_clean(x):\n",
        "    # first we lowercase everything\n",
        "    x = x.lower()\n",
        "    # remove unicode characters\n",
        "    x = x.encode('ascii', 'ignore').decode()\n",
        "    #remove websites\n",
        "    x = re.sub(r'[\\S]+\\.(net|com|org|info|edu|gov|uk|de|ca|jp|fr|au|us|ru|ch|it|nel|se|no|es|mil)[\\S]*\\s?','',x)\n",
        "    x = re.sub(r'[^a-zA-z.,!?/;\\\"\\'\\s]','',x)#removes special characters except some & remove nums 0-9\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_xYN2rM1acB"
      },
      "outputs": [],
      "source": [
        "def changelabel_cleantext(temp):\n",
        "  temp2=temp.label\n",
        "  res=pd.DataFrame(temp2)\n",
        "  for i in res:\n",
        "      res.loc[res[str(f'{i}')]== 'Non_hope_speech', str(f'{i}')] = 0\n",
        "      res.loc[res[str(f'{i}')]== 'Hope_speech', str(f'{i}')] = 1\n",
        "      res[str(f'{i}')]=res[str(f'{i}')].astype(str).astype(int)\n",
        "  temp['text']=temp['text'].apply(str).apply(lambda x: simple_text_clean(x))\n",
        "  newdf=pd.concat([temp['text'],res],axis=1)\n",
        "  return newdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVCMQeaK1dEK"
      },
      "outputs": [],
      "source": [
        "train=changelabel_cleantext(train)\n",
        "test=changelabel_cleantext(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZa5q-e61hWa",
        "outputId": "c8964ffb-625c-48c8-ed26-dc13099fd813"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.16.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "from transformers import RobertaModel, RobertaTokenizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-large', truncation=True, do_lower_case=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qw43JRUi1v3_"
      },
      "outputs": [],
      "source": [
        "# import statistics as st\n",
        "# max_len = 0\n",
        "# lens=[]\n",
        "# sentences=train.text\n",
        "\n",
        "# # For every sentence...\n",
        "# for sent in sentences:\n",
        "\n",
        "#     # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "#     input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "#     lens.append(len(input_ids))\n",
        "#     # Update the maximum sentence length.\n",
        "#     max_len = max(max_len, len(input_ids))\n",
        "\n",
        "# print('Max sentence length: ', max_len)\n",
        "# print('Max sentence length: ', st.mean(lens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azD0cObP2Xiq"
      },
      "outputs": [],
      "source": [
        "class RobertaData(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.text = self.data.text\n",
        "        self.targets = self.data.label\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.text[index])\n",
        "        text = \" \".join(text.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYnhmBby21QU"
      },
      "outputs": [],
      "source": [
        "training_set = RobertaData(train, tokenizer, 22)\n",
        "testing_set = RobertaData(test, tokenizer, 22)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POKUlWuN3oy3"
      },
      "outputs": [],
      "source": [
        "train_params = {'batch_size': 16,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': 16,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrlAbcc34zRo",
        "outputId": "25992351-c50a-4667-d809-ea1303eec19b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "robertamodel = RobertaModel.from_pretrained('roberta-large',output_hidden_states=True)\n",
        "# for p in robertamodel.parameters():\n",
        "#     p.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDtEnlQn302J"
      },
      "outputs": [],
      "source": [
        "class RobertaClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RobertaClass, self).__init__()\n",
        "        self.l1 = robertamodel\n",
        "        self.pre_classifier = torch.nn.Linear(1024, 1024)\n",
        "        self.bn=torch.nn.LayerNorm(1024)\n",
        "        self.dropout = torch.nn.Dropout(0.1)\n",
        "        self.classifier = torch.nn.Linear(1024, 1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        hidden_state = output_1[0]\n",
        "        pooler = hidden_state[:, 0]\n",
        "        pooler = self.pre_classifier(pooler)\n",
        "        bnorm = self.bn(pooler)\n",
        "        # pooler = torch.nn.ReLU()(pooler)\n",
        "        tanlayer =  torch.nn.Tanh()(bnorm)\n",
        "        tanlayer = self.dropout(tanlayer)\n",
        "        output = self.classifier(tanlayer)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzSg2KeY36D3",
        "outputId": "61e51d44-e864-4e32-e0d6-b32e37c7dfce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RobertaClass(\n",
              "  (l1): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (12): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (13): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (14): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (15): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (16): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (17): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (18): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (19): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (20): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (21): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (22): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (23): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): RobertaPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "  (bn): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=1024, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "model = RobertaClass()\n",
        "model.to(device)\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpQ4j3-C4DSS"
      },
      "outputs": [],
      "source": [
        "# # Creating the loss function and optimizer\n",
        "# criterion = torch.nn.BCEWithLogitsLoss()\n",
        "# optimizer = torch.optim.Adam(params =  model.parameters(), lr=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-7pVT2Q5LNb"
      },
      "outputs": [],
      "source": [
        "def calcuate_accuracy(preds, targets):\n",
        "    n_correct = (preds==targets).sum().item()\n",
        "    return n_correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAm94kjuC53N"
      },
      "outputs": [],
      "source": [
        "import tqdm as tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-13ZliubFc_R"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXpXR3XzFmdd"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm, trange"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrtU6dcC_WOn",
        "outputId": "653fcff7-7002-452f-b380-ccfa84e532cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: madgrad in /usr/local/lib/python3.7/dist-packages (1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install madgrad\n",
        "from madgrad import MADGRAD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DUVu-cdFJ8o"
      },
      "outputs": [],
      "source": [
        "def evaluate(model,a, tokenizer, criterion, dataloader, tres = 0.5): \n",
        "    \n",
        "    # Eval!\n",
        "    eval_loss = 0.0\n",
        "    nb_eval_steps = 0\n",
        "    preds = None\n",
        "    proba = None\n",
        "    out_label_ids = None\n",
        "    for batch in a(dataloader):\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            ids = batch['ids'].to(device, dtype = torch.long)\n",
        "            mask = batch['mask'].to(device, dtype = torch.long)\n",
        "            token_type_ids = batch['token_type_ids'].to(device, dtype = torch.long)\n",
        "            targets = batch['targets']\n",
        "            targets=targets.view(targets.size(0),-1)\n",
        "            labels=targets.to(device, dtype = torch.float32)\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "            logits = outputs  # model outputs are always tuple in transformers (see doc)\n",
        "            tmp_eval_loss = criterion(logits, labels) \n",
        "            eval_loss += tmp_eval_loss.mean().item()\n",
        "        nb_eval_steps += 1\n",
        "        if preds is None:\n",
        "            preds = torch.sigmoid(logits).detach().cpu().numpy() > tres\n",
        "            proba = torch.sigmoid(logits).detach().cpu().numpy()\n",
        "            out_label_ids = labels.detach().cpu().numpy()\n",
        "        else:            \n",
        "            preds = np.append(preds, torch.sigmoid(logits).detach().cpu().numpy() > tres, axis=0)\n",
        "            proba = np.append(proba, torch.sigmoid(logits).detach().cpu().numpy(), axis=0)\n",
        "            out_label_ids = np.append(out_label_ids, labels.detach().cpu().numpy(), axis=0)\n",
        "    \n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "\n",
        "    result = {\n",
        "        \"loss\": eval_loss,\n",
        "        \"accuracy\": accuracy_score(out_label_ids, preds),\n",
        "        \"AUC\": roc_auc_score(out_label_ids, proba),\n",
        "        \"micro_f1\": f1_score(out_label_ids, preds, average=\"micro\"),\n",
        "        \"prediction\": preds,\n",
        "        \"labels\": out_label_ids,\n",
        "        \"proba\": proba\n",
        "    }\n",
        "    \n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kb4Q4NEGe8u"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(save_path, model, valid_loss):\n",
        "\n",
        "    if save_path == None:\n",
        "        return\n",
        "    \n",
        "    state_dict = {'model_state_dict': model.state_dict(),\n",
        "                  'valid_loss': valid_loss}\n",
        "    \n",
        "    torch.save(state_dict, save_path)\n",
        "    print(f'Model saved to ==> {save_path}')\n",
        "    \n",
        "def load_checkpoint(load_path, model):\n",
        "    \n",
        "    if load_path==None:\n",
        "        return\n",
        "    \n",
        "    state_dict = torch.load(load_path, map_location=device)\n",
        "    print(f'Model loaded from <== {load_path}')\n",
        "    \n",
        "    model.load_state_dict(state_dict['model_state_dict'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9aEUBcG_ljd"
      },
      "outputs": [],
      "source": [
        "num_labels = 1\n",
        "gradient_accumulation_steps = 20\n",
        "max_seq_length = 22\n",
        "max_grad_norm = 0.5\n",
        "train_batch_size = 16\n",
        "eval_batch_size = 16\n",
        "num_train_epochs = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BluVMZ4A_nW4"
      },
      "outputs": [],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch import nn\n",
        "# Prepare optimizer and schedule (linear warmup and decay)\n",
        "no_decay = [\"bias\", \n",
        "            \"LayerNorm.weight\"\n",
        "           ]\n",
        "weight_decay = 0.0005\n",
        "\n",
        "optimizer_grouped_parameters = [\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": weight_decay,\n",
        "        },\n",
        "        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
        "    ]\n",
        "\n",
        "t_total = (len(training_loader) // gradient_accumulation_steps) * num_train_epochs\n",
        "warmup_steps = t_total // 10\n",
        "\n",
        "optimizer = MADGRAD(optimizer_grouped_parameters, lr=2e-4)\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, warmup_steps, t_total\n",
        "    )\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JZs9m4Q5YWq",
        "outputId": "7f727ccd-5ad2-4e16-bc25-b2b785f321ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 from 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1422 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            " 14%|█▍        | 202/1422 [00:31<03:16,  6.21it/s]\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 2/178 [00:00<00:09, 18.02it/s]\u001b[A\n",
            "  2%|▏         | 4/178 [00:00<00:09, 18.13it/s]\u001b[A\n",
            "  3%|▎         | 6/178 [00:00<00:09, 18.02it/s]\u001b[A\n",
            "  4%|▍         | 8/178 [00:00<00:09, 18.04it/s]\u001b[A\n",
            "  6%|▌         | 10/178 [00:00<00:09, 18.01it/s]\u001b[A\n",
            "  7%|▋         | 12/178 [00:00<00:09, 17.96it/s]\u001b[A\n",
            "  8%|▊         | 14/178 [00:00<00:09, 18.01it/s]\u001b[A\n",
            "  9%|▉         | 16/178 [00:00<00:08, 18.05it/s]\u001b[A\n",
            " 10%|█         | 18/178 [00:01<00:08, 17.97it/s]\u001b[A\n",
            " 11%|█         | 20/178 [00:01<00:08, 18.07it/s]\u001b[A\n",
            " 12%|█▏        | 22/178 [00:01<00:08, 18.10it/s]\u001b[A\n",
            " 13%|█▎        | 24/178 [00:01<00:08, 18.21it/s]\u001b[A\n",
            " 15%|█▍        | 26/178 [00:01<00:08, 18.08it/s]\u001b[A\n",
            " 16%|█▌        | 28/178 [00:01<00:08, 18.13it/s]\u001b[A\n",
            " 17%|█▋        | 30/178 [00:01<00:08, 18.21it/s]\u001b[A\n",
            " 18%|█▊        | 32/178 [00:01<00:08, 18.25it/s]\u001b[A\n",
            " 19%|█▉        | 34/178 [00:01<00:07, 18.25it/s]\u001b[A\n",
            " 20%|██        | 36/178 [00:01<00:07, 18.15it/s]\u001b[A\n",
            " 21%|██▏       | 38/178 [00:02<00:07, 18.10it/s]\u001b[A\n",
            " 22%|██▏       | 40/178 [00:02<00:07, 18.02it/s]\u001b[A\n",
            " 24%|██▎       | 42/178 [00:02<00:07, 18.00it/s]\u001b[A\n",
            " 25%|██▍       | 44/178 [00:02<00:07, 18.10it/s]\u001b[A\n",
            " 26%|██▌       | 46/178 [00:02<00:07, 18.19it/s]\u001b[A\n",
            " 27%|██▋       | 48/178 [00:02<00:07, 18.24it/s]\u001b[A\n",
            " 28%|██▊       | 50/178 [00:02<00:06, 18.30it/s]\u001b[A\n",
            " 29%|██▉       | 52/178 [00:02<00:06, 18.33it/s]\u001b[A\n",
            " 30%|███       | 54/178 [00:02<00:06, 18.31it/s]\u001b[A\n",
            " 31%|███▏      | 56/178 [00:03<00:06, 18.31it/s]\u001b[A\n",
            " 33%|███▎      | 58/178 [00:03<00:06, 18.29it/s]\u001b[A\n",
            " 34%|███▎      | 60/178 [00:03<00:06, 18.30it/s]\u001b[A\n",
            " 35%|███▍      | 62/178 [00:03<00:06, 18.21it/s]\u001b[A\n",
            " 36%|███▌      | 64/178 [00:03<00:06, 18.22it/s]\u001b[A\n",
            " 37%|███▋      | 66/178 [00:03<00:06, 18.20it/s]\u001b[A\n",
            " 38%|███▊      | 68/178 [00:03<00:06, 18.27it/s]\u001b[A\n",
            " 39%|███▉      | 70/178 [00:03<00:05, 18.23it/s]\u001b[A\n",
            " 40%|████      | 72/178 [00:03<00:05, 18.23it/s]\u001b[A\n",
            " 42%|████▏     | 74/178 [00:04<00:05, 18.26it/s]\u001b[A\n",
            " 43%|████▎     | 76/178 [00:04<00:05, 18.10it/s]\u001b[A\n",
            " 44%|████▍     | 78/178 [00:04<00:05, 18.12it/s]\u001b[A\n",
            " 45%|████▍     | 80/178 [00:04<00:05, 18.01it/s]\u001b[A\n",
            " 46%|████▌     | 82/178 [00:04<00:05, 17.82it/s]\u001b[A\n",
            " 47%|████▋     | 84/178 [00:04<00:05, 17.91it/s]\u001b[A\n",
            " 48%|████▊     | 86/178 [00:04<00:05, 18.08it/s]\u001b[A\n",
            " 49%|████▉     | 88/178 [00:04<00:04, 18.08it/s]\u001b[A\n",
            " 51%|█████     | 90/178 [00:04<00:04, 18.09it/s]\u001b[A\n",
            " 52%|█████▏    | 92/178 [00:05<00:04, 18.11it/s]\u001b[A\n",
            " 53%|█████▎    | 94/178 [00:05<00:04, 18.12it/s]\u001b[A\n",
            " 54%|█████▍    | 96/178 [00:05<00:04, 18.22it/s]\u001b[A\n",
            " 55%|█████▌    | 98/178 [00:05<00:04, 18.31it/s]\u001b[A\n",
            " 56%|█████▌    | 100/178 [00:05<00:04, 18.35it/s]\u001b[A\n",
            " 57%|█████▋    | 102/178 [00:05<00:04, 18.27it/s]\u001b[A\n",
            " 58%|█████▊    | 104/178 [00:05<00:04, 18.40it/s]\u001b[A\n",
            " 60%|█████▉    | 106/178 [00:05<00:03, 18.51it/s]\u001b[A\n",
            " 61%|██████    | 108/178 [00:05<00:03, 18.51it/s]\u001b[A\n",
            " 62%|██████▏   | 110/178 [00:06<00:03, 18.45it/s]\u001b[A\n",
            " 63%|██████▎   | 112/178 [00:06<00:03, 18.20it/s]\u001b[A\n",
            " 64%|██████▍   | 114/178 [00:06<00:03, 18.31it/s]\u001b[A\n",
            " 65%|██████▌   | 116/178 [00:06<00:03, 18.33it/s]\u001b[A\n",
            " 66%|██████▋   | 118/178 [00:06<00:03, 18.44it/s]\u001b[A\n",
            " 67%|██████▋   | 120/178 [00:06<00:03, 18.40it/s]\u001b[A\n",
            " 69%|██████▊   | 122/178 [00:06<00:03, 18.28it/s]\u001b[A\n",
            " 70%|██████▉   | 124/178 [00:06<00:02, 18.14it/s]\u001b[A\n",
            " 71%|███████   | 126/178 [00:06<00:02, 18.31it/s]\u001b[A\n",
            " 72%|███████▏  | 128/178 [00:07<00:02, 18.17it/s]\u001b[A\n",
            " 73%|███████▎  | 130/178 [00:07<00:02, 18.27it/s]\u001b[A\n",
            " 74%|███████▍  | 132/178 [00:07<00:02, 18.37it/s]\u001b[A\n",
            " 75%|███████▌  | 134/178 [00:07<00:02, 18.28it/s]\u001b[A\n",
            " 76%|███████▋  | 136/178 [00:07<00:02, 18.23it/s]\u001b[A\n",
            " 78%|███████▊  | 138/178 [00:07<00:02, 18.23it/s]\u001b[A\n",
            " 79%|███████▊  | 140/178 [00:07<00:02, 18.32it/s]\u001b[A\n",
            " 80%|███████▉  | 142/178 [00:07<00:01, 18.29it/s]\u001b[A\n",
            " 81%|████████  | 144/178 [00:07<00:01, 18.34it/s]\u001b[A\n",
            " 82%|████████▏ | 146/178 [00:08<00:01, 18.30it/s]\u001b[A\n",
            " 83%|████████▎ | 148/178 [00:08<00:01, 18.29it/s]\u001b[A\n",
            " 84%|████████▍ | 150/178 [00:08<00:01, 18.26it/s]\u001b[A\n",
            " 85%|████████▌ | 152/178 [00:08<00:01, 18.30it/s]\u001b[A\n",
            " 87%|████████▋ | 154/178 [00:08<00:01, 18.16it/s]\u001b[A\n",
            " 88%|████████▊ | 156/178 [00:08<00:01, 18.17it/s]\u001b[A\n",
            " 89%|████████▉ | 158/178 [00:08<00:01, 18.12it/s]\u001b[A\n",
            " 90%|████████▉ | 160/178 [00:08<00:00, 18.21it/s]\u001b[A\n",
            " 91%|█████████ | 162/178 [00:08<00:00, 18.26it/s]\u001b[A\n",
            " 92%|█████████▏| 164/178 [00:09<00:00, 18.14it/s]\u001b[A\n",
            " 93%|█████████▎| 166/178 [00:09<00:00, 18.04it/s]\u001b[A\n",
            " 94%|█████████▍| 168/178 [00:09<00:00, 18.19it/s]\u001b[A\n",
            " 96%|█████████▌| 170/178 [00:09<00:00, 18.32it/s]\u001b[A\n",
            " 97%|█████████▋| 172/178 [00:09<00:00, 18.24it/s]\u001b[A\n",
            " 98%|█████████▊| 174/178 [00:09<00:00, 18.31it/s]\u001b[A\n",
            "100%|██████████| 178/178 [00:09<00:00, 18.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUC improved, so saving this model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 203/1422 [00:46<1:32:11,  4.54s/it]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            " 14%|█▍        | 204/1422 [00:46<1:05:28,  3.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to ==> /content/drive/MyDrive/RajWorkspace/mytestresults/model-auc0.402-loss0.354-acc0.904.pt\n",
            "Val loss: 0.3543 Val acc: 0.9043 Val f1: 0.9043 AUC: 0.4015\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 405/1422 [01:17<02:34,  6.57it/s]\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 2/178 [00:00<00:09, 19.28it/s]\u001b[A\n",
            "  2%|▏         | 4/178 [00:00<00:09, 18.81it/s]\u001b[A\n",
            "  3%|▎         | 6/178 [00:00<00:09, 18.75it/s]\u001b[A\n",
            "  4%|▍         | 8/178 [00:00<00:09, 18.76it/s]\u001b[A\n",
            "  6%|▌         | 10/178 [00:00<00:08, 18.78it/s]\u001b[A\n",
            "  7%|▋         | 12/178 [00:00<00:08, 18.73it/s]\u001b[A\n",
            "  8%|▊         | 14/178 [00:00<00:08, 18.66it/s]\u001b[A\n",
            "  9%|▉         | 16/178 [00:00<00:08, 18.46it/s]\u001b[A\n",
            " 10%|█         | 18/178 [00:00<00:08, 18.54it/s]\u001b[A\n",
            " 11%|█         | 20/178 [00:01<00:08, 18.65it/s]\u001b[A\n",
            " 12%|█▏        | 22/178 [00:01<00:08, 18.46it/s]\u001b[A\n",
            " 13%|█▎        | 24/178 [00:01<00:08, 18.53it/s]\u001b[A\n",
            " 15%|█▍        | 26/178 [00:01<00:08, 18.44it/s]\u001b[A\n",
            " 16%|█▌        | 28/178 [00:01<00:08, 18.52it/s]\u001b[A\n",
            " 17%|█▋        | 30/178 [00:01<00:07, 18.62it/s]\u001b[A\n",
            " 18%|█▊        | 32/178 [00:01<00:07, 18.69it/s]\u001b[A\n",
            " 19%|█▉        | 34/178 [00:01<00:07, 18.73it/s]\u001b[A\n",
            " 20%|██        | 36/178 [00:01<00:07, 18.71it/s]\u001b[A\n",
            " 21%|██▏       | 38/178 [00:02<00:07, 18.73it/s]\u001b[A\n",
            " 22%|██▏       | 40/178 [00:02<00:07, 18.68it/s]\u001b[A\n",
            " 24%|██▎       | 42/178 [00:02<00:07, 18.71it/s]\u001b[A\n",
            " 25%|██▍       | 44/178 [00:02<00:07, 18.61it/s]\u001b[A\n",
            " 26%|██▌       | 46/178 [00:02<00:07, 18.65it/s]\u001b[A\n",
            " 27%|██▋       | 48/178 [00:02<00:06, 18.71it/s]\u001b[A\n",
            " 28%|██▊       | 50/178 [00:02<00:06, 18.71it/s]\u001b[A\n",
            " 29%|██▉       | 52/178 [00:02<00:06, 18.63it/s]\u001b[A\n",
            " 30%|███       | 54/178 [00:02<00:06, 18.65it/s]\u001b[A\n",
            " 31%|███▏      | 56/178 [00:03<00:06, 18.65it/s]\u001b[A\n",
            " 33%|███▎      | 58/178 [00:03<00:06, 18.56it/s]\u001b[A\n",
            " 34%|███▎      | 60/178 [00:03<00:06, 18.50it/s]\u001b[A\n",
            " 35%|███▍      | 62/178 [00:03<00:06, 18.47it/s]\u001b[A\n",
            " 36%|███▌      | 64/178 [00:03<00:06, 18.42it/s]\u001b[A\n",
            " 37%|███▋      | 66/178 [00:03<00:06, 18.54it/s]\u001b[A\n",
            " 38%|███▊      | 68/178 [00:03<00:05, 18.55it/s]\u001b[A\n",
            " 39%|███▉      | 70/178 [00:03<00:05, 18.54it/s]\u001b[A\n",
            " 40%|████      | 72/178 [00:03<00:05, 18.51it/s]\u001b[A\n",
            " 42%|████▏     | 74/178 [00:03<00:05, 18.45it/s]\u001b[A\n",
            " 43%|████▎     | 76/178 [00:04<00:05, 18.47it/s]\u001b[A\n",
            " 44%|████▍     | 78/178 [00:04<00:05, 18.50it/s]\u001b[A\n",
            " 45%|████▍     | 80/178 [00:04<00:05, 18.45it/s]\u001b[A\n",
            " 46%|████▌     | 82/178 [00:04<00:05, 18.58it/s]\u001b[A\n",
            " 47%|████▋     | 84/178 [00:04<00:05, 18.66it/s]\u001b[A\n",
            " 48%|████▊     | 86/178 [00:04<00:04, 18.65it/s]\u001b[A\n",
            " 49%|████▉     | 88/178 [00:04<00:04, 18.64it/s]\u001b[A\n",
            " 51%|█████     | 90/178 [00:04<00:04, 18.66it/s]\u001b[A\n",
            " 52%|█████▏    | 92/178 [00:04<00:04, 18.70it/s]\u001b[A\n",
            " 53%|█████▎    | 94/178 [00:05<00:04, 18.69it/s]\u001b[A\n",
            " 54%|█████▍    | 96/178 [00:05<00:04, 18.72it/s]\u001b[A\n",
            " 55%|█████▌    | 98/178 [00:05<00:04, 18.56it/s]\u001b[A\n",
            " 56%|█████▌    | 100/178 [00:05<00:04, 18.64it/s]\u001b[A\n",
            " 57%|█████▋    | 102/178 [00:05<00:04, 18.67it/s]\u001b[A\n",
            " 58%|█████▊    | 104/178 [00:05<00:03, 18.71it/s]\u001b[A\n",
            " 60%|█████▉    | 106/178 [00:05<00:03, 18.72it/s]\u001b[A\n",
            " 61%|██████    | 108/178 [00:05<00:03, 18.73it/s]\u001b[A\n",
            " 62%|██████▏   | 110/178 [00:05<00:03, 18.61it/s]\u001b[A\n",
            " 63%|██████▎   | 112/178 [00:06<00:03, 18.61it/s]\u001b[A\n",
            " 64%|██████▍   | 114/178 [00:06<00:03, 18.67it/s]\u001b[A\n",
            " 65%|██████▌   | 116/178 [00:06<00:03, 18.69it/s]\u001b[A\n",
            " 66%|██████▋   | 118/178 [00:06<00:03, 18.61it/s]\u001b[A\n",
            " 67%|██████▋   | 120/178 [00:06<00:03, 18.68it/s]\u001b[A\n",
            " 69%|██████▊   | 122/178 [00:06<00:03, 18.64it/s]\u001b[A\n",
            " 70%|██████▉   | 124/178 [00:06<00:02, 18.24it/s]\u001b[A\n",
            " 71%|███████   | 126/178 [00:06<00:02, 17.90it/s]\u001b[A\n",
            " 72%|███████▏  | 128/178 [00:06<00:02, 17.42it/s]\u001b[A\n",
            " 73%|███████▎  | 130/178 [00:07<00:02, 17.22it/s]\u001b[A\n",
            " 74%|███████▍  | 132/178 [00:07<00:02, 17.53it/s]\u001b[A\n",
            " 75%|███████▌  | 134/178 [00:07<00:02, 17.81it/s]\u001b[A\n",
            " 76%|███████▋  | 136/178 [00:07<00:02, 17.87it/s]\u001b[A\n",
            " 78%|███████▊  | 138/178 [00:07<00:02, 18.01it/s]\u001b[A\n",
            " 79%|███████▊  | 140/178 [00:07<00:02, 18.18it/s]\u001b[A\n",
            " 80%|███████▉  | 142/178 [00:07<00:02, 15.48it/s]\u001b[A\n",
            " 81%|████████  | 144/178 [00:07<00:02, 15.78it/s]\u001b[A\n",
            " 82%|████████▏ | 146/178 [00:07<00:01, 16.04it/s]\u001b[A\n",
            " 83%|████████▎ | 148/178 [00:08<00:01, 16.69it/s]\u001b[A\n",
            " 84%|████████▍ | 150/178 [00:08<00:01, 17.28it/s]\u001b[A\n",
            " 85%|████████▌ | 152/178 [00:08<00:01, 17.63it/s]\u001b[A\n",
            " 87%|████████▋ | 154/178 [00:08<00:01, 17.84it/s]\u001b[A\n",
            " 88%|████████▊ | 156/178 [00:08<00:01, 18.07it/s]\u001b[A\n",
            " 89%|████████▉ | 158/178 [00:08<00:01, 17.48it/s]\u001b[A\n",
            " 90%|████████▉ | 160/178 [00:08<00:01, 17.23it/s]\u001b[A\n",
            " 91%|█████████ | 162/178 [00:08<00:00, 17.26it/s]\u001b[A\n",
            " 92%|█████████▏| 164/178 [00:08<00:00, 17.70it/s]\u001b[A\n",
            " 93%|█████████▎| 166/178 [00:09<00:00, 17.94it/s]\u001b[A\n",
            " 94%|█████████▍| 168/178 [00:09<00:00, 18.15it/s]\u001b[A\n",
            " 96%|█████████▌| 170/178 [00:09<00:00, 18.37it/s]\u001b[A\n",
            " 97%|█████████▋| 172/178 [00:09<00:00, 18.37it/s]\u001b[A\n",
            " 98%|█████████▊| 174/178 [00:09<00:00, 18.49it/s]\u001b[A\n",
            "100%|██████████| 178/178 [00:09<00:00, 18.30it/s]\n",
            " 29%|██▊       | 406/1422 [01:27<52:02,  3.07s/it]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            " 29%|██▊       | 407/1422 [01:27<37:08,  2.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 0.3122 Val acc: 0.9043 Val f1: 0.9043 AUC: 0.6622\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 608/1422 [01:57<02:01,  6.73it/s]\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 2/178 [00:00<00:09, 19.10it/s]\u001b[A\n",
            "  2%|▏         | 4/178 [00:00<00:09, 18.82it/s]\u001b[A\n",
            "  3%|▎         | 6/178 [00:00<00:09, 18.73it/s]\u001b[A\n",
            "  4%|▍         | 8/178 [00:00<00:09, 18.68it/s]\u001b[A\n",
            "  6%|▌         | 10/178 [00:00<00:09, 18.61it/s]\u001b[A\n",
            "  7%|▋         | 12/178 [00:00<00:08, 18.62it/s]\u001b[A\n",
            "  8%|▊         | 14/178 [00:00<00:08, 18.57it/s]\u001b[A\n",
            "  9%|▉         | 16/178 [00:00<00:08, 18.59it/s]\u001b[A\n",
            " 10%|█         | 18/178 [00:00<00:08, 18.56it/s]\u001b[A\n",
            " 11%|█         | 20/178 [00:01<00:08, 18.55it/s]\u001b[A\n",
            " 12%|█▏        | 22/178 [00:01<00:08, 18.44it/s]\u001b[A\n",
            " 13%|█▎        | 24/178 [00:01<00:08, 18.41it/s]\u001b[A\n",
            " 15%|█▍        | 26/178 [00:01<00:08, 18.30it/s]\u001b[A\n",
            " 16%|█▌        | 28/178 [00:01<00:08, 18.39it/s]\u001b[A\n",
            " 17%|█▋        | 30/178 [00:01<00:08, 18.40it/s]\u001b[A\n",
            " 18%|█▊        | 32/178 [00:01<00:07, 18.55it/s]\u001b[A\n",
            " 19%|█▉        | 34/178 [00:01<00:07, 18.64it/s]\u001b[A\n",
            " 20%|██        | 36/178 [00:01<00:07, 18.65it/s]\u001b[A\n",
            " 21%|██▏       | 38/178 [00:02<00:07, 18.49it/s]\u001b[A\n",
            " 22%|██▏       | 40/178 [00:02<00:07, 18.50it/s]\u001b[A\n",
            " 24%|██▎       | 42/178 [00:02<00:07, 18.52it/s]\u001b[A\n",
            " 25%|██▍       | 44/178 [00:02<00:07, 18.46it/s]\u001b[A\n",
            " 26%|██▌       | 46/178 [00:02<00:07, 18.51it/s]\u001b[A\n",
            " 27%|██▋       | 48/178 [00:02<00:07, 18.57it/s]\u001b[A\n",
            " 28%|██▊       | 50/178 [00:02<00:06, 18.53it/s]\u001b[A\n",
            " 29%|██▉       | 52/178 [00:02<00:06, 18.51it/s]\u001b[A\n",
            " 30%|███       | 54/178 [00:02<00:06, 18.52it/s]\u001b[A\n",
            " 31%|███▏      | 56/178 [00:03<00:06, 18.63it/s]\u001b[A\n",
            " 33%|███▎      | 58/178 [00:03<00:06, 18.65it/s]\u001b[A\n",
            " 34%|███▎      | 60/178 [00:03<00:06, 18.64it/s]\u001b[A\n",
            " 35%|███▍      | 62/178 [00:03<00:06, 18.69it/s]\u001b[A\n",
            " 36%|███▌      | 64/178 [00:03<00:06, 18.58it/s]\u001b[A\n",
            " 37%|███▋      | 66/178 [00:03<00:06, 18.61it/s]\u001b[A\n",
            " 38%|███▊      | 68/178 [00:03<00:05, 18.53it/s]\u001b[A\n",
            " 39%|███▉      | 70/178 [00:03<00:05, 18.61it/s]\u001b[A\n",
            " 40%|████      | 72/178 [00:03<00:05, 18.63it/s]\u001b[A\n",
            " 42%|████▏     | 74/178 [00:03<00:05, 18.70it/s]\u001b[A\n",
            " 43%|████▎     | 76/178 [00:04<00:05, 18.55it/s]\u001b[A\n",
            " 44%|████▍     | 78/178 [00:04<00:05, 18.49it/s]\u001b[A\n",
            " 45%|████▍     | 80/178 [00:04<00:05, 18.49it/s]\u001b[A\n",
            " 46%|████▌     | 82/178 [00:04<00:05, 18.43it/s]\u001b[A\n",
            " 47%|████▋     | 84/178 [00:04<00:05, 18.47it/s]\u001b[A\n",
            " 48%|████▊     | 86/178 [00:04<00:04, 18.51it/s]\u001b[A\n",
            " 49%|████▉     | 88/178 [00:04<00:04, 18.58it/s]\u001b[A\n",
            " 51%|█████     | 90/178 [00:04<00:04, 18.61it/s]\u001b[A\n",
            " 52%|█████▏    | 92/178 [00:04<00:04, 18.64it/s]\u001b[A\n",
            " 53%|█████▎    | 94/178 [00:05<00:04, 18.66it/s]\u001b[A\n",
            " 54%|█████▍    | 96/178 [00:05<00:04, 18.60it/s]\u001b[A\n",
            " 55%|█████▌    | 98/178 [00:05<00:04, 18.73it/s]\u001b[A\n",
            " 56%|█████▌    | 100/178 [00:05<00:04, 18.78it/s]\u001b[A\n",
            " 57%|█████▋    | 102/178 [00:05<00:04, 18.81it/s]\u001b[A\n",
            " 58%|█████▊    | 104/178 [00:05<00:03, 18.76it/s]\u001b[A\n",
            " 60%|█████▉    | 106/178 [00:05<00:03, 18.69it/s]\u001b[A\n",
            " 61%|██████    | 108/178 [00:05<00:03, 18.68it/s]\u001b[A\n",
            " 62%|██████▏   | 110/178 [00:05<00:03, 18.66it/s]\u001b[A\n",
            " 63%|██████▎   | 112/178 [00:06<00:03, 18.63it/s]\u001b[A\n",
            " 64%|██████▍   | 114/178 [00:06<00:03, 18.64it/s]\u001b[A\n",
            " 65%|██████▌   | 116/178 [00:06<00:03, 18.63it/s]\u001b[A\n",
            " 66%|██████▋   | 118/178 [00:06<00:03, 18.49it/s]\u001b[A\n",
            " 67%|██████▋   | 120/178 [00:06<00:03, 18.33it/s]\u001b[A\n",
            " 69%|██████▊   | 122/178 [00:06<00:03, 18.41it/s]\u001b[A\n",
            " 70%|██████▉   | 124/178 [00:06<00:02, 18.35it/s]\u001b[A\n",
            " 71%|███████   | 126/178 [00:06<00:02, 18.50it/s]\u001b[A\n",
            " 72%|███████▏  | 128/178 [00:06<00:02, 18.42it/s]\u001b[A\n",
            " 73%|███████▎  | 130/178 [00:07<00:02, 18.40it/s]\u001b[A\n",
            " 74%|███████▍  | 132/178 [00:07<00:02, 18.35it/s]\u001b[A\n",
            " 75%|███████▌  | 134/178 [00:07<00:02, 18.25it/s]\u001b[A\n",
            " 76%|███████▋  | 136/178 [00:07<00:02, 18.30it/s]\u001b[A\n",
            " 78%|███████▊  | 138/178 [00:07<00:02, 18.33it/s]\u001b[A\n",
            " 79%|███████▊  | 140/178 [00:07<00:02, 18.37it/s]\u001b[A\n",
            " 80%|███████▉  | 142/178 [00:07<00:01, 18.42it/s]\u001b[A\n",
            " 81%|████████  | 144/178 [00:07<00:01, 18.45it/s]\u001b[A\n",
            " 82%|████████▏ | 146/178 [00:07<00:01, 18.55it/s]\u001b[A\n",
            " 83%|████████▎ | 148/178 [00:07<00:01, 18.52it/s]\u001b[A\n",
            " 84%|████████▍ | 150/178 [00:08<00:01, 18.58it/s]\u001b[A\n",
            " 85%|████████▌ | 152/178 [00:08<00:01, 18.54it/s]\u001b[A\n",
            " 87%|████████▋ | 154/178 [00:08<00:01, 18.43it/s]\u001b[A\n",
            " 88%|████████▊ | 156/178 [00:08<00:01, 18.44it/s]\u001b[A\n",
            " 89%|████████▉ | 158/178 [00:08<00:01, 18.44it/s]\u001b[A\n",
            " 90%|████████▉ | 160/178 [00:08<00:00, 18.48it/s]\u001b[A\n",
            " 91%|█████████ | 162/178 [00:08<00:00, 18.44it/s]\u001b[A\n",
            " 92%|█████████▏| 164/178 [00:08<00:00, 18.50it/s]\u001b[A\n",
            " 93%|█████████▎| 166/178 [00:08<00:00, 18.57it/s]\u001b[A\n",
            " 94%|█████████▍| 168/178 [00:09<00:00, 18.61it/s]\u001b[A\n",
            " 96%|█████████▌| 170/178 [00:09<00:00, 18.40it/s]\u001b[A\n",
            " 97%|█████████▋| 172/178 [00:09<00:00, 18.43it/s]\u001b[A\n",
            " 98%|█████████▊| 174/178 [00:09<00:00, 18.52it/s]\u001b[A\n",
            "100%|██████████| 178/178 [00:09<00:00, 18.55it/s]\n",
            " 43%|████▎     | 609/1422 [02:07<41:02,  3.03s/it]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            " 43%|████▎     | 610/1422 [02:07<29:17,  2.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 0.3189 Val acc: 0.9043 Val f1: 0.9043 AUC: 0.3668\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 811/1422 [02:38<01:30,  6.75it/s]\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 2/178 [00:00<00:08, 19.60it/s]\u001b[A\n",
            "  2%|▏         | 4/178 [00:00<00:09, 18.98it/s]\u001b[A\n",
            "  3%|▎         | 6/178 [00:00<00:09, 18.87it/s]\u001b[A\n",
            "  4%|▍         | 8/178 [00:00<00:09, 18.82it/s]\u001b[A\n",
            "  6%|▌         | 10/178 [00:00<00:08, 18.84it/s]\u001b[A\n",
            "  7%|▋         | 12/178 [00:00<00:08, 18.78it/s]\u001b[A\n",
            "  8%|▊         | 14/178 [00:00<00:08, 18.69it/s]\u001b[A\n",
            "  9%|▉         | 16/178 [00:00<00:08, 18.74it/s]\u001b[A\n",
            " 10%|█         | 18/178 [00:00<00:08, 18.71it/s]\u001b[A\n",
            " 11%|█         | 20/178 [00:01<00:08, 18.81it/s]\u001b[A\n",
            " 12%|█▏        | 22/178 [00:01<00:08, 18.80it/s]\u001b[A\n",
            " 13%|█▎        | 24/178 [00:01<00:08, 18.75it/s]\u001b[A\n",
            " 15%|█▍        | 26/178 [00:01<00:08, 18.73it/s]\u001b[A\n",
            " 16%|█▌        | 28/178 [00:01<00:08, 18.73it/s]\u001b[A\n",
            " 17%|█▋        | 30/178 [00:01<00:07, 18.69it/s]\u001b[A\n",
            " 18%|█▊        | 32/178 [00:01<00:07, 18.64it/s]\u001b[A\n",
            " 19%|█▉        | 34/178 [00:01<00:07, 18.66it/s]\u001b[A\n",
            " 20%|██        | 36/178 [00:01<00:07, 18.57it/s]\u001b[A\n",
            " 21%|██▏       | 38/178 [00:02<00:07, 18.65it/s]\u001b[A\n",
            " 22%|██▏       | 40/178 [00:02<00:07, 18.56it/s]\u001b[A\n",
            " 24%|██▎       | 42/178 [00:02<00:07, 18.57it/s]\u001b[A\n",
            " 25%|██▍       | 44/178 [00:02<00:07, 18.59it/s]\u001b[A\n",
            " 26%|██▌       | 46/178 [00:02<00:07, 18.69it/s]\u001b[A\n",
            " 27%|██▋       | 48/178 [00:02<00:06, 18.71it/s]\u001b[A\n",
            " 28%|██▊       | 50/178 [00:02<00:06, 18.69it/s]\u001b[A\n",
            " 29%|██▉       | 52/178 [00:02<00:06, 18.66it/s]\u001b[A\n",
            " 30%|███       | 54/178 [00:02<00:06, 18.53it/s]\u001b[A\n",
            " 31%|███▏      | 56/178 [00:02<00:06, 18.58it/s]\u001b[A\n",
            " 33%|███▎      | 58/178 [00:03<00:06, 18.46it/s]\u001b[A\n",
            " 34%|███▎      | 60/178 [00:03<00:06, 18.52it/s]\u001b[A\n",
            " 35%|███▍      | 62/178 [00:03<00:06, 18.46it/s]\u001b[A\n",
            " 36%|███▌      | 64/178 [00:03<00:06, 18.33it/s]\u001b[A\n",
            " 37%|███▋      | 66/178 [00:03<00:06, 18.21it/s]\u001b[A\n",
            " 38%|███▊      | 68/178 [00:03<00:06, 18.23it/s]\u001b[A\n",
            " 39%|███▉      | 70/178 [00:03<00:05, 18.31it/s]\u001b[A\n",
            " 40%|████      | 72/178 [00:03<00:05, 18.30it/s]\u001b[A\n",
            " 42%|████▏     | 74/178 [00:03<00:05, 18.35it/s]\u001b[A\n",
            " 43%|████▎     | 76/178 [00:04<00:05, 18.30it/s]\u001b[A\n",
            " 44%|████▍     | 78/178 [00:04<00:05, 18.52it/s]\u001b[A\n",
            " 45%|████▍     | 80/178 [00:04<00:05, 18.45it/s]\u001b[A\n",
            " 46%|████▌     | 82/178 [00:04<00:05, 18.46it/s]\u001b[A\n",
            " 47%|████▋     | 84/178 [00:04<00:05, 18.51it/s]\u001b[A\n",
            " 48%|████▊     | 86/178 [00:04<00:04, 18.59it/s]\u001b[A\n",
            " 49%|████▉     | 88/178 [00:04<00:04, 18.52it/s]\u001b[A\n",
            " 51%|█████     | 90/178 [00:04<00:04, 18.57it/s]\u001b[A\n",
            " 52%|█████▏    | 92/178 [00:04<00:04, 18.64it/s]\u001b[A\n",
            " 53%|█████▎    | 94/178 [00:05<00:04, 18.64it/s]\u001b[A\n",
            " 54%|█████▍    | 96/178 [00:05<00:04, 18.65it/s]\u001b[A\n",
            " 55%|█████▌    | 98/178 [00:05<00:04, 18.35it/s]\u001b[A\n",
            " 56%|█████▌    | 100/178 [00:05<00:04, 18.41it/s]\u001b[A\n",
            " 57%|█████▋    | 102/178 [00:05<00:04, 18.31it/s]\u001b[A\n",
            " 58%|█████▊    | 104/178 [00:05<00:04, 18.46it/s]\u001b[A\n",
            " 60%|█████▉    | 106/178 [00:05<00:03, 18.42it/s]\u001b[A\n",
            " 61%|██████    | 108/178 [00:05<00:03, 18.45it/s]\u001b[A\n",
            " 62%|██████▏   | 110/178 [00:05<00:03, 18.54it/s]\u001b[A\n",
            " 63%|██████▎   | 112/178 [00:06<00:03, 18.50it/s]\u001b[A\n",
            " 64%|██████▍   | 114/178 [00:06<00:03, 18.39it/s]\u001b[A\n",
            " 65%|██████▌   | 116/178 [00:06<00:03, 18.55it/s]\u001b[A\n",
            " 66%|██████▋   | 118/178 [00:06<00:03, 18.60it/s]\u001b[A\n",
            " 67%|██████▋   | 120/178 [00:06<00:03, 18.65it/s]\u001b[A\n",
            " 69%|██████▊   | 122/178 [00:06<00:03, 18.63it/s]\u001b[A\n",
            " 70%|██████▉   | 124/178 [00:06<00:02, 18.63it/s]\u001b[A\n",
            " 71%|███████   | 126/178 [00:06<00:02, 18.55it/s]\u001b[A\n",
            " 72%|███████▏  | 128/178 [00:06<00:02, 18.64it/s]\u001b[A\n",
            " 73%|███████▎  | 130/178 [00:07<00:02, 18.47it/s]\u001b[A\n",
            " 74%|███████▍  | 132/178 [00:07<00:02, 18.47it/s]\u001b[A\n",
            " 75%|███████▌  | 134/178 [00:07<00:02, 18.55it/s]\u001b[A\n",
            " 76%|███████▋  | 136/178 [00:07<00:02, 18.62it/s]\u001b[A\n",
            " 78%|███████▊  | 138/178 [00:07<00:02, 18.67it/s]\u001b[A\n",
            " 79%|███████▊  | 140/178 [00:07<00:02, 18.69it/s]\u001b[A\n",
            " 80%|███████▉  | 142/178 [00:07<00:01, 18.75it/s]\u001b[A\n",
            " 81%|████████  | 144/178 [00:07<00:01, 18.65it/s]\u001b[A\n",
            " 82%|████████▏ | 146/178 [00:07<00:01, 18.68it/s]\u001b[A\n",
            " 83%|████████▎ | 148/178 [00:07<00:01, 18.77it/s]\u001b[A\n",
            " 84%|████████▍ | 150/178 [00:08<00:01, 18.75it/s]\u001b[A\n",
            " 85%|████████▌ | 152/178 [00:08<00:01, 18.78it/s]\u001b[A\n",
            " 87%|████████▋ | 154/178 [00:08<00:01, 18.69it/s]\u001b[A\n",
            " 88%|████████▊ | 156/178 [00:08<00:01, 18.67it/s]\u001b[A\n",
            " 89%|████████▉ | 158/178 [00:08<00:01, 18.65it/s]\u001b[A\n",
            " 90%|████████▉ | 160/178 [00:08<00:00, 18.57it/s]\u001b[A\n",
            " 91%|█████████ | 162/178 [00:08<00:00, 18.55it/s]\u001b[A\n",
            " 92%|█████████▏| 164/178 [00:08<00:00, 18.57it/s]\u001b[A\n",
            " 93%|█████████▎| 166/178 [00:08<00:00, 18.63it/s]\u001b[A\n",
            " 94%|█████████▍| 168/178 [00:09<00:00, 18.70it/s]\u001b[A\n",
            " 96%|█████████▌| 170/178 [00:09<00:00, 18.76it/s]\u001b[A\n",
            " 97%|█████████▋| 172/178 [00:09<00:00, 18.65it/s]\u001b[A\n",
            " 98%|█████████▊| 174/178 [00:09<00:00, 18.62it/s]\u001b[A\n",
            "100%|██████████| 178/178 [00:09<00:00, 18.62it/s]\n",
            " 57%|█████▋    | 812/1422 [02:47<30:42,  3.02s/it]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            " 57%|█████▋    | 813/1422 [02:48<21:54,  2.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 0.3185 Val acc: 0.9043 Val f1: 0.9043 AUC: 0.4192\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 71%|███████▏  | 1014/1422 [03:18<01:00,  6.76it/s]\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 2/178 [00:00<00:09, 19.16it/s]\u001b[A\n",
            "  2%|▏         | 4/178 [00:00<00:09, 18.41it/s]\u001b[A\n",
            "  3%|▎         | 6/178 [00:00<00:09, 18.21it/s]\u001b[A\n",
            "  4%|▍         | 8/178 [00:00<00:09, 18.12it/s]\u001b[A\n",
            "  6%|▌         | 10/178 [00:00<00:09, 18.21it/s]\u001b[A\n",
            "  7%|▋         | 12/178 [00:00<00:09, 18.05it/s]\u001b[A\n",
            "  8%|▊         | 14/178 [00:00<00:09, 18.05it/s]\u001b[A\n",
            "  9%|▉         | 16/178 [00:00<00:08, 18.04it/s]\u001b[A\n",
            " 10%|█         | 18/178 [00:00<00:08, 18.26it/s]\u001b[A\n",
            " 11%|█         | 20/178 [00:01<00:08, 18.35it/s]\u001b[A\n",
            " 12%|█▏        | 22/178 [00:01<00:08, 18.45it/s]\u001b[A\n",
            " 13%|█▎        | 24/178 [00:01<00:08, 18.47it/s]\u001b[A\n",
            " 15%|█▍        | 26/178 [00:01<00:08, 18.25it/s]\u001b[A\n",
            " 16%|█▌        | 28/178 [00:01<00:08, 18.33it/s]\u001b[A\n",
            " 17%|█▋        | 30/178 [00:01<00:08, 18.46it/s]\u001b[A\n",
            " 18%|█▊        | 32/178 [00:01<00:07, 18.50it/s]\u001b[A\n",
            " 19%|█▉        | 34/178 [00:01<00:07, 18.47it/s]\u001b[A\n",
            " 20%|██        | 36/178 [00:01<00:07, 18.51it/s]\u001b[A\n",
            " 21%|██▏       | 38/178 [00:02<00:07, 18.23it/s]\u001b[A\n",
            " 22%|██▏       | 40/178 [00:02<00:07, 18.21it/s]\u001b[A\n",
            " 24%|██▎       | 42/178 [00:02<00:07, 18.19it/s]\u001b[A\n",
            " 25%|██▍       | 44/178 [00:02<00:07, 18.34it/s]\u001b[A\n",
            " 26%|██▌       | 46/178 [00:02<00:07, 18.30it/s]\u001b[A\n",
            " 27%|██▋       | 48/178 [00:02<00:07, 18.34it/s]\u001b[A\n",
            " 28%|██▊       | 50/178 [00:02<00:06, 18.43it/s]\u001b[A\n",
            " 29%|██▉       | 52/178 [00:02<00:06, 18.45it/s]\u001b[A\n",
            " 30%|███       | 54/178 [00:02<00:06, 18.42it/s]\u001b[A\n",
            " 31%|███▏      | 56/178 [00:03<00:06, 18.49it/s]\u001b[A\n",
            " 33%|███▎      | 58/178 [00:03<00:06, 18.51it/s]\u001b[A\n",
            " 34%|███▎      | 60/178 [00:03<00:06, 18.51it/s]\u001b[A\n",
            " 35%|███▍      | 62/178 [00:03<00:06, 18.51it/s]\u001b[A\n",
            " 36%|███▌      | 64/178 [00:03<00:06, 18.51it/s]\u001b[A\n",
            " 37%|███▋      | 66/178 [00:03<00:06, 18.39it/s]\u001b[A\n",
            " 38%|███▊      | 68/178 [00:03<00:06, 18.30it/s]\u001b[A\n",
            " 39%|███▉      | 70/178 [00:03<00:05, 18.14it/s]\u001b[A\n",
            " 40%|████      | 72/178 [00:03<00:05, 18.06it/s]\u001b[A\n",
            " 42%|████▏     | 74/178 [00:04<00:05, 18.14it/s]\u001b[A\n",
            " 43%|████▎     | 76/178 [00:04<00:05, 18.30it/s]\u001b[A\n",
            " 44%|████▍     | 78/178 [00:04<00:05, 18.33it/s]\u001b[A\n",
            " 45%|████▍     | 80/178 [00:04<00:05, 18.45it/s]\u001b[A\n",
            " 46%|████▌     | 82/178 [00:04<00:05, 18.56it/s]\u001b[A\n",
            " 47%|████▋     | 84/178 [00:04<00:05, 18.53it/s]\u001b[A\n",
            " 48%|████▊     | 86/178 [00:04<00:04, 18.48it/s]\u001b[A\n",
            " 49%|████▉     | 88/178 [00:04<00:04, 18.53it/s]\u001b[A\n",
            " 51%|█████     | 90/178 [00:04<00:04, 18.53it/s]\u001b[A\n",
            " 52%|█████▏    | 92/178 [00:05<00:04, 18.50it/s]\u001b[A\n",
            " 53%|█████▎    | 94/178 [00:05<00:04, 18.45it/s]\u001b[A\n",
            " 54%|█████▍    | 96/178 [00:05<00:04, 18.47it/s]\u001b[A\n",
            " 55%|█████▌    | 98/178 [00:05<00:04, 18.28it/s]\u001b[A\n",
            " 56%|█████▌    | 100/178 [00:05<00:04, 18.34it/s]\u001b[A\n",
            " 57%|█████▋    | 102/178 [00:05<00:04, 18.38it/s]\u001b[A\n",
            " 58%|█████▊    | 104/178 [00:05<00:04, 18.43it/s]\u001b[A\n",
            " 60%|█████▉    | 106/178 [00:05<00:03, 18.25it/s]\u001b[A\n",
            " 61%|██████    | 108/178 [00:05<00:03, 18.20it/s]\u001b[A\n",
            " 62%|██████▏   | 110/178 [00:05<00:03, 18.20it/s]\u001b[A\n",
            " 63%|██████▎   | 112/178 [00:06<00:03, 18.10it/s]\u001b[A\n",
            " 64%|██████▍   | 114/178 [00:06<00:03, 18.21it/s]\u001b[A\n",
            " 65%|██████▌   | 116/178 [00:06<00:03, 18.33it/s]\u001b[A\n",
            " 66%|██████▋   | 118/178 [00:06<00:03, 18.33it/s]\u001b[A\n",
            " 67%|██████▋   | 120/178 [00:06<00:03, 18.21it/s]\u001b[A\n",
            " 69%|██████▊   | 122/178 [00:06<00:03, 18.22it/s]\u001b[A\n",
            " 70%|██████▉   | 124/178 [00:06<00:02, 18.33it/s]\u001b[A\n",
            " 71%|███████   | 126/178 [00:06<00:02, 18.28it/s]\u001b[A\n",
            " 72%|███████▏  | 128/178 [00:06<00:02, 18.09it/s]\u001b[A\n",
            " 73%|███████▎  | 130/178 [00:07<00:02, 18.13it/s]\u001b[A\n",
            " 74%|███████▍  | 132/178 [00:07<00:02, 18.16it/s]\u001b[A\n",
            " 75%|███████▌  | 134/178 [00:07<00:02, 18.25it/s]\u001b[A\n",
            " 76%|███████▋  | 136/178 [00:07<00:02, 18.23it/s]\u001b[A\n",
            " 78%|███████▊  | 138/178 [00:07<00:02, 18.28it/s]\u001b[A\n",
            " 79%|███████▊  | 140/178 [00:07<00:02, 18.39it/s]\u001b[A\n",
            " 80%|███████▉  | 142/178 [00:07<00:01, 18.40it/s]\u001b[A\n",
            " 81%|████████  | 144/178 [00:07<00:01, 18.38it/s]\u001b[A\n",
            " 82%|████████▏ | 146/178 [00:07<00:01, 18.24it/s]\u001b[A\n",
            " 83%|████████▎ | 148/178 [00:08<00:01, 18.25it/s]\u001b[A\n",
            " 84%|████████▍ | 150/178 [00:08<00:01, 18.22it/s]\u001b[A\n",
            " 85%|████████▌ | 152/178 [00:08<00:01, 18.16it/s]\u001b[A\n",
            " 87%|████████▋ | 154/178 [00:08<00:01, 18.22it/s]\u001b[A\n",
            " 88%|████████▊ | 156/178 [00:08<00:01, 18.34it/s]\u001b[A\n",
            " 89%|████████▉ | 158/178 [00:08<00:01, 18.22it/s]\u001b[A\n",
            " 90%|████████▉ | 160/178 [00:08<00:00, 18.20it/s]\u001b[A\n",
            " 91%|█████████ | 162/178 [00:08<00:00, 18.39it/s]\u001b[A\n",
            " 92%|█████████▏| 164/178 [00:08<00:00, 18.29it/s]\u001b[A\n",
            " 93%|█████████▎| 166/178 [00:09<00:00, 18.36it/s]\u001b[A\n",
            " 94%|█████████▍| 168/178 [00:09<00:00, 18.39it/s]\u001b[A\n",
            " 96%|█████████▌| 170/178 [00:09<00:00, 18.32it/s]\u001b[A\n",
            " 97%|█████████▋| 172/178 [00:09<00:00, 18.35it/s]\u001b[A\n",
            " 98%|█████████▊| 174/178 [00:09<00:00, 18.23it/s]\u001b[A\n",
            "100%|██████████| 178/178 [00:09<00:00, 18.35it/s]\n",
            " 71%|███████▏  | 1015/1422 [03:28<20:46,  3.06s/it]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            " 71%|███████▏  | 1016/1422 [03:28<14:48,  2.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 0.3157 Val acc: 0.9043 Val f1: 0.9043 AUC: 0.5374\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 1217/1422 [03:59<00:30,  6.79it/s]\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 2/178 [00:00<00:09, 19.11it/s]\u001b[A\n",
            "  2%|▏         | 4/178 [00:00<00:09, 18.82it/s]\u001b[A\n",
            "  3%|▎         | 6/178 [00:00<00:09, 18.69it/s]\u001b[A\n",
            "  4%|▍         | 8/178 [00:00<00:09, 18.56it/s]\u001b[A\n",
            "  6%|▌         | 10/178 [00:00<00:09, 18.50it/s]\u001b[A\n",
            "  7%|▋         | 12/178 [00:00<00:08, 18.47it/s]\u001b[A\n",
            "  8%|▊         | 14/178 [00:00<00:08, 18.38it/s]\u001b[A\n",
            "  9%|▉         | 16/178 [00:00<00:08, 18.38it/s]\u001b[A\n",
            " 10%|█         | 18/178 [00:00<00:08, 18.32it/s]\u001b[A\n",
            " 11%|█         | 20/178 [00:01<00:08, 18.38it/s]\u001b[A\n",
            " 12%|█▏        | 22/178 [00:01<00:08, 18.42it/s]\u001b[A\n",
            " 13%|█▎        | 24/178 [00:01<00:08, 18.35it/s]\u001b[A\n",
            " 15%|█▍        | 26/178 [00:01<00:08, 18.33it/s]\u001b[A\n",
            " 16%|█▌        | 28/178 [00:01<00:08, 18.39it/s]\u001b[A\n",
            " 17%|█▋        | 30/178 [00:01<00:08, 18.39it/s]\u001b[A\n",
            " 18%|█▊        | 32/178 [00:01<00:07, 18.43it/s]\u001b[A\n",
            " 19%|█▉        | 34/178 [00:01<00:07, 18.35it/s]\u001b[A\n",
            " 20%|██        | 36/178 [00:01<00:07, 18.35it/s]\u001b[A\n",
            " 21%|██▏       | 38/178 [00:02<00:07, 18.32it/s]\u001b[A\n",
            " 22%|██▏       | 40/178 [00:02<00:07, 18.30it/s]\u001b[A\n",
            " 24%|██▎       | 42/178 [00:02<00:07, 18.34it/s]\u001b[A\n",
            " 25%|██▍       | 44/178 [00:02<00:07, 18.32it/s]\u001b[A\n",
            " 26%|██▌       | 46/178 [00:02<00:07, 18.40it/s]\u001b[A\n",
            " 27%|██▋       | 48/178 [00:02<00:07, 18.35it/s]\u001b[A\n",
            " 28%|██▊       | 50/178 [00:02<00:06, 18.34it/s]\u001b[A\n",
            " 29%|██▉       | 52/178 [00:02<00:06, 18.30it/s]\u001b[A\n",
            " 30%|███       | 54/178 [00:02<00:06, 18.28it/s]\u001b[A\n",
            " 31%|███▏      | 56/178 [00:03<00:06, 18.22it/s]\u001b[A\n",
            " 33%|███▎      | 58/178 [00:03<00:06, 18.27it/s]\u001b[A\n",
            " 34%|███▎      | 60/178 [00:03<00:06, 18.21it/s]\u001b[A\n",
            " 35%|███▍      | 62/178 [00:03<00:06, 18.26it/s]\u001b[A\n",
            " 36%|███▌      | 64/178 [00:03<00:06, 18.28it/s]\u001b[A\n",
            " 37%|███▋      | 66/178 [00:03<00:06, 18.32it/s]\u001b[A\n",
            " 38%|███▊      | 68/178 [00:03<00:05, 18.45it/s]\u001b[A\n",
            " 39%|███▉      | 70/178 [00:03<00:05, 18.40it/s]\u001b[A\n",
            " 40%|████      | 72/178 [00:03<00:05, 18.12it/s]\u001b[A\n",
            " 42%|████▏     | 74/178 [00:04<00:05, 18.18it/s]\u001b[A\n",
            " 43%|████▎     | 76/178 [00:04<00:05, 18.34it/s]\u001b[A\n",
            " 44%|████▍     | 78/178 [00:04<00:05, 18.25it/s]\u001b[A\n",
            " 45%|████▍     | 80/178 [00:04<00:05, 18.38it/s]\u001b[A\n",
            " 46%|████▌     | 82/178 [00:04<00:05, 18.43it/s]\u001b[A\n",
            " 47%|████▋     | 84/178 [00:04<00:05, 18.48it/s]\u001b[A\n",
            " 48%|████▊     | 86/178 [00:04<00:04, 18.50it/s]\u001b[A\n",
            " 49%|████▉     | 88/178 [00:04<00:04, 18.54it/s]\u001b[A\n",
            " 51%|█████     | 90/178 [00:04<00:04, 18.57it/s]\u001b[A\n",
            " 52%|█████▏    | 92/178 [00:05<00:04, 18.63it/s]\u001b[A\n",
            " 53%|█████▎    | 94/178 [00:05<00:04, 18.58it/s]\u001b[A\n",
            " 54%|█████▍    | 96/178 [00:05<00:04, 18.54it/s]\u001b[A\n",
            " 55%|█████▌    | 98/178 [00:05<00:04, 18.61it/s]\u001b[A\n",
            " 56%|█████▌    | 100/178 [00:05<00:04, 18.66it/s]\u001b[A\n",
            " 57%|█████▋    | 102/178 [00:05<00:04, 18.76it/s]\u001b[A\n",
            " 58%|█████▊    | 104/178 [00:05<00:03, 18.76it/s]\u001b[A\n",
            " 60%|█████▉    | 106/178 [00:05<00:03, 18.80it/s]\u001b[A\n",
            " 61%|██████    | 108/178 [00:05<00:03, 18.83it/s]\u001b[A\n",
            " 62%|██████▏   | 110/178 [00:05<00:03, 18.64it/s]\u001b[A\n",
            " 63%|██████▎   | 112/178 [00:06<00:03, 18.61it/s]\u001b[A\n",
            " 64%|██████▍   | 114/178 [00:06<00:03, 18.66it/s]\u001b[A\n",
            " 65%|██████▌   | 116/178 [00:06<00:03, 18.66it/s]\u001b[A\n",
            " 66%|██████▋   | 118/178 [00:06<00:03, 18.58it/s]\u001b[A\n",
            " 67%|██████▋   | 120/178 [00:06<00:03, 18.63it/s]\u001b[A\n",
            " 69%|██████▊   | 122/178 [00:06<00:03, 18.66it/s]\u001b[A\n",
            " 70%|██████▉   | 124/178 [00:06<00:02, 18.57it/s]\u001b[A\n",
            " 71%|███████   | 126/178 [00:06<00:02, 18.54it/s]\u001b[A\n",
            " 72%|███████▏  | 128/178 [00:06<00:02, 18.35it/s]\u001b[A\n",
            " 73%|███████▎  | 130/178 [00:07<00:02, 18.35it/s]\u001b[A\n",
            " 74%|███████▍  | 132/178 [00:07<00:02, 18.35it/s]\u001b[A\n",
            " 75%|███████▌  | 134/178 [00:07<00:02, 18.37it/s]\u001b[A\n",
            " 76%|███████▋  | 136/178 [00:07<00:02, 18.42it/s]\u001b[A\n",
            " 78%|███████▊  | 138/178 [00:07<00:02, 18.43it/s]\u001b[A\n",
            " 79%|███████▊  | 140/178 [00:07<00:02, 18.47it/s]\u001b[A\n",
            " 80%|███████▉  | 142/178 [00:07<00:01, 18.50it/s]\u001b[A\n",
            " 81%|████████  | 144/178 [00:07<00:01, 18.48it/s]\u001b[A\n",
            " 82%|████████▏ | 146/178 [00:07<00:01, 18.45it/s]\u001b[A\n",
            " 83%|████████▎ | 148/178 [00:08<00:01, 18.54it/s]\u001b[A\n",
            " 84%|████████▍ | 150/178 [00:08<00:01, 18.28it/s]\u001b[A\n",
            " 85%|████████▌ | 152/178 [00:08<00:01, 18.33it/s]\u001b[A\n",
            " 87%|████████▋ | 154/178 [00:08<00:01, 18.40it/s]\u001b[A\n",
            " 88%|████████▊ | 156/178 [00:08<00:01, 18.38it/s]\u001b[A\n",
            " 89%|████████▉ | 158/178 [00:08<00:01, 18.42it/s]\u001b[A\n",
            " 90%|████████▉ | 160/178 [00:08<00:00, 18.45it/s]\u001b[A\n",
            " 91%|█████████ | 162/178 [00:08<00:00, 18.52it/s]\u001b[A\n",
            " 92%|█████████▏| 164/178 [00:08<00:00, 18.53it/s]\u001b[A\n",
            " 93%|█████████▎| 166/178 [00:08<00:00, 18.61it/s]\u001b[A\n",
            " 94%|█████████▍| 168/178 [00:09<00:00, 18.54it/s]\u001b[A\n",
            " 96%|█████████▌| 170/178 [00:09<00:00, 18.56it/s]\u001b[A\n",
            " 97%|█████████▋| 172/178 [00:09<00:00, 18.57it/s]\u001b[A\n",
            " 98%|█████████▊| 174/178 [00:09<00:00, 18.61it/s]\u001b[A\n",
            "100%|██████████| 178/178 [00:09<00:00, 18.48it/s]\n",
            " 86%|████████▌ | 1218/1422 [04:09<10:20,  3.04s/it]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            " 86%|████████▌ | 1219/1422 [04:09<07:20,  2.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 0.3163 Val acc: 0.9043 Val f1: 0.9043 AUC: 0.5308\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 1420/1422 [04:39<00:00,  5.76it/s]\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 2/178 [00:00<00:09, 18.54it/s]\u001b[A\n",
            "  2%|▏         | 4/178 [00:00<00:09, 18.49it/s]\u001b[A\n",
            "  3%|▎         | 6/178 [00:00<00:09, 18.43it/s]\u001b[A\n",
            "  4%|▍         | 8/178 [00:00<00:09, 18.18it/s]\u001b[A\n",
            "  6%|▌         | 10/178 [00:00<00:09, 18.25it/s]\u001b[A\n",
            "  7%|▋         | 12/178 [00:00<00:09, 18.23it/s]\u001b[A\n",
            "  8%|▊         | 14/178 [00:00<00:08, 18.26it/s]\u001b[A\n",
            "  9%|▉         | 16/178 [00:00<00:08, 18.14it/s]\u001b[A\n",
            " 10%|█         | 18/178 [00:00<00:08, 18.19it/s]\u001b[A\n",
            " 11%|█         | 20/178 [00:01<00:08, 18.30it/s]\u001b[A\n",
            " 12%|█▏        | 22/178 [00:01<00:08, 18.37it/s]\u001b[A\n",
            " 13%|█▎        | 24/178 [00:01<00:08, 18.25it/s]\u001b[A\n",
            " 15%|█▍        | 26/178 [00:01<00:08, 18.32it/s]\u001b[A\n",
            " 16%|█▌        | 28/178 [00:01<00:08, 18.20it/s]\u001b[A\n",
            " 17%|█▋        | 30/178 [00:01<00:08, 18.23it/s]\u001b[A\n",
            " 18%|█▊        | 32/178 [00:01<00:07, 18.27it/s]\u001b[A\n",
            " 19%|█▉        | 34/178 [00:01<00:07, 18.21it/s]\u001b[A\n",
            " 20%|██        | 36/178 [00:01<00:07, 18.30it/s]\u001b[A\n",
            " 21%|██▏       | 38/178 [00:02<00:07, 18.36it/s]\u001b[A\n",
            " 22%|██▏       | 40/178 [00:02<00:07, 18.42it/s]\u001b[A\n",
            " 24%|██▎       | 42/178 [00:02<00:07, 18.28it/s]\u001b[A\n",
            " 25%|██▍       | 44/178 [00:02<00:07, 18.10it/s]\u001b[A\n",
            " 26%|██▌       | 46/178 [00:02<00:07, 18.16it/s]\u001b[A\n",
            " 27%|██▋       | 48/178 [00:02<00:07, 18.17it/s]\u001b[A\n",
            " 28%|██▊       | 50/178 [00:02<00:07, 18.15it/s]\u001b[A\n",
            " 29%|██▉       | 52/178 [00:02<00:06, 18.26it/s]\u001b[A\n",
            " 30%|███       | 54/178 [00:02<00:06, 18.32it/s]\u001b[A\n",
            " 31%|███▏      | 56/178 [00:03<00:06, 18.32it/s]\u001b[A\n",
            " 33%|███▎      | 58/178 [00:03<00:06, 18.35it/s]\u001b[A\n",
            " 34%|███▎      | 60/178 [00:03<00:06, 18.31it/s]\u001b[A\n",
            " 35%|███▍      | 62/178 [00:03<00:06, 18.32it/s]\u001b[A\n",
            " 36%|███▌      | 64/178 [00:03<00:06, 18.33it/s]\u001b[A\n",
            " 37%|███▋      | 66/178 [00:03<00:06, 18.28it/s]\u001b[A\n",
            " 38%|███▊      | 68/178 [00:03<00:06, 18.32it/s]\u001b[A\n",
            " 39%|███▉      | 70/178 [00:03<00:05, 18.25it/s]\u001b[A\n",
            " 40%|████      | 72/178 [00:03<00:05, 18.23it/s]\u001b[A\n",
            " 42%|████▏     | 74/178 [00:04<00:05, 18.25it/s]\u001b[A\n",
            " 43%|████▎     | 76/178 [00:04<00:05, 18.19it/s]\u001b[A\n",
            " 44%|████▍     | 78/178 [00:04<00:05, 18.24it/s]\u001b[A\n",
            " 45%|████▍     | 80/178 [00:04<00:05, 18.34it/s]\u001b[A\n",
            " 46%|████▌     | 82/178 [00:04<00:05, 18.26it/s]\u001b[A\n",
            " 47%|████▋     | 84/178 [00:04<00:05, 18.32it/s]\u001b[A\n",
            " 48%|████▊     | 86/178 [00:04<00:05, 18.38it/s]\u001b[A\n",
            " 49%|████▉     | 88/178 [00:04<00:04, 18.30it/s]\u001b[A\n",
            " 51%|█████     | 90/178 [00:04<00:04, 18.38it/s]\u001b[A\n",
            " 52%|█████▏    | 92/178 [00:05<00:04, 18.38it/s]\u001b[A\n",
            " 53%|█████▎    | 94/178 [00:05<00:04, 18.32it/s]\u001b[A\n",
            " 54%|█████▍    | 96/178 [00:05<00:04, 18.25it/s]\u001b[A\n",
            " 55%|█████▌    | 98/178 [00:05<00:04, 18.28it/s]\u001b[A\n",
            " 56%|█████▌    | 100/178 [00:05<00:04, 18.32it/s]\u001b[A\n",
            " 57%|█████▋    | 102/178 [00:05<00:04, 18.32it/s]\u001b[A\n",
            " 58%|█████▊    | 104/178 [00:05<00:04, 18.35it/s]\u001b[A\n",
            " 60%|█████▉    | 106/178 [00:05<00:03, 18.28it/s]\u001b[A\n",
            " 61%|██████    | 108/178 [00:05<00:03, 18.37it/s]\u001b[A\n",
            " 62%|██████▏   | 110/178 [00:06<00:03, 18.35it/s]\u001b[A\n",
            " 63%|██████▎   | 112/178 [00:06<00:03, 18.36it/s]\u001b[A\n",
            " 64%|██████▍   | 114/178 [00:06<00:03, 18.31it/s]\u001b[A\n",
            " 65%|██████▌   | 116/178 [00:06<00:03, 18.26it/s]\u001b[A\n",
            " 66%|██████▋   | 118/178 [00:06<00:03, 18.04it/s]\u001b[A\n",
            " 67%|██████▋   | 120/178 [00:06<00:03, 18.14it/s]\u001b[A\n",
            " 69%|██████▊   | 122/178 [00:06<00:03, 18.14it/s]\u001b[A\n",
            " 70%|██████▉   | 124/178 [00:06<00:02, 18.26it/s]\u001b[A\n",
            " 71%|███████   | 126/178 [00:06<00:02, 18.29it/s]\u001b[A\n",
            " 72%|███████▏  | 128/178 [00:07<00:02, 18.30it/s]\u001b[A\n",
            " 73%|███████▎  | 130/178 [00:07<00:02, 18.34it/s]\u001b[A\n",
            " 74%|███████▍  | 132/178 [00:07<00:02, 18.32it/s]\u001b[A\n",
            " 75%|███████▌  | 134/178 [00:07<00:02, 18.22it/s]\u001b[A\n",
            " 76%|███████▋  | 136/178 [00:07<00:02, 18.13it/s]\u001b[A\n",
            " 78%|███████▊  | 138/178 [00:07<00:02, 18.03it/s]\u001b[A\n",
            " 79%|███████▊  | 140/178 [00:07<00:02, 18.15it/s]\u001b[A\n",
            " 80%|███████▉  | 142/178 [00:07<00:01, 18.13it/s]\u001b[A\n",
            " 81%|████████  | 144/178 [00:07<00:01, 18.13it/s]\u001b[A\n",
            " 82%|████████▏ | 146/178 [00:07<00:01, 18.13it/s]\u001b[A\n",
            " 83%|████████▎ | 148/178 [00:08<00:01, 18.19it/s]\u001b[A\n",
            " 84%|████████▍ | 150/178 [00:08<00:01, 18.27it/s]\u001b[A\n",
            " 85%|████████▌ | 152/178 [00:08<00:01, 18.24it/s]\u001b[A\n",
            " 87%|████████▋ | 154/178 [00:08<00:01, 18.14it/s]\u001b[A\n",
            " 88%|████████▊ | 156/178 [00:08<00:01, 18.12it/s]\u001b[A\n",
            " 89%|████████▉ | 158/178 [00:08<00:01, 18.17it/s]\u001b[A\n",
            " 90%|████████▉ | 160/178 [00:08<00:00, 18.18it/s]\u001b[A\n",
            " 91%|█████████ | 162/178 [00:08<00:00, 18.28it/s]\u001b[A\n",
            " 92%|█████████▏| 164/178 [00:08<00:00, 18.42it/s]\u001b[A\n",
            " 93%|█████████▎| 166/178 [00:09<00:00, 18.38it/s]\u001b[A\n",
            " 94%|█████████▍| 168/178 [00:09<00:00, 18.39it/s]\u001b[A\n",
            " 96%|█████████▌| 170/178 [00:09<00:00, 18.35it/s]\u001b[A\n",
            " 97%|█████████▋| 172/178 [00:09<00:00, 18.32it/s]\u001b[A\n",
            " 98%|█████████▊| 174/178 [00:09<00:00, 18.32it/s]\u001b[A\n",
            "100%|██████████| 178/178 [00:09<00:00, 18.30it/s]\n",
            "100%|█████████▉| 1421/1422 [04:49<00:03,  3.09s/it]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100%|██████████| 1422/1422 [04:49<00:00,  4.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 0.3157 Val acc: 0.9043 Val f1: 0.9043 AUC: 0.6210\n",
            "\n",
            "\n",
            "Epoch 2 from 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 202/1422 [00:30<03:14,  6.26it/s]\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 2/178 [00:00<00:09, 19.20it/s]\u001b[A\n",
            "  2%|▏         | 4/178 [00:00<00:09, 18.82it/s]\u001b[A\n",
            "  3%|▎         | 6/178 [00:00<00:09, 18.71it/s]\u001b[A\n",
            "  4%|▍         | 8/178 [00:00<00:09, 18.74it/s]\u001b[A\n",
            "  6%|▌         | 10/178 [00:00<00:09, 18.64it/s]\u001b[A\n",
            "  7%|▋         | 12/178 [00:00<00:08, 18.63it/s]\u001b[A\n",
            "  8%|▊         | 14/178 [00:00<00:08, 18.33it/s]\u001b[A\n",
            "  9%|▉         | 16/178 [00:00<00:08, 18.14it/s]\u001b[A\n",
            " 10%|█         | 18/178 [00:00<00:08, 18.08it/s]\u001b[A\n",
            " 11%|█         | 20/178 [00:01<00:08, 18.19it/s]\u001b[A\n",
            " 12%|█▏        | 22/178 [00:01<00:08, 18.30it/s]\u001b[A\n",
            " 13%|█▎        | 24/178 [00:01<00:08, 18.41it/s]\u001b[A\n",
            " 15%|█▍        | 26/178 [00:01<00:08, 18.39it/s]\u001b[A\n",
            " 16%|█▌        | 28/178 [00:01<00:08, 18.34it/s]\u001b[A\n",
            " 17%|█▋        | 30/178 [00:01<00:08, 18.47it/s]\u001b[A\n",
            " 18%|█▊        | 32/178 [00:01<00:07, 18.30it/s]\u001b[A\n",
            " 19%|█▉        | 34/178 [00:01<00:07, 18.18it/s]\u001b[A\n",
            " 20%|██        | 36/178 [00:01<00:07, 18.24it/s]\u001b[A\n",
            " 21%|██▏       | 38/178 [00:02<00:07, 18.37it/s]\u001b[A\n",
            " 22%|██▏       | 40/178 [00:02<00:07, 18.37it/s]\u001b[A\n",
            " 24%|██▎       | 42/178 [00:02<00:07, 18.34it/s]\u001b[A\n",
            " 25%|██▍       | 44/178 [00:02<00:07, 18.22it/s]\u001b[A\n",
            " 26%|██▌       | 46/178 [00:02<00:07, 18.31it/s]\u001b[A\n",
            " 27%|██▋       | 48/178 [00:02<00:07, 18.45it/s]\u001b[A\n",
            " 28%|██▊       | 50/178 [00:02<00:06, 18.47it/s]\u001b[A\n",
            " 29%|██▉       | 52/178 [00:02<00:06, 18.40it/s]\u001b[A\n",
            " 30%|███       | 54/178 [00:02<00:06, 18.48it/s]\u001b[A\n",
            " 31%|███▏      | 56/178 [00:03<00:06, 18.50it/s]\u001b[A\n",
            " 33%|███▎      | 58/178 [00:03<00:06, 18.55it/s]\u001b[A\n",
            " 34%|███▎      | 60/178 [00:03<00:06, 18.52it/s]\u001b[A\n",
            " 35%|███▍      | 62/178 [00:03<00:06, 18.57it/s]\u001b[A\n",
            " 36%|███▌      | 64/178 [00:03<00:06, 18.57it/s]\u001b[A\n",
            " 37%|███▋      | 66/178 [00:03<00:06, 18.63it/s]\u001b[A\n",
            " 38%|███▊      | 68/178 [00:03<00:05, 18.65it/s]\u001b[A\n",
            " 39%|███▉      | 70/178 [00:03<00:05, 18.75it/s]\u001b[A\n",
            " 40%|████      | 72/178 [00:03<00:05, 18.67it/s]\u001b[A\n",
            " 42%|████▏     | 74/178 [00:04<00:05, 18.62it/s]\u001b[A\n",
            " 43%|████▎     | 76/178 [00:04<00:05, 18.55it/s]\u001b[A\n",
            " 44%|████▍     | 78/178 [00:04<00:05, 18.68it/s]\u001b[A\n",
            " 45%|████▍     | 80/178 [00:04<00:05, 18.69it/s]\u001b[A\n",
            " 46%|████▌     | 82/178 [00:04<00:05, 18.69it/s]\u001b[A\n",
            " 47%|████▋     | 84/178 [00:04<00:05, 18.62it/s]\u001b[A\n",
            " 48%|████▊     | 86/178 [00:04<00:04, 18.59it/s]\u001b[A\n",
            " 49%|████▉     | 88/178 [00:04<00:04, 18.59it/s]\u001b[A\n",
            " 51%|█████     | 90/178 [00:04<00:04, 18.49it/s]\u001b[A\n",
            " 52%|█████▏    | 92/178 [00:04<00:04, 18.46it/s]\u001b[A\n",
            " 53%|█████▎    | 94/178 [00:05<00:04, 18.50it/s]\u001b[A\n",
            " 54%|█████▍    | 96/178 [00:05<00:04, 18.48it/s]\u001b[A\n",
            " 55%|█████▌    | 98/178 [00:05<00:04, 18.62it/s]\u001b[A\n",
            " 56%|█████▌    | 100/178 [00:05<00:04, 18.58it/s]\u001b[A\n",
            " 57%|█████▋    | 102/178 [00:05<00:04, 18.53it/s]\u001b[A\n",
            " 58%|█████▊    | 104/178 [00:05<00:03, 18.56it/s]\u001b[A\n",
            " 60%|█████▉    | 106/178 [00:05<00:03, 18.57it/s]\u001b[A\n",
            " 61%|██████    | 108/178 [00:05<00:03, 18.48it/s]\u001b[A\n",
            " 62%|██████▏   | 110/178 [00:05<00:03, 18.44it/s]\u001b[A\n",
            " 63%|██████▎   | 112/178 [00:06<00:03, 18.47it/s]\u001b[A\n",
            " 64%|██████▍   | 114/178 [00:06<00:03, 18.51it/s]\u001b[A\n",
            " 65%|██████▌   | 116/178 [00:06<00:03, 18.55it/s]\u001b[A\n",
            " 66%|██████▋   | 118/178 [00:06<00:03, 18.53it/s]\u001b[A\n",
            " 67%|██████▋   | 120/178 [00:06<00:03, 18.54it/s]\u001b[A\n",
            " 69%|██████▊   | 122/178 [00:06<00:03, 18.53it/s]\u001b[A\n",
            " 70%|██████▉   | 124/178 [00:06<00:02, 18.51it/s]\u001b[A\n",
            " 71%|███████   | 126/178 [00:06<00:02, 18.39it/s]\u001b[A\n",
            " 72%|███████▏  | 128/178 [00:06<00:02, 18.46it/s]\u001b[A\n",
            " 73%|███████▎  | 130/178 [00:07<00:02, 18.54it/s]\u001b[A\n",
            " 74%|███████▍  | 132/178 [00:07<00:02, 18.62it/s]\u001b[A\n",
            " 75%|███████▌  | 134/178 [00:07<00:02, 18.58it/s]\u001b[A\n",
            " 76%|███████▋  | 136/178 [00:07<00:02, 18.63it/s]\u001b[A\n",
            " 78%|███████▊  | 138/178 [00:07<00:02, 18.41it/s]\u001b[A\n",
            " 79%|███████▊  | 140/178 [00:07<00:02, 18.47it/s]\u001b[A\n",
            " 80%|███████▉  | 142/178 [00:07<00:01, 18.32it/s]\u001b[A\n",
            " 81%|████████  | 144/178 [00:07<00:01, 18.26it/s]\u001b[A\n",
            " 82%|████████▏ | 146/178 [00:07<00:01, 18.29it/s]\u001b[A\n",
            " 83%|████████▎ | 148/178 [00:08<00:01, 18.37it/s]\u001b[A\n",
            " 84%|████████▍ | 150/178 [00:08<00:01, 18.44it/s]\u001b[A\n",
            " 85%|████████▌ | 152/178 [00:08<00:01, 18.37it/s]\u001b[A\n",
            " 87%|████████▋ | 154/178 [00:08<00:01, 18.48it/s]\u001b[A\n",
            " 88%|████████▊ | 156/178 [00:08<00:01, 18.44it/s]\u001b[A\n",
            " 89%|████████▉ | 158/178 [00:08<00:01, 18.40it/s]\u001b[A\n",
            " 90%|████████▉ | 160/178 [00:08<00:00, 18.48it/s]\u001b[A\n",
            " 91%|█████████ | 162/178 [00:08<00:00, 18.52it/s]\u001b[A\n",
            " 92%|█████████▏| 164/178 [00:08<00:00, 18.50it/s]\u001b[A\n",
            " 93%|█████████▎| 166/178 [00:08<00:00, 18.09it/s]\u001b[A\n",
            " 94%|█████████▍| 168/178 [00:09<00:00, 18.10it/s]\u001b[A\n",
            " 96%|█████████▌| 170/178 [00:09<00:00, 18.29it/s]\u001b[A\n",
            " 97%|█████████▋| 172/178 [00:09<00:00, 18.39it/s]\u001b[A\n",
            " 98%|█████████▊| 174/178 [00:09<00:00, 18.47it/s]\u001b[A\n",
            "100%|██████████| 178/178 [00:09<00:00, 18.50it/s]\n",
            " 14%|█▍        | 203/1422 [00:40<1:01:54,  3.05s/it]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            " 14%|█▍        | 204/1422 [00:40<44:12,  2.18s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 0.3170 Val acc: 0.9043 Val f1: 0.9043 AUC: 0.6314\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 405/1422 [01:10<02:34,  6.59it/s]\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 2/178 [00:00<00:09, 19.20it/s]\u001b[A\n",
            "  2%|▏         | 4/178 [00:00<00:09, 18.71it/s]\u001b[A\n",
            "  3%|▎         | 6/178 [00:00<00:09, 18.47it/s]\u001b[A\n",
            "  4%|▍         | 8/178 [00:00<00:09, 18.32it/s]\u001b[A\n",
            "  6%|▌         | 10/178 [00:00<00:09, 18.10it/s]\u001b[A\n",
            "  7%|▋         | 12/178 [00:00<00:09, 18.10it/s]\u001b[A\n",
            "  8%|▊         | 14/178 [00:00<00:09, 18.13it/s]\u001b[A\n",
            "  9%|▉         | 16/178 [00:00<00:08, 18.28it/s]\u001b[A\n",
            " 10%|█         | 18/178 [00:00<00:08, 18.37it/s]\u001b[A\n",
            " 11%|█         | 20/178 [00:01<00:08, 18.45it/s]\u001b[A\n",
            " 12%|█▏        | 22/178 [00:01<00:08, 18.45it/s]\u001b[A\n",
            " 13%|█▎        | 24/178 [00:01<00:08, 18.44it/s]\u001b[A\n",
            " 15%|█▍        | 26/178 [00:01<00:08, 18.41it/s]\u001b[A\n",
            " 16%|█▌        | 28/178 [00:01<00:08, 18.38it/s]\u001b[A\n",
            " 17%|█▋        | 30/178 [00:01<00:08, 18.26it/s]\u001b[A\n",
            " 18%|█▊        | 32/178 [00:01<00:08, 18.19it/s]\u001b[A\n",
            " 19%|█▉        | 34/178 [00:01<00:07, 18.21it/s]\u001b[A\n",
            " 20%|██        | 36/178 [00:01<00:07, 18.23it/s]\u001b[A\n",
            " 21%|██▏       | 38/178 [00:02<00:07, 18.18it/s]\u001b[A\n",
            " 22%|██▏       | 40/178 [00:02<00:07, 18.09it/s]\u001b[A\n",
            " 24%|██▎       | 42/178 [00:02<00:07, 18.16it/s]\u001b[A\n",
            " 25%|██▍       | 44/178 [00:02<00:07, 18.28it/s]\u001b[A\n",
            " 26%|██▌       | 46/178 [00:02<00:07, 18.32it/s]\u001b[A\n",
            " 27%|██▋       | 48/178 [00:02<00:07, 18.27it/s]\u001b[A\n",
            " 28%|██▊       | 50/178 [00:02<00:07, 18.25it/s]\u001b[A\n",
            " 29%|██▉       | 52/178 [00:02<00:06, 18.31it/s]\u001b[A\n",
            " 30%|███       | 54/178 [00:02<00:06, 18.27it/s]\u001b[A\n",
            " 31%|███▏      | 56/178 [00:03<00:06, 18.38it/s]\u001b[A\n",
            " 33%|███▎      | 58/178 [00:03<00:06, 18.45it/s]\u001b[A\n",
            " 34%|███▎      | 60/178 [00:03<00:06, 18.45it/s]\u001b[A\n",
            " 35%|███▍      | 62/178 [00:03<00:06, 18.53it/s]\u001b[A\n",
            " 36%|███▌      | 64/178 [00:03<00:06, 18.32it/s]\u001b[A\n",
            " 37%|███▋      | 66/178 [00:03<00:06, 18.42it/s]\u001b[A\n",
            " 38%|███▊      | 68/178 [00:03<00:05, 18.37it/s]\u001b[A\n",
            " 39%|███▉      | 70/178 [00:03<00:05, 18.45it/s]\u001b[A\n",
            " 40%|████      | 72/178 [00:03<00:05, 18.46it/s]\u001b[A\n",
            " 42%|████▏     | 74/178 [00:04<00:05, 18.44it/s]\u001b[A\n",
            " 43%|████▎     | 76/178 [00:04<00:05, 18.26it/s]\u001b[A\n",
            " 44%|████▍     | 78/178 [00:04<00:05, 18.33it/s]\u001b[A\n",
            " 45%|████▍     | 80/178 [00:04<00:05, 18.34it/s]\u001b[A\n",
            " 46%|████▌     | 82/178 [00:04<00:05, 18.39it/s]\u001b[A\n",
            " 47%|████▋     | 84/178 [00:04<00:05, 18.50it/s]\u001b[A\n",
            " 48%|████▊     | 86/178 [00:04<00:04, 18.47it/s]\u001b[A\n",
            " 49%|████▉     | 88/178 [00:04<00:04, 18.39it/s]\u001b[A\n",
            " 51%|█████     | 90/178 [00:04<00:04, 18.47it/s]\u001b[A\n",
            " 52%|█████▏    | 92/178 [00:05<00:04, 18.54it/s]\u001b[A\n",
            " 53%|█████▎    | 94/178 [00:05<00:04, 18.54it/s]\u001b[A\n",
            " 54%|█████▍    | 96/178 [00:05<00:04, 18.48it/s]\u001b[A\n",
            " 55%|█████▌    | 98/178 [00:05<00:04, 18.45it/s]\u001b[A\n",
            " 56%|█████▌    | 100/178 [00:05<00:04, 18.43it/s]\u001b[A\n",
            " 57%|█████▋    | 102/178 [00:05<00:04, 18.38it/s]\u001b[A\n",
            " 58%|█████▊    | 104/178 [00:05<00:04, 18.15it/s]\u001b[A\n",
            " 60%|█████▉    | 106/178 [00:05<00:03, 18.24it/s]\u001b[A\n",
            " 61%|██████    | 108/178 [00:05<00:03, 18.25it/s]\u001b[A\n",
            " 62%|██████▏   | 110/178 [00:05<00:03, 18.26it/s]\u001b[A\n",
            " 63%|██████▎   | 112/178 [00:06<00:03, 18.31it/s]\u001b[A\n",
            " 64%|██████▍   | 114/178 [00:06<00:03, 18.21it/s]\u001b[A\n",
            " 65%|██████▌   | 116/178 [00:06<00:03, 18.20it/s]\u001b[A\n",
            " 66%|██████▋   | 118/178 [00:06<00:03, 18.21it/s]\u001b[A\n",
            " 67%|██████▋   | 120/178 [00:06<00:03, 18.23it/s]\u001b[A\n",
            " 69%|██████▊   | 122/178 [00:06<00:03, 18.39it/s]\u001b[A\n",
            " 70%|██████▉   | 124/178 [00:06<00:02, 18.35it/s]\u001b[A\n",
            " 71%|███████   | 126/178 [00:06<00:02, 18.43it/s]\u001b[A\n",
            " 72%|███████▏  | 128/178 [00:06<00:02, 18.47it/s]\u001b[A\n",
            " 73%|███████▎  | 130/178 [00:07<00:02, 18.48it/s]\u001b[A\n",
            " 74%|███████▍  | 132/178 [00:07<00:02, 18.53it/s]\u001b[A\n",
            " 75%|███████▌  | 134/178 [00:07<00:02, 18.53it/s]\u001b[A\n",
            " 76%|███████▋  | 136/178 [00:07<00:02, 18.50it/s]\u001b[A\n",
            " 78%|███████▊  | 138/178 [00:07<00:02, 18.39it/s]\u001b[A\n",
            " 79%|███████▊  | 140/178 [00:07<00:02, 18.39it/s]\u001b[A\n",
            " 80%|███████▉  | 142/178 [00:07<00:01, 18.39it/s]\u001b[A\n",
            " 81%|████████  | 144/178 [00:07<00:01, 18.38it/s]\u001b[A\n",
            " 82%|████████▏ | 146/178 [00:07<00:01, 18.39it/s]\u001b[A\n",
            " 83%|████████▎ | 148/178 [00:08<00:01, 18.35it/s]\u001b[A\n",
            " 84%|████████▍ | 150/178 [00:08<00:01, 18.40it/s]\u001b[A\n",
            " 85%|████████▌ | 152/178 [00:08<00:01, 18.48it/s]\u001b[A\n",
            " 87%|████████▋ | 154/178 [00:08<00:01, 18.43it/s]\u001b[A\n",
            " 88%|████████▊ | 156/178 [00:08<00:01, 18.47it/s]\u001b[A\n",
            " 89%|████████▉ | 158/178 [00:08<00:01, 18.42it/s]\u001b[A\n",
            " 90%|████████▉ | 160/178 [00:08<00:00, 18.43it/s]\u001b[A\n",
            " 91%|█████████ | 162/178 [00:08<00:00, 18.33it/s]\u001b[A\n",
            " 92%|█████████▏| 164/178 [00:08<00:00, 18.43it/s]\u001b[A\n",
            " 93%|█████████▎| 166/178 [00:09<00:00, 18.38it/s]\u001b[A\n",
            " 94%|█████████▍| 168/178 [00:09<00:00, 18.48it/s]\u001b[A\n",
            " 96%|█████████▌| 170/178 [00:09<00:00, 18.48it/s]\u001b[A\n",
            " 97%|█████████▋| 172/178 [00:09<00:00, 18.50it/s]\u001b[A\n",
            " 98%|█████████▊| 174/178 [00:09<00:00, 18.49it/s]\u001b[A\n",
            "100%|██████████| 178/178 [00:09<00:00, 18.40it/s]\n",
            " 29%|██▊       | 406/1422 [01:20<51:44,  3.06s/it]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            " 29%|██▊       | 407/1422 [01:20<36:56,  2.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 0.3177 Val acc: 0.9043 Val f1: 0.9043 AUC: 0.6171\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 608/1422 [01:51<02:00,  6.77it/s]\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 2/178 [00:00<00:09, 19.07it/s]\u001b[A\n",
            "  2%|▏         | 4/178 [00:00<00:09, 18.74it/s]\u001b[A\n",
            "  3%|▎         | 6/178 [00:00<00:09, 18.66it/s]\u001b[A\n",
            "  4%|▍         | 8/178 [00:00<00:09, 18.53it/s]\u001b[A\n",
            "  6%|▌         | 10/178 [00:00<00:09, 18.49it/s]\u001b[A\n",
            "  7%|▋         | 12/178 [00:00<00:08, 18.60it/s]\u001b[A\n",
            "  8%|▊         | 14/178 [00:00<00:08, 18.64it/s]\u001b[A\n",
            "  9%|▉         | 16/178 [00:00<00:08, 18.41it/s]\u001b[A\n",
            " 10%|█         | 18/178 [00:00<00:08, 18.48it/s]\u001b[A\n",
            " 11%|█         | 20/178 [00:01<00:08, 18.51it/s]\u001b[A\n",
            " 12%|█▏        | 22/178 [00:01<00:08, 18.40it/s]\u001b[A\n",
            " 13%|█▎        | 24/178 [00:01<00:08, 18.49it/s]\u001b[A\n",
            " 15%|█▍        | 26/178 [00:01<00:08, 18.53it/s]\u001b[A\n",
            " 16%|█▌        | 28/178 [00:01<00:08, 18.61it/s]\u001b[A\n",
            " 17%|█▋        | 30/178 [00:01<00:07, 18.51it/s]\u001b[A\n",
            " 18%|█▊        | 32/178 [00:01<00:07, 18.43it/s]\u001b[A\n",
            " 19%|█▉        | 34/178 [00:01<00:07, 18.51it/s]\u001b[A\n",
            " 20%|██        | 36/178 [00:01<00:07, 18.52it/s]\u001b[A\n",
            " 21%|██▏       | 38/178 [00:02<00:07, 18.49it/s]\u001b[A\n",
            " 22%|██▏       | 40/178 [00:02<00:07, 18.47it/s]\u001b[A\n",
            " 24%|██▎       | 42/178 [00:02<00:07, 18.56it/s]\u001b[A\n",
            " 25%|██▍       | 44/178 [00:02<00:07, 18.59it/s]\u001b[A\n",
            " 26%|██▌       | 46/178 [00:02<00:07, 18.46it/s]\u001b[A\n",
            " 27%|██▋       | 48/178 [00:02<00:07, 18.51it/s]\u001b[A\n",
            " 28%|██▊       | 50/178 [00:02<00:06, 18.49it/s]\u001b[A\n",
            " 29%|██▉       | 52/178 [00:02<00:06, 18.50it/s]\u001b[A\n",
            " 30%|███       | 54/178 [00:02<00:06, 18.51it/s]\u001b[A\n",
            " 31%|███▏      | 56/178 [00:03<00:06, 18.45it/s]\u001b[A\n",
            " 33%|███▎      | 58/178 [00:03<00:06, 18.36it/s]\u001b[A\n",
            " 34%|███▎      | 60/178 [00:03<00:06, 18.23it/s]\u001b[A\n",
            " 35%|███▍      | 62/178 [00:03<00:06, 18.23it/s]\u001b[A\n",
            " 36%|███▌      | 64/178 [00:03<00:06, 18.33it/s]\u001b[A\n",
            " 37%|███▋      | 66/178 [00:03<00:06, 18.38it/s]\u001b[A\n",
            " 38%|███▊      | 68/178 [00:03<00:05, 18.34it/s]\u001b[A\n",
            " 39%|███▉      | 70/178 [00:03<00:05, 18.47it/s]\u001b[A\n",
            " 40%|████      | 72/178 [00:03<00:05, 18.47it/s]\u001b[A\n",
            " 42%|████▏     | 74/178 [00:04<00:05, 18.46it/s]\u001b[A\n",
            " 43%|████▎     | 76/178 [00:04<00:05, 18.39it/s]\u001b[A\n",
            " 44%|████▍     | 78/178 [00:04<00:05, 18.41it/s]\u001b[A\n",
            " 45%|████▍     | 80/178 [00:04<00:05, 18.40it/s]\u001b[A\n",
            " 46%|████▌     | 82/178 [00:04<00:05, 18.18it/s]\u001b[A\n",
            " 47%|████▋     | 84/178 [00:04<00:05, 18.30it/s]\u001b[A\n",
            " 48%|████▊     | 86/178 [00:04<00:05, 18.38it/s]\u001b[A\n",
            " 49%|████▉     | 88/178 [00:04<00:04, 18.48it/s]\u001b[A\n",
            " 51%|█████     | 90/178 [00:04<00:04, 18.51it/s]\u001b[A\n",
            " 52%|█████▏    | 92/178 [00:04<00:04, 18.44it/s]\u001b[A\n",
            " 53%|█████▎    | 94/178 [00:05<00:04, 18.37it/s]\u001b[A\n",
            " 54%|█████▍    | 96/178 [00:05<00:04, 18.49it/s]\u001b[A\n",
            " 55%|█████▌    | 98/178 [00:05<00:04, 18.47it/s]\u001b[A\n",
            " 56%|█████▌    | 100/178 [00:05<00:04, 18.49it/s]\u001b[A\n",
            " 57%|█████▋    | 102/178 [00:05<00:04, 18.47it/s]\u001b[A\n",
            " 58%|█████▊    | 104/178 [00:05<00:04, 18.41it/s]\u001b[A\n",
            " 60%|█████▉    | 106/178 [00:05<00:03, 18.44it/s]\u001b[A\n",
            " 61%|██████    | 108/178 [00:05<00:03, 18.42it/s]\u001b[A\n",
            " 62%|██████▏   | 110/178 [00:05<00:03, 18.49it/s]\u001b[A\n",
            " 63%|██████▎   | 112/178 [00:06<00:03, 18.46it/s]\u001b[A\n",
            " 64%|██████▍   | 114/178 [00:06<00:03, 18.52it/s]\u001b[A\n",
            " 65%|██████▌   | 116/178 [00:06<00:03, 18.57it/s]\u001b[A\n",
            " 66%|██████▋   | 118/178 [00:06<00:03, 18.38it/s]\u001b[A\n",
            " 67%|██████▋   | 120/178 [00:06<00:03, 18.42it/s]\u001b[A\n",
            " 69%|██████▊   | 122/178 [00:06<00:03, 18.44it/s]\u001b[A\n",
            " 70%|██████▉   | 124/178 [00:06<00:02, 18.42it/s]\u001b[A\n",
            " 71%|███████   | 126/178 [00:06<00:02, 18.49it/s]\u001b[A\n",
            " 72%|███████▏  | 128/178 [00:06<00:02, 18.58it/s]\u001b[A\n",
            " 73%|███████▎  | 130/178 [00:07<00:02, 18.38it/s]\u001b[A\n",
            " 74%|███████▍  | 132/178 [00:07<00:02, 18.35it/s]\u001b[A\n",
            " 75%|███████▌  | 134/178 [00:07<00:02, 18.49it/s]\u001b[A\n",
            " 76%|███████▋  | 136/178 [00:07<00:02, 18.59it/s]\u001b[A\n",
            " 78%|███████▊  | 138/178 [00:07<00:02, 18.64it/s]\u001b[A\n",
            " 79%|███████▊  | 140/178 [00:07<00:02, 18.67it/s]\u001b[A\n",
            " 80%|███████▉  | 142/178 [00:07<00:01, 18.69it/s]\u001b[A\n",
            " 81%|████████  | 144/178 [00:07<00:01, 18.61it/s]\u001b[A\n",
            " 82%|████████▏ | 146/178 [00:07<00:01, 18.59it/s]\u001b[A\n",
            " 83%|████████▎ | 148/178 [00:08<00:01, 18.63it/s]\u001b[A\n",
            " 84%|████████▍ | 150/178 [00:08<00:01, 18.53it/s]\u001b[A\n",
            " 85%|████████▌ | 152/178 [00:08<00:01, 18.59it/s]\u001b[A\n",
            " 87%|████████▋ | 154/178 [00:08<00:01, 18.61it/s]\u001b[A\n",
            " 88%|████████▊ | 156/178 [00:08<00:01, 18.60it/s]\u001b[A\n",
            " 89%|████████▉ | 158/178 [00:08<00:01, 18.57it/s]\u001b[A\n",
            " 90%|████████▉ | 160/178 [00:08<00:00, 18.57it/s]\u001b[A\n",
            " 91%|█████████ | 162/178 [00:08<00:00, 18.51it/s]\u001b[A\n",
            " 92%|█████████▏| 164/178 [00:08<00:00, 18.59it/s]\u001b[A\n",
            " 93%|█████████▎| 166/178 [00:08<00:00, 18.63it/s]\u001b[A\n",
            " 94%|█████████▍| 168/178 [00:09<00:00, 18.53it/s]\u001b[A\n",
            " 96%|█████████▌| 170/178 [00:09<00:00, 18.48it/s]\u001b[A\n",
            " 97%|█████████▋| 172/178 [00:09<00:00, 18.60it/s]\u001b[A\n",
            " 98%|█████████▊| 174/178 [00:09<00:00, 18.55it/s]\u001b[A\n",
            "100%|██████████| 178/178 [00:09<00:00, 18.51it/s]\n",
            " 43%|████▎     | 609/1422 [02:00<41:07,  3.04s/it]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            " 43%|████▎     | 610/1422 [02:01<29:21,  2.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 0.3204 Val acc: 0.9043 Val f1: 0.9043 AUC: 0.6138\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 811/1422 [02:31<01:30,  6.77it/s]\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 2/178 [00:00<00:09, 19.00it/s]\u001b[A\n",
            "  2%|▏         | 4/178 [00:00<00:09, 18.57it/s]\u001b[A\n",
            "  3%|▎         | 6/178 [00:00<00:09, 18.39it/s]\u001b[A\n",
            "  4%|▍         | 8/178 [00:00<00:09, 18.45it/s]\u001b[A\n",
            "  6%|▌         | 10/178 [00:00<00:09, 18.47it/s]\u001b[A\n",
            "  7%|▋         | 12/178 [00:00<00:08, 18.46it/s]\u001b[A\n",
            "  8%|▊         | 14/178 [00:00<00:08, 18.50it/s]\u001b[A\n",
            "  9%|▉         | 16/178 [00:00<00:08, 18.56it/s]\u001b[A\n",
            " 10%|█         | 18/178 [00:00<00:08, 18.46it/s]\u001b[A\n",
            " 11%|█         | 20/178 [00:01<00:08, 18.49it/s]\u001b[A\n",
            " 12%|█▏        | 22/178 [00:01<00:08, 18.56it/s]\u001b[A\n",
            " 13%|█▎        | 24/178 [00:01<00:08, 18.67it/s]\u001b[A\n",
            " 15%|█▍        | 26/178 [00:01<00:08, 18.45it/s]\u001b[A\n",
            " 16%|█▌        | 28/178 [00:01<00:08, 18.33it/s]\u001b[A\n",
            " 17%|█▋        | 30/178 [00:01<00:08, 18.22it/s]\u001b[A\n",
            " 18%|█▊        | 32/178 [00:01<00:08, 18.24it/s]\u001b[A\n",
            " 19%|█▉        | 34/178 [00:01<00:07, 18.18it/s]\u001b[A\n",
            " 20%|██        | 36/178 [00:01<00:07, 18.35it/s]\u001b[A\n",
            " 21%|██▏       | 38/178 [00:02<00:07, 18.37it/s]\u001b[A\n",
            " 22%|██▏       | 40/178 [00:02<00:07, 18.30it/s]\u001b[A\n",
            " 24%|██▎       | 42/178 [00:02<00:07, 18.23it/s]\u001b[A\n",
            " 25%|██▍       | 44/178 [00:02<00:07, 18.33it/s]\u001b[A\n",
            " 26%|██▌       | 46/178 [00:02<00:07, 18.35it/s]\u001b[A\n",
            " 27%|██▋       | 48/178 [00:02<00:07, 18.36it/s]\u001b[A\n",
            " 28%|██▊       | 50/178 [00:02<00:06, 18.30it/s]\u001b[A\n",
            " 29%|██▉       | 52/178 [00:02<00:06, 18.23it/s]\u001b[A\n",
            " 30%|███       | 54/178 [00:02<00:06, 18.04it/s]\u001b[A\n",
            " 31%|███▏      | 56/178 [00:03<00:06, 18.04it/s]\u001b[A\n",
            " 33%|███▎      | 58/178 [00:03<00:06, 18.09it/s]\u001b[A\n",
            " 34%|███▎      | 60/178 [00:03<00:06, 18.16it/s]\u001b[A\n",
            " 35%|███▍      | 62/178 [00:03<00:06, 18.28it/s]\u001b[A\n",
            " 36%|███▌      | 64/178 [00:03<00:06, 18.38it/s]\u001b[A\n",
            " 37%|███▋      | 66/178 [00:03<00:06, 18.44it/s]\u001b[A\n",
            " 38%|███▊      | 68/178 [00:03<00:05, 18.42it/s]\u001b[A\n",
            " 39%|███▉      | 70/178 [00:03<00:05, 18.50it/s]\u001b[A\n",
            " 40%|████      | 72/178 [00:03<00:05, 18.41it/s]\u001b[A\n",
            " 42%|████▏     | 74/178 [00:04<00:05, 18.41it/s]\u001b[A\n",
            " 43%|████▎     | 76/178 [00:04<00:05, 18.19it/s]\u001b[A\n",
            " 44%|████▍     | 78/178 [00:04<00:05, 18.21it/s]\u001b[A\n",
            " 45%|████▍     | 80/178 [00:04<00:05, 18.07it/s]\u001b[A\n",
            " 46%|████▌     | 82/178 [00:04<00:05, 18.19it/s]\u001b[A\n",
            " 47%|████▋     | 84/178 [00:04<00:05, 18.23it/s]\u001b[A\n",
            " 48%|████▊     | 86/178 [00:04<00:05, 18.12it/s]\u001b[A\n",
            " 49%|████▉     | 88/178 [00:04<00:04, 18.21it/s]\u001b[A\n",
            " 51%|█████     | 90/178 [00:04<00:04, 18.30it/s]\u001b[A\n",
            " 52%|█████▏    | 92/178 [00:05<00:04, 18.27it/s]\u001b[A\n",
            " 53%|█████▎    | 94/178 [00:05<00:04, 18.39it/s]\u001b[A\n",
            " 54%|█████▍    | 96/178 [00:05<00:04, 18.43it/s]\u001b[A\n",
            " 55%|█████▌    | 98/178 [00:05<00:04, 18.40it/s]\u001b[A\n",
            " 56%|█████▌    | 100/178 [00:05<00:04, 18.43it/s]\u001b[A\n",
            " 57%|█████▋    | 102/178 [00:05<00:04, 18.47it/s]\u001b[A\n",
            " 58%|█████▊    | 104/178 [00:05<00:04, 18.41it/s]\u001b[A\n",
            " 60%|█████▉    | 106/178 [00:05<00:03, 18.43it/s]\u001b[A\n",
            " 61%|██████    | 108/178 [00:05<00:03, 18.45it/s]\u001b[A\n",
            " 62%|██████▏   | 110/178 [00:05<00:03, 18.40it/s]\u001b[A\n",
            " 63%|██████▎   | 112/178 [00:06<00:03, 18.52it/s]\u001b[A\n",
            " 64%|██████▍   | 114/178 [00:06<00:03, 18.61it/s]\u001b[A\n",
            " 65%|██████▌   | 116/178 [00:06<00:03, 18.63it/s]\u001b[A\n",
            " 66%|██████▋   | 118/178 [00:06<00:03, 18.56it/s]\u001b[A\n",
            " 67%|██████▋   | 120/178 [00:06<00:03, 18.57it/s]\u001b[A\n",
            " 69%|██████▊   | 122/178 [00:06<00:03, 18.50it/s]\u001b[A\n",
            " 70%|██████▉   | 124/178 [00:06<00:02, 18.54it/s]\u001b[A\n",
            " 71%|███████   | 126/178 [00:06<00:02, 18.52it/s]\u001b[A\n",
            " 72%|███████▏  | 128/178 [00:06<00:02, 18.35it/s]\u001b[A\n",
            " 73%|███████▎  | 130/178 [00:07<00:02, 18.33it/s]\u001b[A\n",
            " 74%|███████▍  | 132/178 [00:07<00:02, 18.38it/s]\u001b[A\n",
            " 75%|███████▌  | 134/178 [00:07<00:02, 18.41it/s]\u001b[A\n",
            " 76%|███████▋  | 136/178 [00:07<00:02, 18.40it/s]\u001b[A\n",
            " 78%|███████▊  | 138/178 [00:07<00:02, 18.44it/s]\u001b[A\n",
            " 79%|███████▊  | 140/178 [00:07<00:02, 18.47it/s]\u001b[A\n",
            " 80%|███████▉  | 142/178 [00:07<00:01, 18.57it/s]\u001b[A\n",
            " 81%|████████  | 144/178 [00:07<00:01, 18.59it/s]\u001b[A\n",
            " 82%|████████▏ | 146/178 [00:07<00:01, 18.63it/s]\u001b[A\n",
            " 83%|████████▎ | 148/178 [00:08<00:01, 18.45it/s]\u001b[A\n",
            " 84%|████████▍ | 150/178 [00:08<00:01, 18.40it/s]\u001b[A\n",
            " 85%|████████▌ | 152/178 [00:08<00:01, 18.48it/s]\u001b[A\n",
            " 87%|████████▋ | 154/178 [00:08<00:01, 18.48it/s]\u001b[A\n",
            " 88%|████████▊ | 156/178 [00:08<00:01, 18.52it/s]\u001b[A\n",
            " 89%|████████▉ | 158/178 [00:08<00:01, 18.55it/s]\u001b[A\n",
            " 90%|████████▉ | 160/178 [00:08<00:00, 18.58it/s]\u001b[A\n",
            " 91%|█████████ | 162/178 [00:08<00:00, 18.62it/s]\u001b[A\n",
            " 92%|█████████▏| 164/178 [00:08<00:00, 18.58it/s]\u001b[A\n",
            " 93%|█████████▎| 166/178 [00:09<00:00, 18.52it/s]\u001b[A\n",
            " 94%|█████████▍| 168/178 [00:09<00:00, 18.58it/s]\u001b[A\n",
            " 96%|█████████▌| 170/178 [00:09<00:00, 18.62it/s]\u001b[A\n",
            " 97%|█████████▋| 172/178 [00:09<00:00, 18.58it/s]\u001b[A\n",
            " 98%|█████████▊| 174/178 [00:09<00:00, 18.59it/s]\u001b[A\n",
            "100%|██████████| 178/178 [00:09<00:00, 18.44it/s]\n",
            " 57%|█████▋    | 812/1422 [02:41<30:58,  3.05s/it]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            " 57%|█████▋    | 813/1422 [02:41<22:06,  2.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 0.3216 Val acc: 0.9043 Val f1: 0.9043 AUC: 0.6211\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 71%|███████▏  | 1014/1422 [03:11<00:59,  6.81it/s]\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 2/178 [00:00<00:09, 19.12it/s]\u001b[A\n",
            "  2%|▏         | 4/178 [00:00<00:09, 18.68it/s]\u001b[A\n",
            "  3%|▎         | 6/178 [00:00<00:09, 18.49it/s]\u001b[A\n",
            "  4%|▍         | 8/178 [00:00<00:09, 18.50it/s]\u001b[A\n",
            "  6%|▌         | 10/178 [00:00<00:09, 18.34it/s]\u001b[A\n",
            "  7%|▋         | 12/178 [00:00<00:09, 18.26it/s]\u001b[A\n",
            "  8%|▊         | 14/178 [00:00<00:08, 18.35it/s]\u001b[A\n",
            "  9%|▉         | 16/178 [00:00<00:08, 18.37it/s]\u001b[A\n",
            " 10%|█         | 18/178 [00:00<00:08, 18.37it/s]\u001b[A\n",
            " 11%|█         | 20/178 [00:01<00:08, 18.28it/s]\u001b[A\n",
            " 12%|█▏        | 22/178 [00:01<00:08, 18.19it/s]\u001b[A\n",
            " 13%|█▎        | 24/178 [00:01<00:08, 18.16it/s]\u001b[A\n",
            " 15%|█▍        | 26/178 [00:01<00:08, 18.15it/s]\u001b[A\n",
            " 16%|█▌        | 28/178 [00:01<00:08, 18.25it/s]\u001b[A\n",
            " 17%|█▋        | 30/178 [00:01<00:08, 18.31it/s]\u001b[A\n",
            " 18%|█▊        | 32/178 [00:01<00:07, 18.29it/s]\u001b[A\n",
            " 19%|█▉        | 34/178 [00:01<00:07, 18.35it/s]\u001b[A\n",
            " 20%|██        | 36/178 [00:01<00:07, 18.42it/s]\u001b[A\n",
            " 21%|██▏       | 38/178 [00:02<00:07, 18.45it/s]\u001b[A\n",
            " 22%|██▏       | 40/178 [00:02<00:07, 18.38it/s]\u001b[A\n",
            " 24%|██▎       | 42/178 [00:02<00:07, 18.43it/s]\u001b[A\n",
            " 25%|██▍       | 44/178 [00:02<00:07, 18.41it/s]\u001b[A\n",
            " 26%|██▌       | 46/178 [00:02<00:07, 18.48it/s]\u001b[A\n",
            " 27%|██▋       | 48/178 [00:02<00:07, 18.22it/s]\u001b[A\n",
            " 28%|██▊       | 50/178 [00:02<00:06, 18.29it/s]\u001b[A\n",
            " 29%|██▉       | 52/178 [00:02<00:06, 18.38it/s]\u001b[A\n",
            " 30%|███       | 54/178 [00:02<00:06, 18.45it/s]\u001b[A\n",
            " 31%|███▏      | 56/178 [00:03<00:06, 18.30it/s]\u001b[A\n",
            " 33%|███▎      | 58/178 [00:03<00:06, 18.36it/s]\u001b[A\n",
            " 34%|███▎      | 60/178 [00:03<00:06, 18.42it/s]\u001b[A\n",
            " 35%|███▍      | 62/178 [00:03<00:06, 18.42it/s]\u001b[A\n",
            " 36%|███▌      | 64/178 [00:03<00:06, 18.43it/s]\u001b[A\n",
            " 37%|███▋      | 66/178 [00:03<00:06, 18.33it/s]\u001b[A\n",
            " 38%|███▊      | 68/178 [00:03<00:05, 18.37it/s]\u001b[A\n",
            " 39%|███▉      | 70/178 [00:03<00:05, 18.36it/s]\u001b[A\n",
            " 40%|████      | 72/178 [00:03<00:05, 18.39it/s]\u001b[A\n",
            " 42%|████▏     | 74/178 [00:04<00:05, 18.47it/s]\u001b[A\n",
            " 43%|████▎     | 76/178 [00:04<00:05, 18.42it/s]\u001b[A\n",
            " 44%|████▍     | 78/178 [00:04<00:05, 18.48it/s]\u001b[A\n",
            " 45%|████▍     | 80/178 [00:04<00:05, 18.59it/s]\u001b[A\n",
            " 46%|████▌     | 82/178 [00:04<00:05, 18.66it/s]\u001b[A\n",
            " 47%|████▋     | 84/178 [00:04<00:05, 18.53it/s]\u001b[A\n",
            " 48%|████▊     | 86/178 [00:04<00:04, 18.49it/s]\u001b[A\n",
            " 49%|████▉     | 88/178 [00:04<00:04, 18.47it/s]\u001b[A\n",
            " 51%|█████     | 90/178 [00:04<00:04, 18.49it/s]\u001b[A\n",
            " 52%|█████▏    | 92/178 [00:05<00:04, 18.43it/s]\u001b[A\n",
            " 53%|█████▎    | 94/178 [00:05<00:04, 18.42it/s]\u001b[A\n",
            " 54%|█████▍    | 96/178 [00:05<00:04, 18.45it/s]\u001b[A\n",
            " 55%|█████▌    | 98/178 [00:05<00:04, 18.22it/s]\u001b[A\n",
            " 56%|█████▌    | 100/178 [00:05<00:04, 18.18it/s]\u001b[A\n",
            " 57%|█████▋    | 102/178 [00:05<00:04, 18.35it/s]\u001b[A\n",
            " 58%|█████▊    | 104/178 [00:05<00:04, 18.43it/s]\u001b[A\n",
            " 60%|█████▉    | 106/178 [00:05<00:03, 18.37it/s]\u001b[A\n",
            " 61%|██████    | 108/178 [00:05<00:03, 18.29it/s]\u001b[A\n",
            " 62%|██████▏   | 110/178 [00:05<00:03, 18.35it/s]\u001b[A\n",
            " 63%|██████▎   | 112/178 [00:06<00:03, 18.23it/s]\u001b[A\n",
            " 64%|██████▍   | 114/178 [00:06<00:03, 18.28it/s]\u001b[A\n",
            " 65%|██████▌   | 116/178 [00:06<00:03, 18.28it/s]\u001b[A\n",
            " 66%|██████▋   | 118/178 [00:06<00:03, 18.36it/s]\u001b[A\n",
            " 67%|██████▋   | 120/178 [00:06<00:03, 18.38it/s]\u001b[A\n",
            " 69%|██████▊   | 122/178 [00:06<00:03, 18.35it/s]\u001b[A\n",
            " 70%|██████▉   | 124/178 [00:06<00:02, 18.38it/s]\u001b[A\n",
            " 71%|███████   | 126/178 [00:06<00:02, 18.36it/s]\u001b[A\n",
            " 72%|███████▏  | 128/178 [00:06<00:02, 18.36it/s]\u001b[A\n",
            " 73%|███████▎  | 130/178 [00:07<00:02, 18.38it/s]\u001b[A\n",
            " 74%|███████▍  | 132/178 [00:07<00:02, 18.45it/s]\u001b[A\n",
            " 75%|███████▌  | 134/178 [00:07<00:02, 18.52it/s]\u001b[A\n",
            " 76%|███████▋  | 136/178 [00:07<00:02, 18.55it/s]\u001b[A\n",
            " 78%|███████▊  | 138/178 [00:07<00:02, 18.47it/s]\u001b[A\n",
            " 79%|███████▊  | 140/178 [00:07<00:02, 18.49it/s]\u001b[A\n",
            " 80%|███████▉  | 142/178 [00:07<00:01, 18.33it/s]\u001b[A\n",
            " 81%|████████  | 144/178 [00:07<00:01, 18.33it/s]\u001b[A\n",
            " 82%|████████▏ | 146/178 [00:07<00:01, 18.32it/s]\u001b[A\n",
            " 83%|████████▎ | 148/178 [00:08<00:01, 18.37it/s]\u001b[A\n",
            " 84%|████████▍ | 150/178 [00:08<00:01, 18.42it/s]\u001b[A\n",
            " 85%|████████▌ | 152/178 [00:08<00:01, 18.49it/s]\u001b[A\n",
            " 87%|████████▋ | 154/178 [00:08<00:01, 18.41it/s]\u001b[A\n",
            " 88%|████████▊ | 156/178 [00:08<00:01, 18.40it/s]\u001b[A\n",
            " 89%|████████▉ | 158/178 [00:08<00:01, 18.48it/s]\u001b[A\n",
            " 90%|████████▉ | 160/178 [00:08<00:00, 18.45it/s]\u001b[A\n",
            " 91%|█████████ | 162/178 [00:08<00:00, 18.42it/s]\u001b[A\n",
            " 92%|█████████▏| 164/178 [00:08<00:00, 18.40it/s]\u001b[A\n",
            " 93%|█████████▎| 166/178 [00:09<00:00, 18.45it/s]\u001b[A\n",
            " 94%|█████████▍| 168/178 [00:09<00:00, 18.45it/s]\u001b[A\n",
            " 96%|█████████▌| 170/178 [00:09<00:00, 18.48it/s]\u001b[A\n",
            " 97%|█████████▋| 172/178 [00:09<00:00, 18.50it/s]\u001b[A\n",
            " 98%|█████████▊| 174/178 [00:09<00:00, 18.60it/s]\u001b[A\n",
            "100%|██████████| 178/178 [00:09<00:00, 18.43it/s]\n",
            " 71%|███████▏  | 1015/1422 [03:21<20:40,  3.05s/it]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            " 71%|███████▏  | 1016/1422 [03:21<14:44,  2.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 0.3196 Val acc: 0.9043 Val f1: 0.9043 AUC: 0.6427\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 1217/1422 [03:52<00:30,  6.83it/s]\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 2/178 [00:00<00:09, 19.11it/s]\u001b[A\n",
            "  2%|▏         | 4/178 [00:00<00:09, 18.76it/s]\u001b[A\n",
            "  3%|▎         | 6/178 [00:00<00:09, 18.42it/s]\u001b[A\n",
            "  4%|▍         | 8/178 [00:00<00:09, 18.43it/s]\u001b[A\n",
            "  6%|▌         | 10/178 [00:00<00:09, 18.52it/s]\u001b[A\n",
            "  7%|▋         | 12/178 [00:00<00:08, 18.55it/s]\u001b[A\n",
            "  8%|▊         | 14/178 [00:00<00:08, 18.23it/s]\u001b[A\n",
            "  9%|▉         | 16/178 [00:00<00:08, 18.20it/s]\u001b[A\n",
            " 10%|█         | 18/178 [00:00<00:08, 18.29it/s]\u001b[A\n",
            " 11%|█         | 20/178 [00:01<00:08, 18.28it/s]\u001b[A\n",
            " 12%|█▏        | 22/178 [00:01<00:08, 18.37it/s]\u001b[A\n",
            " 13%|█▎        | 24/178 [00:01<00:08, 18.40it/s]\u001b[A\n",
            " 15%|█▍        | 26/178 [00:01<00:08, 18.37it/s]\u001b[A\n",
            " 16%|█▌        | 28/178 [00:01<00:08, 18.47it/s]\u001b[A\n",
            " 17%|█▋        | 30/178 [00:01<00:08, 18.46it/s]\u001b[A\n",
            " 18%|█▊        | 32/178 [00:01<00:07, 18.54it/s]\u001b[A\n",
            " 19%|█▉        | 34/178 [00:01<00:07, 18.55it/s]\u001b[A\n",
            " 20%|██        | 36/178 [00:01<00:07, 18.51it/s]\u001b[A\n",
            " 21%|██▏       | 38/178 [00:02<00:07, 18.46it/s]\u001b[A\n",
            " 22%|██▏       | 40/178 [00:02<00:07, 18.43it/s]\u001b[A\n",
            " 24%|██▎       | 42/178 [00:02<00:07, 18.20it/s]\u001b[A\n",
            " 25%|██▍       | 44/178 [00:02<00:07, 18.31it/s]\u001b[A\n",
            " 26%|██▌       | 46/178 [00:02<00:07, 18.39it/s]\u001b[A\n",
            " 27%|██▋       | 48/178 [00:02<00:07, 18.34it/s]\u001b[A\n",
            " 28%|██▊       | 50/178 [00:02<00:06, 18.44it/s]\u001b[A\n",
            " 29%|██▉       | 52/178 [00:02<00:06, 18.49it/s]\u001b[A\n",
            " 30%|███       | 54/178 [00:02<00:06, 18.41it/s]\u001b[A\n",
            " 31%|███▏      | 56/178 [00:03<00:06, 18.47it/s]\u001b[A\n",
            " 33%|███▎      | 58/178 [00:03<00:06, 18.48it/s]\u001b[A\n",
            " 34%|███▎      | 60/178 [00:03<00:06, 18.45it/s]\u001b[A\n",
            " 35%|███▍      | 62/178 [00:03<00:06, 18.47it/s]\u001b[A\n",
            " 36%|███▌      | 64/178 [00:03<00:06, 18.47it/s]\u001b[A\n",
            " 37%|███▋      | 66/178 [00:03<00:06, 18.42it/s]\u001b[A\n",
            " 38%|███▊      | 68/178 [00:03<00:05, 18.37it/s]\u001b[A\n",
            " 39%|███▉      | 70/178 [00:03<00:05, 18.51it/s]\u001b[A\n",
            " 40%|████      | 72/178 [00:03<00:05, 18.46it/s]\u001b[A\n",
            " 42%|████▏     | 74/178 [00:04<00:05, 18.45it/s]\u001b[A\n",
            " 43%|████▎     | 76/178 [00:04<00:05, 18.42it/s]\u001b[A\n",
            " 44%|████▍     | 78/178 [00:04<00:05, 18.34it/s]\u001b[A\n",
            " 45%|████▍     | 80/178 [00:04<00:05, 18.41it/s]\u001b[A\n",
            " 46%|████▌     | 82/178 [00:04<00:05, 18.39it/s]\u001b[A\n",
            " 47%|████▋     | 84/178 [00:04<00:05, 18.46it/s]\u001b[A\n",
            " 48%|████▊     | 86/178 [00:04<00:04, 18.43it/s]\u001b[A\n",
            " 49%|████▉     | 88/178 [00:04<00:04, 18.33it/s]\u001b[A\n",
            " 51%|█████     | 90/178 [00:04<00:04, 18.39it/s]\u001b[A\n",
            " 52%|█████▏    | 92/178 [00:04<00:04, 18.48it/s]\u001b[A\n",
            " 53%|█████▎    | 94/178 [00:05<00:04, 18.41it/s]\u001b[A\n",
            " 54%|█████▍    | 96/178 [00:05<00:04, 18.44it/s]\u001b[A\n",
            " 55%|█████▌    | 98/178 [00:05<00:04, 18.46it/s]\u001b[A\n",
            " 56%|█████▌    | 100/178 [00:05<00:04, 18.44it/s]\u001b[A\n",
            " 57%|█████▋    | 102/178 [00:05<00:04, 18.40it/s]\u001b[A\n",
            " 58%|█████▊    | 104/178 [00:05<00:04, 18.38it/s]\u001b[A\n",
            " 60%|█████▉    | 106/178 [00:05<00:03, 18.33it/s]\u001b[A\n",
            " 61%|██████    | 108/178 [00:05<00:03, 18.30it/s]\u001b[A\n",
            " 62%|██████▏   | 110/178 [00:05<00:03, 18.19it/s]\u001b[A\n",
            " 63%|██████▎   | 112/178 [00:06<00:03, 18.31it/s]\u001b[A\n",
            " 64%|██████▍   | 114/178 [00:06<00:03, 18.37it/s]\u001b[A\n",
            " 65%|██████▌   | 116/178 [00:06<00:03, 18.45it/s]\u001b[A\n",
            " 66%|██████▋   | 118/178 [00:06<00:03, 18.42it/s]\u001b[A\n",
            " 67%|██████▋   | 120/178 [00:06<00:03, 18.38it/s]\u001b[A\n",
            " 69%|██████▊   | 122/178 [00:06<00:03, 18.47it/s]\u001b[A\n",
            " 70%|██████▉   | 124/178 [00:06<00:02, 18.44it/s]\u001b[A\n",
            " 71%|███████   | 126/178 [00:06<00:02, 18.48it/s]\u001b[A\n",
            " 72%|███████▏  | 128/178 [00:06<00:02, 18.44it/s]\u001b[A\n",
            " 73%|███████▎  | 130/178 [00:07<00:02, 18.49it/s]\u001b[A\n",
            " 74%|███████▍  | 132/178 [00:07<00:02, 18.53it/s]\u001b[A\n",
            " 75%|███████▌  | 134/178 [00:07<00:02, 18.48it/s]\u001b[A\n",
            " 76%|███████▋  | 136/178 [00:07<00:02, 18.37it/s]\u001b[A\n",
            " 78%|███████▊  | 138/178 [00:07<00:02, 18.49it/s]\u001b[A\n",
            " 79%|███████▊  | 140/178 [00:07<00:02, 18.48it/s]\u001b[A\n",
            " 80%|███████▉  | 142/178 [00:07<00:01, 18.52it/s]\u001b[A\n",
            " 81%|████████  | 144/178 [00:07<00:01, 18.60it/s]\u001b[A\n",
            " 82%|████████▏ | 146/178 [00:07<00:01, 18.62it/s]\u001b[A\n",
            " 83%|████████▎ | 148/178 [00:08<00:01, 18.51it/s]\u001b[A\n",
            " 84%|████████▍ | 150/178 [00:08<00:01, 18.50it/s]\u001b[A\n",
            " 85%|████████▌ | 152/178 [00:08<00:01, 18.54it/s]\u001b[A\n",
            " 87%|████████▋ | 154/178 [00:08<00:01, 18.62it/s]\u001b[A\n",
            " 88%|████████▊ | 156/178 [00:08<00:01, 18.65it/s]\u001b[A\n",
            " 89%|████████▉ | 158/178 [00:08<00:01, 18.51it/s]\u001b[A\n",
            " 90%|████████▉ | 160/178 [00:08<00:00, 18.47it/s]\u001b[A\n",
            " 91%|█████████ | 162/178 [00:08<00:00, 18.36it/s]\u001b[A\n",
            " 92%|█████████▏| 164/178 [00:08<00:00, 18.37it/s]\u001b[A\n",
            " 93%|█████████▎| 166/178 [00:09<00:00, 18.43it/s]\u001b[A\n",
            " 94%|█████████▍| 168/178 [00:09<00:00, 18.55it/s]\u001b[A\n",
            " 96%|█████████▌| 170/178 [00:09<00:00, 18.52it/s]\u001b[A\n",
            " 97%|█████████▋| 172/178 [00:09<00:00, 18.53it/s]\u001b[A\n",
            " 98%|█████████▊| 174/178 [00:09<00:00, 18.58it/s]\u001b[A\n",
            "100%|██████████| 178/178 [00:09<00:00, 18.47it/s]\n",
            " 86%|████████▌ | 1218/1422 [04:01<10:20,  3.04s/it]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            " 86%|████████▌ | 1219/1422 [04:02<07:21,  2.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 0.3191 Val acc: 0.9043 Val f1: 0.9043 AUC: 0.6631\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 1420/1422 [04:32<00:00,  5.77it/s]\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 2/178 [00:00<00:09, 19.24it/s]\u001b[A\n",
            "  2%|▏         | 4/178 [00:00<00:09, 18.47it/s]\u001b[A\n",
            "  3%|▎         | 6/178 [00:00<00:09, 18.43it/s]\u001b[A\n",
            "  4%|▍         | 8/178 [00:00<00:09, 18.45it/s]\u001b[A\n",
            "  6%|▌         | 10/178 [00:00<00:09, 18.34it/s]\u001b[A\n",
            "  7%|▋         | 12/178 [00:00<00:09, 18.32it/s]\u001b[A\n",
            "  8%|▊         | 14/178 [00:00<00:08, 18.29it/s]\u001b[A\n",
            "  9%|▉         | 16/178 [00:00<00:08, 18.36it/s]\u001b[A\n",
            " 10%|█         | 18/178 [00:00<00:08, 18.35it/s]\u001b[A\n",
            " 11%|█         | 20/178 [00:01<00:08, 18.16it/s]\u001b[A\n",
            " 12%|█▏        | 22/178 [00:01<00:08, 18.20it/s]\u001b[A\n",
            " 13%|█▎        | 24/178 [00:01<00:08, 18.21it/s]\u001b[A\n",
            " 15%|█▍        | 26/178 [00:01<00:08, 18.17it/s]\u001b[A\n",
            " 16%|█▌        | 28/178 [00:01<00:08, 18.10it/s]\u001b[A\n",
            " 17%|█▋        | 30/178 [00:01<00:08, 18.24it/s]\u001b[A\n",
            " 18%|█▊        | 32/178 [00:01<00:07, 18.30it/s]\u001b[A\n",
            " 19%|█▉        | 34/178 [00:01<00:07, 18.17it/s]\u001b[A\n",
            " 20%|██        | 36/178 [00:01<00:07, 18.23it/s]\u001b[A\n",
            " 21%|██▏       | 38/178 [00:02<00:07, 18.27it/s]\u001b[A\n",
            " 22%|██▏       | 40/178 [00:02<00:07, 18.35it/s]\u001b[A\n",
            " 24%|██▎       | 42/178 [00:02<00:07, 18.29it/s]\u001b[A\n",
            " 25%|██▍       | 44/178 [00:02<00:07, 18.32it/s]\u001b[A\n",
            " 26%|██▌       | 46/178 [00:02<00:07, 18.33it/s]\u001b[A\n",
            " 27%|██▋       | 48/178 [00:02<00:07, 18.33it/s]\u001b[A\n",
            " 28%|██▊       | 50/178 [00:02<00:06, 18.30it/s]\u001b[A\n",
            " 29%|██▉       | 52/178 [00:02<00:06, 18.29it/s]\u001b[A\n",
            " 30%|███       | 54/178 [00:02<00:06, 18.21it/s]\u001b[A\n",
            " 31%|███▏      | 56/178 [00:03<00:06, 18.02it/s]\u001b[A\n",
            " 33%|███▎      | 58/178 [00:03<00:06, 17.87it/s]\u001b[A\n",
            " 34%|███▎      | 60/178 [00:03<00:06, 17.93it/s]\u001b[A\n",
            " 35%|███▍      | 62/178 [00:03<00:06, 17.96it/s]\u001b[A\n",
            " 36%|███▌      | 64/178 [00:03<00:06, 17.99it/s]\u001b[A\n",
            " 37%|███▋      | 66/178 [00:03<00:06, 17.96it/s]\u001b[A\n",
            " 38%|███▊      | 68/178 [00:03<00:06, 17.88it/s]\u001b[A\n",
            " 39%|███▉      | 70/178 [00:03<00:06, 17.97it/s]\u001b[A\n",
            " 40%|████      | 72/178 [00:03<00:05, 18.08it/s]\u001b[A\n",
            " 42%|████▏     | 74/178 [00:04<00:05, 18.06it/s]\u001b[A\n",
            " 43%|████▎     | 76/178 [00:04<00:05, 18.09it/s]\u001b[A\n",
            " 44%|████▍     | 78/178 [00:04<00:05, 18.14it/s]\u001b[A\n",
            " 45%|████▍     | 80/178 [00:04<00:05, 18.22it/s]\u001b[A\n",
            " 46%|████▌     | 82/178 [00:04<00:05, 18.23it/s]\u001b[A\n",
            " 47%|████▋     | 84/178 [00:04<00:05, 18.21it/s]\u001b[A\n",
            " 48%|████▊     | 86/178 [00:04<00:05, 18.14it/s]\u001b[A\n",
            " 49%|████▉     | 88/178 [00:04<00:04, 18.14it/s]\u001b[A\n",
            " 51%|█████     | 90/178 [00:04<00:04, 18.15it/s]\u001b[A\n",
            " 52%|█████▏    | 92/178 [00:05<00:04, 18.12it/s]\u001b[A\n",
            " 53%|█████▎    | 94/178 [00:05<00:04, 18.09it/s]\u001b[A\n",
            " 54%|█████▍    | 96/178 [00:05<00:04, 18.17it/s]\u001b[A\n",
            " 55%|█████▌    | 98/178 [00:05<00:04, 18.20it/s]\u001b[A\n",
            " 56%|█████▌    | 100/178 [00:05<00:04, 18.11it/s]\u001b[A\n",
            " 57%|█████▋    | 102/178 [00:05<00:04, 18.20it/s]\u001b[A\n",
            " 58%|█████▊    | 104/178 [00:05<00:04, 18.20it/s]\u001b[A\n",
            " 60%|█████▉    | 106/178 [00:05<00:03, 18.26it/s]\u001b[A\n",
            " 61%|██████    | 108/178 [00:05<00:03, 18.16it/s]\u001b[A\n",
            " 62%|██████▏   | 110/178 [00:06<00:03, 18.11it/s]\u001b[A\n",
            " 63%|██████▎   | 112/178 [00:06<00:03, 18.01it/s]\u001b[A\n",
            " 64%|██████▍   | 114/178 [00:06<00:03, 18.12it/s]\u001b[A\n",
            " 65%|██████▌   | 116/178 [00:06<00:03, 18.08it/s]\u001b[A\n",
            " 66%|██████▋   | 118/178 [00:06<00:03, 18.13it/s]\u001b[A\n",
            " 67%|██████▋   | 120/178 [00:06<00:03, 18.22it/s]\u001b[A\n",
            " 69%|██████▊   | 122/178 [00:06<00:03, 18.22it/s]\u001b[A\n",
            " 70%|██████▉   | 124/178 [00:06<00:02, 18.29it/s]\u001b[A\n",
            " 71%|███████   | 126/178 [00:06<00:02, 18.25it/s]\u001b[A\n",
            " 72%|███████▏  | 128/178 [00:07<00:02, 18.19it/s]\u001b[A\n",
            " 73%|███████▎  | 130/178 [00:07<00:02, 18.25it/s]\u001b[A\n",
            " 74%|███████▍  | 132/178 [00:07<00:02, 18.21it/s]\u001b[A\n",
            " 75%|███████▌  | 134/178 [00:07<00:02, 18.30it/s]\u001b[A\n",
            " 76%|███████▋  | 136/178 [00:07<00:02, 18.30it/s]\u001b[A\n",
            " 78%|███████▊  | 138/178 [00:07<00:02, 18.22it/s]\u001b[A\n",
            " 79%|███████▊  | 140/178 [00:07<00:02, 18.29it/s]\u001b[A\n",
            " 80%|███████▉  | 142/178 [00:07<00:01, 18.29it/s]\u001b[A\n",
            " 81%|████████  | 144/178 [00:07<00:01, 18.31it/s]\u001b[A\n",
            " 82%|████████▏ | 146/178 [00:08<00:01, 18.30it/s]\u001b[A\n",
            " 83%|████████▎ | 148/178 [00:08<00:01, 18.31it/s]\u001b[A\n",
            " 84%|████████▍ | 150/178 [00:08<00:01, 18.33it/s]\u001b[A\n",
            " 85%|████████▌ | 152/178 [00:08<00:01, 18.35it/s]\u001b[A\n",
            " 87%|████████▋ | 154/178 [00:08<00:01, 18.43it/s]\u001b[A\n",
            " 88%|████████▊ | 156/178 [00:08<00:01, 18.37it/s]\u001b[A\n",
            " 89%|████████▉ | 158/178 [00:08<00:01, 18.22it/s]\u001b[A\n",
            " 90%|████████▉ | 160/178 [00:08<00:00, 18.19it/s]\u001b[A\n",
            " 91%|█████████ | 162/178 [00:08<00:00, 18.20it/s]\u001b[A\n",
            " 92%|█████████▏| 164/178 [00:09<00:00, 18.16it/s]\u001b[A\n",
            " 93%|█████████▎| 166/178 [00:09<00:00, 18.11it/s]\u001b[A\n",
            " 94%|█████████▍| 168/178 [00:09<00:00, 18.06it/s]\u001b[A\n",
            " 96%|█████████▌| 170/178 [00:09<00:00, 18.01it/s]\u001b[A\n",
            " 97%|█████████▋| 172/178 [00:09<00:00, 18.09it/s]\u001b[A\n",
            " 98%|█████████▊| 174/178 [00:09<00:00, 18.10it/s]\u001b[A\n",
            "100%|██████████| 178/178 [00:09<00:00, 18.22it/s]\n",
            "100%|█████████▉| 1421/1422 [04:42<00:03,  3.10s/it]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100%|██████████| 1422/1422 [04:42<00:00,  5.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 0.3157 Val acc: 0.9043 Val f1: 0.9043 AUC: 0.6716\n",
            "\n",
            "\n",
            "Epoch 3 from 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 202/1422 [00:30<03:14,  6.26it/s]\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 2/178 [00:00<00:09, 18.47it/s]\u001b[A\n",
            "  2%|▏         | 4/178 [00:00<00:09, 18.50it/s]\u001b[A\n",
            "  3%|▎         | 6/178 [00:00<00:09, 18.34it/s]\u001b[A\n",
            "  4%|▍         | 8/178 [00:00<00:09, 18.38it/s]\u001b[A\n",
            "  6%|▌         | 10/178 [00:00<00:09, 18.37it/s]\u001b[A\n",
            "  7%|▋         | 12/178 [00:00<00:09, 18.44it/s]\u001b[A\n",
            "  8%|▊         | 14/178 [00:00<00:08, 18.42it/s]\u001b[A\n",
            "  9%|▉         | 16/178 [00:00<00:08, 18.36it/s]\u001b[A\n",
            " 10%|█         | 18/178 [00:00<00:08, 18.41it/s]\u001b[A\n",
            " 11%|█         | 20/178 [00:01<00:08, 18.40it/s]\u001b[A\n",
            " 12%|█▏        | 22/178 [00:01<00:08, 18.02it/s]\u001b[A\n",
            " 13%|█▎        | 24/178 [00:01<00:08, 18.14it/s]\u001b[A\n",
            " 15%|█▍        | 26/178 [00:01<00:08, 18.27it/s]\u001b[A\n",
            " 16%|█▌        | 28/178 [00:01<00:08, 18.27it/s]\u001b[A\n",
            " 17%|█▋        | 30/178 [00:01<00:08, 18.33it/s]\u001b[A\n",
            " 18%|█▊        | 32/178 [00:01<00:07, 18.41it/s]\u001b[A\n",
            " 19%|█▉        | 34/178 [00:01<00:07, 18.33it/s]\u001b[A\n",
            " 20%|██        | 36/178 [00:01<00:07, 18.45it/s]\u001b[A\n",
            " 21%|██▏       | 38/178 [00:02<00:07, 18.43it/s]\u001b[A\n",
            " 22%|██▏       | 40/178 [00:02<00:07, 18.45it/s]\u001b[A\n",
            " 24%|██▎       | 42/178 [00:02<00:07, 18.30it/s]\u001b[A\n",
            " 25%|██▍       | 44/178 [00:02<00:07, 18.22it/s]\u001b[A\n",
            " 26%|██▌       | 46/178 [00:02<00:07, 18.16it/s]\u001b[A\n",
            " 27%|██▋       | 48/178 [00:02<00:07, 18.21it/s]\u001b[A\n",
            " 28%|██▊       | 50/178 [00:02<00:06, 18.30it/s]\u001b[A\n",
            " 29%|██▉       | 52/178 [00:02<00:06, 18.40it/s]\u001b[A\n",
            " 30%|███       | 54/178 [00:02<00:06, 18.55it/s]\u001b[A\n",
            " 31%|███▏      | 56/178 [00:03<00:06, 18.50it/s]\u001b[A\n",
            " 33%|███▎      | 58/178 [00:03<00:06, 18.65it/s]\u001b[A\n",
            " 34%|███▎      | 60/178 [00:03<00:06, 18.49it/s]\u001b[A\n",
            " 35%|███▍      | 62/178 [00:03<00:06, 18.56it/s]\u001b[A\n",
            " 36%|███▌      | 64/178 [00:03<00:06, 18.62it/s]\u001b[A\n",
            " 37%|███▋      | 66/178 [00:03<00:06, 18.64it/s]\u001b[A\n",
            " 38%|███▊      | 68/178 [00:03<00:05, 18.61it/s]\u001b[A\n",
            " 39%|███▉      | 70/178 [00:03<00:05, 18.63it/s]\u001b[A\n",
            " 40%|████      | 72/178 [00:03<00:05, 18.59it/s]\u001b[A\n",
            " 42%|████▏     | 74/178 [00:04<00:05, 18.54it/s]\u001b[A\n",
            " 43%|████▎     | 76/178 [00:04<00:05, 18.64it/s]\u001b[A\n",
            " 44%|████▍     | 78/178 [00:04<00:05, 18.65it/s]\u001b[A\n",
            " 45%|████▍     | 80/178 [00:04<00:05, 18.62it/s]\u001b[A\n",
            " 46%|████▌     | 82/178 [00:04<00:05, 18.57it/s]\u001b[A\n",
            " 47%|████▋     | 84/178 [00:04<00:05, 18.42it/s]\u001b[A\n",
            " 48%|████▊     | 86/178 [00:04<00:04, 18.43it/s]\u001b[A\n",
            " 49%|████▉     | 88/178 [00:04<00:04, 18.49it/s]\u001b[A\n",
            " 51%|█████     | 90/178 [00:04<00:04, 18.54it/s]\u001b[A\n",
            " 52%|█████▏    | 92/178 [00:04<00:04, 18.54it/s]\u001b[A\n",
            " 53%|█████▎    | 94/178 [00:05<00:04, 18.56it/s]\u001b[A\n",
            " 54%|█████▍    | 96/178 [00:05<00:04, 18.53it/s]\u001b[A\n",
            " 55%|█████▌    | 98/178 [00:05<00:04, 18.54it/s]\u001b[A\n",
            " 56%|█████▌    | 100/178 [00:05<00:04, 18.56it/s]\u001b[A\n",
            " 57%|█████▋    | 102/178 [00:05<00:04, 18.62it/s]\u001b[A\n",
            " 58%|█████▊    | 104/178 [00:05<00:03, 18.57it/s]\u001b[A\n",
            " 60%|█████▉    | 106/178 [00:05<00:03, 18.54it/s]\u001b[A\n",
            " 61%|██████    | 108/178 [00:05<00:03, 18.51it/s]\u001b[A\n",
            " 62%|██████▏   | 110/178 [00:05<00:03, 18.53it/s]\u001b[A\n",
            " 63%|██████▎   | 112/178 [00:06<00:03, 18.53it/s]\u001b[A\n",
            " 64%|██████▍   | 114/178 [00:06<00:03, 18.62it/s]\u001b[A\n",
            " 65%|██████▌   | 116/178 [00:06<00:03, 18.31it/s]\u001b[A\n",
            " 66%|██████▋   | 118/178 [00:06<00:03, 18.20it/s]\u001b[A\n",
            " 67%|██████▋   | 120/178 [00:06<00:03, 18.24it/s]\u001b[A\n",
            " 69%|██████▊   | 122/178 [00:06<00:03, 18.36it/s]\u001b[A\n",
            " 70%|██████▉   | 124/178 [00:06<00:02, 18.45it/s]\u001b[A\n",
            " 71%|███████   | 126/178 [00:06<00:02, 18.53it/s]\u001b[A\n",
            " 72%|███████▏  | 128/178 [00:06<00:02, 18.57it/s]\u001b[A\n",
            " 73%|███████▎  | 130/178 [00:07<00:02, 18.67it/s]\u001b[A\n",
            " 74%|███████▍  | 132/178 [00:07<00:02, 18.63it/s]\u001b[A\n",
            " 75%|███████▌  | 134/178 [00:07<00:02, 18.61it/s]\u001b[A\n",
            " 76%|███████▋  | 136/178 [00:07<00:02, 18.50it/s]\u001b[A\n",
            " 78%|███████▊  | 138/178 [00:07<00:02, 18.30it/s]\u001b[A\n",
            " 79%|███████▊  | 140/178 [00:07<00:02, 18.25it/s]\u001b[A\n",
            " 80%|███████▉  | 142/178 [00:07<00:01, 18.26it/s]\u001b[A\n",
            " 81%|████████  | 144/178 [00:07<00:01, 18.27it/s]\u001b[A\n",
            " 82%|████████▏ | 146/178 [00:07<00:01, 18.35it/s]\u001b[A\n",
            " 83%|████████▎ | 148/178 [00:08<00:01, 18.42it/s]\u001b[A\n",
            " 84%|████████▍ | 150/178 [00:08<00:01, 18.51it/s]\u001b[A\n",
            " 85%|████████▌ | 152/178 [00:08<00:01, 18.48it/s]\u001b[A\n",
            " 87%|████████▋ | 154/178 [00:08<00:01, 18.56it/s]\u001b[A\n",
            " 88%|████████▊ | 156/178 [00:08<00:01, 18.69it/s]\u001b[A\n",
            " 89%|████████▉ | 158/178 [00:08<00:01, 18.67it/s]\u001b[A\n",
            " 90%|████████▉ | 160/178 [00:08<00:00, 18.55it/s]\u001b[A\n",
            " 91%|█████████ | 162/178 [00:08<00:00, 18.49it/s]\u001b[A\n",
            " 92%|█████████▏| 164/178 [00:08<00:00, 18.50it/s]\u001b[A\n",
            " 93%|█████████▎| 166/178 [00:08<00:00, 18.60it/s]\u001b[A\n",
            " 94%|█████████▍| 168/178 [00:09<00:00, 18.65it/s]\u001b[A\n",
            " 96%|█████████▌| 170/178 [00:09<00:00, 18.66it/s]\u001b[A\n",
            " 97%|█████████▋| 172/178 [00:09<00:00, 18.66it/s]\u001b[A\n",
            " 98%|█████████▊| 174/178 [00:09<00:00, 18.50it/s]\u001b[A\n",
            "100%|██████████| 178/178 [00:09<00:00, 18.50it/s]\n",
            " 14%|█▍        | 203/1422 [00:40<1:01:53,  3.05s/it]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            " 14%|█▍        | 204/1422 [00:40<44:10,  2.18s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 0.3194 Val acc: 0.9043 Val f1: 0.9043 AUC: 0.4331\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 405/1422 [01:10<02:33,  6.63it/s]\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 2/178 [00:00<00:09, 19.03it/s]\u001b[A\n",
            "  2%|▏         | 4/178 [00:00<00:09, 18.57it/s]\u001b[A\n",
            "  3%|▎         | 6/178 [00:00<00:09, 18.57it/s]\u001b[A\n",
            "  4%|▍         | 8/178 [00:00<00:09, 18.54it/s]\u001b[A\n",
            "  6%|▌         | 10/178 [00:00<00:09, 18.48it/s]\u001b[A\n",
            "  7%|▋         | 12/178 [00:00<00:08, 18.50it/s]\u001b[A\n",
            "  8%|▊         | 14/178 [00:00<00:08, 18.47it/s]\u001b[A\n",
            "  9%|▉         | 16/178 [00:00<00:08, 18.44it/s]\u001b[A\n",
            " 10%|█         | 18/178 [00:00<00:08, 18.37it/s]\u001b[A\n",
            " 11%|█         | 20/178 [00:01<00:08, 18.28it/s]\u001b[A\n",
            " 12%|█▏        | 22/178 [00:01<00:08, 18.22it/s]\u001b[A\n",
            " 13%|█▎        | 24/178 [00:01<00:08, 18.12it/s]\u001b[A\n",
            " 15%|█▍        | 26/178 [00:01<00:08, 18.14it/s]\u001b[A\n",
            " 16%|█▌        | 28/178 [00:01<00:08, 18.18it/s]\u001b[A\n",
            " 17%|█▋        | 30/178 [00:01<00:08, 18.14it/s]\u001b[A\n",
            " 18%|█▊        | 32/178 [00:01<00:08, 18.23it/s]\u001b[A\n",
            " 19%|█▉        | 34/178 [00:01<00:07, 18.32it/s]\u001b[A\n",
            " 20%|██        | 36/178 [00:01<00:07, 18.28it/s]\u001b[A\n",
            " 21%|██▏       | 38/178 [00:02<00:07, 18.35it/s]\u001b[A\n",
            " 22%|██▏       | 40/178 [00:02<00:07, 18.12it/s]\u001b[A\n",
            " 24%|██▎       | 42/178 [00:02<00:07, 18.06it/s]\u001b[A\n",
            " 25%|██▍       | 44/178 [00:02<00:07, 18.14it/s]\u001b[A\n",
            " 26%|██▌       | 46/178 [00:02<00:07, 18.30it/s]\u001b[A\n",
            " 27%|██▋       | 48/178 [00:02<00:07, 18.41it/s]\u001b[A\n",
            " 28%|██▊       | 50/178 [00:02<00:06, 18.41it/s]\u001b[A\n",
            " 29%|██▉       | 52/178 [00:02<00:06, 18.50it/s]\u001b[A\n",
            " 30%|███       | 54/178 [00:02<00:06, 18.51it/s]\u001b[A\n",
            " 31%|███▏      | 56/178 [00:03<00:06, 18.47it/s]\u001b[A\n",
            " 33%|███▎      | 58/178 [00:03<00:06, 18.37it/s]\u001b[A\n",
            " 34%|███▎      | 60/178 [00:03<00:06, 18.20it/s]\u001b[A\n",
            " 35%|███▍      | 62/178 [00:03<00:06, 18.19it/s]\u001b[A\n",
            " 36%|███▌      | 64/178 [00:03<00:06, 18.09it/s]\u001b[A\n",
            " 37%|███▋      | 66/178 [00:03<00:06, 18.07it/s]\u001b[A\n",
            " 38%|███▊      | 68/178 [00:03<00:06, 17.92it/s]\u001b[A\n",
            " 39%|███▉      | 70/178 [00:03<00:05, 18.00it/s]\u001b[A\n",
            " 40%|████      | 72/178 [00:03<00:05, 18.04it/s]\u001b[A\n",
            " 42%|████▏     | 74/178 [00:04<00:05, 17.98it/s]\u001b[A\n",
            " 43%|████▎     | 76/178 [00:04<00:05, 18.02it/s]\u001b[A\n",
            " 44%|████▍     | 78/178 [00:04<00:05, 17.93it/s]\u001b[A\n",
            " 45%|████▍     | 80/178 [00:04<00:05, 18.02it/s]\u001b[A\n",
            " 46%|████▌     | 82/178 [00:04<00:05, 18.25it/s]\u001b[A\n",
            " 47%|████▋     | 84/178 [00:04<00:05, 18.34it/s]\u001b[A\n",
            " 48%|████▊     | 86/178 [00:04<00:04, 18.46it/s]\u001b[A\n",
            " 49%|████▉     | 88/178 [00:04<00:04, 18.50it/s]\u001b[A\n",
            " 51%|█████     | 90/178 [00:04<00:04, 18.48it/s]\u001b[A\n",
            " 52%|█████▏    | 92/178 [00:05<00:04, 18.51it/s]\u001b[A\n",
            " 53%|█████▎    | 94/178 [00:05<00:04, 18.33it/s]\u001b[A\n",
            " 54%|█████▍    | 96/178 [00:05<00:04, 18.25it/s]\u001b[A\n",
            " 55%|█████▌    | 98/178 [00:05<00:04, 18.23it/s]\u001b[A\n",
            " 56%|█████▌    | 100/178 [00:05<00:04, 18.15it/s]\u001b[A\n",
            " 57%|█████▋    | 102/178 [00:05<00:04, 18.02it/s]\u001b[A\n",
            " 58%|█████▊    | 104/178 [00:05<00:04, 18.04it/s]\u001b[A\n",
            " 60%|█████▉    | 106/178 [00:05<00:04, 17.96it/s]\u001b[A\n",
            " 61%|██████    | 108/178 [00:05<00:03, 17.96it/s]\u001b[A\n",
            " 62%|██████▏   | 110/178 [00:06<00:03, 17.88it/s]\u001b[A\n",
            " 63%|██████▎   | 112/178 [00:06<00:03, 17.79it/s]\u001b[A\n",
            " 64%|██████▍   | 114/178 [00:06<00:03, 17.74it/s]\u001b[A\n",
            " 65%|██████▌   | 116/178 [00:06<00:03, 17.86it/s]\u001b[A\n",
            " 66%|██████▋   | 118/178 [00:06<00:03, 18.07it/s]\u001b[A\n",
            " 67%|██████▋   | 120/178 [00:06<00:03, 18.12it/s]\u001b[A\n",
            " 69%|██████▊   | 122/178 [00:06<00:03, 18.20it/s]\u001b[A\n",
            " 70%|██████▉   | 124/178 [00:06<00:02, 18.20it/s]\u001b[A\n",
            " 71%|███████   | 126/178 [00:06<00:02, 18.03it/s]\u001b[A\n",
            " 72%|███████▏  | 128/178 [00:07<00:02, 18.10it/s]\u001b[A\n",
            " 73%|███████▎  | 130/178 [00:07<00:02, 18.18it/s]\u001b[A\n",
            " 74%|███████▍  | 132/178 [00:07<00:02, 18.37it/s]\u001b[A\n",
            " 75%|███████▌  | 134/178 [00:07<00:02, 18.38it/s]\u001b[A\n",
            " 76%|███████▋  | 136/178 [00:07<00:02, 18.39it/s]\u001b[A\n",
            " 78%|███████▊  | 138/178 [00:07<00:02, 18.33it/s]\u001b[A\n",
            " 79%|███████▊  | 140/178 [00:07<00:02, 18.48it/s]\u001b[A\n",
            " 80%|███████▉  | 142/178 [00:07<00:01, 18.50it/s]\u001b[A\n",
            " 81%|████████  | 144/178 [00:07<00:01, 18.41it/s]\u001b[A\n",
            " 82%|████████▏ | 146/178 [00:08<00:01, 18.44it/s]\u001b[A\n",
            " 83%|████████▎ | 148/178 [00:08<00:01, 18.46it/s]\u001b[A\n",
            " 84%|████████▍ | 150/178 [00:08<00:01, 18.44it/s]\u001b[A\n",
            " 85%|████████▌ | 152/178 [00:08<00:01, 18.54it/s]\u001b[A\n",
            " 87%|████████▋ | 154/178 [00:08<00:01, 18.57it/s]\u001b[A\n",
            " 88%|████████▊ | 156/178 [00:08<00:01, 18.59it/s]\u001b[A\n",
            " 89%|████████▉ | 158/178 [00:08<00:01, 18.56it/s]\u001b[A\n",
            " 90%|████████▉ | 160/178 [00:08<00:00, 18.54it/s]\u001b[A\n",
            " 91%|█████████ | 162/178 [00:08<00:00, 18.46it/s]\u001b[A\n",
            " 92%|█████████▏| 164/178 [00:08<00:00, 18.42it/s]\u001b[A\n",
            " 93%|█████████▎| 166/178 [00:09<00:00, 18.14it/s]\u001b[A\n",
            " 94%|█████████▍| 168/178 [00:09<00:00, 18.10it/s]\u001b[A\n",
            " 96%|█████████▌| 170/178 [00:09<00:00, 18.18it/s]\u001b[A\n",
            " 97%|█████████▋| 172/178 [00:09<00:00, 18.36it/s]\u001b[A\n",
            " 98%|█████████▊| 174/178 [00:09<00:00, 18.39it/s]\u001b[A\n",
            "100%|██████████| 178/178 [00:09<00:00, 18.28it/s]\n",
            " 29%|██▊       | 406/1422 [01:20<52:03,  3.07s/it]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            " 29%|██▊       | 407/1422 [01:20<37:08,  2.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 0.3153 Val acc: 0.9043 Val f1: 0.9043 AUC: 0.4732\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 608/1422 [01:51<02:00,  6.76it/s]\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 2/178 [00:00<00:09, 19.18it/s]\u001b[A\n",
            "  2%|▏         | 4/178 [00:00<00:09, 18.81it/s]\u001b[A\n",
            "  3%|▎         | 6/178 [00:00<00:09, 18.64it/s]\u001b[A\n",
            "  4%|▍         | 8/178 [00:00<00:09, 18.70it/s]\u001b[A\n",
            "  6%|▌         | 10/178 [00:00<00:09, 18.34it/s]\u001b[A\n",
            "  7%|▋         | 12/178 [00:00<00:09, 18.36it/s]\u001b[A\n",
            "  8%|▊         | 14/178 [00:00<00:08, 18.23it/s]\u001b[A\n",
            "  9%|▉         | 16/178 [00:00<00:08, 18.26it/s]\u001b[A\n",
            " 10%|█         | 18/178 [00:00<00:08, 18.39it/s]\u001b[A\n",
            " 11%|█         | 20/178 [00:01<00:08, 18.45it/s]\u001b[A\n",
            " 12%|█▏        | 22/178 [00:01<00:08, 18.37it/s]\u001b[A\n",
            " 13%|█▎        | 24/178 [00:01<00:08, 18.35it/s]\u001b[A\n",
            " 15%|█▍        | 26/178 [00:01<00:08, 18.33it/s]\u001b[A\n",
            " 16%|█▌        | 28/178 [00:01<00:08, 18.31it/s]\u001b[A\n",
            " 17%|█▋        | 30/178 [00:01<00:08, 18.37it/s]\u001b[A\n",
            " 18%|█▊        | 32/178 [00:01<00:08, 18.22it/s]\u001b[A\n",
            " 19%|█▉        | 34/178 [00:01<00:07, 18.29it/s]\u001b[A\n",
            " 20%|██        | 36/178 [00:01<00:07, 18.28it/s]\u001b[A\n",
            " 21%|██▏       | 38/178 [00:02<00:07, 18.42it/s]\u001b[A\n",
            " 22%|██▏       | 40/178 [00:02<00:07, 18.46it/s]\u001b[A\n",
            " 24%|██▎       | 42/178 [00:02<00:07, 18.51it/s]\u001b[A\n",
            " 25%|██▍       | 44/178 [00:02<00:07, 18.51it/s]\u001b[A\n",
            " 26%|██▌       | 46/178 [00:02<00:07, 18.58it/s]\u001b[A\n",
            " 27%|██▋       | 48/178 [00:02<00:07, 18.53it/s]\u001b[A\n",
            " 28%|██▊       | 50/178 [00:02<00:06, 18.33it/s]\u001b[A\n",
            " 29%|██▉       | 52/178 [00:02<00:06, 18.20it/s]\u001b[A\n",
            " 30%|███       | 54/178 [00:02<00:06, 18.20it/s]\u001b[A\n",
            " 31%|███▏      | 56/178 [00:03<00:06, 18.22it/s]\u001b[A\n",
            " 33%|███▎      | 58/178 [00:03<00:06, 18.37it/s]\u001b[A\n",
            " 34%|███▎      | 60/178 [00:03<00:06, 18.49it/s]\u001b[A\n",
            " 35%|███▍      | 62/178 [00:03<00:06, 18.50it/s]\u001b[A\n",
            " 36%|███▌      | 64/178 [00:03<00:06, 18.48it/s]\u001b[A\n",
            " 37%|███▋      | 66/178 [00:03<00:06, 18.50it/s]\u001b[A\n",
            " 38%|███▊      | 68/178 [00:03<00:05, 18.49it/s]\u001b[A\n",
            " 39%|███▉      | 70/178 [00:03<00:05, 18.30it/s]\u001b[A\n",
            " 40%|████      | 72/178 [00:03<00:05, 18.36it/s]\u001b[A\n",
            " 42%|████▏     | 74/178 [00:04<00:05, 18.38it/s]\u001b[A\n",
            " 43%|████▎     | 76/178 [00:04<00:05, 18.42it/s]\u001b[A\n",
            " 44%|████▍     | 78/178 [00:04<00:05, 18.35it/s]\u001b[A\n",
            " 45%|████▍     | 80/178 [00:04<00:05, 18.34it/s]\u001b[A\n",
            " 46%|████▌     | 82/178 [00:04<00:05, 18.41it/s]\u001b[A\n",
            " 47%|████▋     | 84/178 [00:04<00:05, 18.45it/s]\u001b[A\n",
            " 48%|████▊     | 86/178 [00:04<00:04, 18.57it/s]\u001b[A\n",
            " 49%|████▉     | 88/178 [00:04<00:04, 18.39it/s]\u001b[A\n",
            " 51%|█████     | 90/178 [00:04<00:04, 18.30it/s]\u001b[A\n",
            " 52%|█████▏    | 92/178 [00:05<00:04, 18.23it/s]\u001b[A\n",
            " 53%|█████▎    | 94/178 [00:05<00:04, 18.14it/s]\u001b[A\n",
            " 54%|█████▍    | 96/178 [00:05<00:04, 18.24it/s]\u001b[A\n",
            " 55%|█████▌    | 98/178 [00:05<00:04, 18.10it/s]\u001b[A\n",
            " 56%|█████▌    | 100/178 [00:05<00:04, 18.08it/s]\u001b[A\n",
            " 57%|█████▋    | 102/178 [00:05<00:04, 17.98it/s]\u001b[A\n",
            " 58%|█████▊    | 104/178 [00:05<00:04, 18.00it/s]\u001b[A\n",
            " 60%|█████▉    | 106/178 [00:05<00:04, 17.92it/s]\u001b[A\n",
            " 61%|██████    | 108/178 [00:05<00:03, 17.92it/s]\u001b[A\n",
            " 62%|██████▏   | 110/178 [00:06<00:03, 18.00it/s]\u001b[A\n",
            " 63%|██████▎   | 112/178 [00:06<00:03, 18.05it/s]\u001b[A\n",
            " 64%|██████▍   | 114/178 [00:06<00:03, 18.03it/s]\u001b[A\n",
            " 65%|██████▌   | 116/178 [00:06<00:03, 18.02it/s]\u001b[A\n",
            " 66%|██████▋   | 118/178 [00:06<00:03, 18.12it/s]\u001b[A\n",
            " 67%|██████▋   | 120/178 [00:06<00:03, 18.18it/s]\u001b[A\n",
            " 69%|██████▊   | 122/178 [00:06<00:03, 18.28it/s]\u001b[A\n",
            " 70%|██████▉   | 124/178 [00:06<00:02, 18.35it/s]\u001b[A\n",
            " 71%|███████   | 126/178 [00:06<00:02, 18.34it/s]\u001b[A\n",
            " 72%|███████▏  | 128/178 [00:06<00:02, 18.39it/s]\u001b[A\n",
            " 73%|███████▎  | 130/178 [00:07<00:02, 18.33it/s]\u001b[A\n",
            " 74%|███████▍  | 132/178 [00:07<00:02, 18.24it/s]\u001b[A\n",
            " 75%|███████▌  | 134/178 [00:07<00:02, 18.22it/s]\u001b[A\n",
            " 76%|███████▋  | 136/178 [00:07<00:02, 18.22it/s]\u001b[A\n",
            " 78%|███████▊  | 138/178 [00:07<00:02, 18.22it/s]\u001b[A\n",
            " 79%|███████▊  | 140/178 [00:07<00:02, 18.23it/s]\u001b[A\n",
            " 80%|███████▉  | 142/178 [00:07<00:01, 18.27it/s]\u001b[A\n",
            " 81%|████████  | 144/178 [00:07<00:01, 18.30it/s]\u001b[A\n",
            " 82%|████████▏ | 146/178 [00:07<00:01, 18.35it/s]\u001b[A\n",
            " 83%|████████▎ | 148/178 [00:08<00:01, 18.26it/s]\u001b[A\n",
            " 84%|████████▍ | 150/178 [00:08<00:01, 18.26it/s]\u001b[A\n",
            " 85%|████████▌ | 152/178 [00:08<00:01, 18.20it/s]\u001b[A\n",
            " 87%|████████▋ | 154/178 [00:08<00:01, 18.04it/s]\u001b[A\n",
            " 88%|████████▊ | 156/178 [00:08<00:01, 18.06it/s]\u001b[A\n",
            " 89%|████████▉ | 158/178 [00:08<00:01, 18.04it/s]\u001b[A\n",
            " 90%|████████▉ | 160/178 [00:08<00:00, 18.05it/s]\u001b[A\n",
            " 91%|█████████ | 162/178 [00:08<00:00, 17.91it/s]\u001b[A\n",
            " 92%|█████████▏| 164/178 [00:08<00:00, 18.03it/s]\u001b[A\n",
            " 93%|█████████▎| 166/178 [00:09<00:00, 18.28it/s]\u001b[A\n",
            " 94%|█████████▍| 168/178 [00:09<00:00, 18.33it/s]\u001b[A\n",
            " 96%|█████████▌| 170/178 [00:09<00:00, 18.41it/s]\u001b[A\n",
            " 97%|█████████▋| 172/178 [00:09<00:00, 18.33it/s]\u001b[A\n",
            " 98%|█████████▊| 174/178 [00:09<00:00, 18.24it/s]\u001b[A\n",
            "100%|██████████| 178/178 [00:09<00:00, 18.31it/s]\n",
            " 43%|████▎     | 609/1422 [02:01<41:33,  3.07s/it]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            " 43%|████▎     | 610/1422 [02:01<29:39,  2.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 0.3159 Val acc: 0.9043 Val f1: 0.9043 AUC: 0.5112\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 811/1422 [02:31<01:29,  6.79it/s]\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 2/178 [00:00<00:09, 18.44it/s]\u001b[A\n",
            "  2%|▏         | 4/178 [00:00<00:09, 18.14it/s]\u001b[A\n",
            "  3%|▎         | 6/178 [00:00<00:09, 18.15it/s]\u001b[A\n",
            "  4%|▍         | 8/178 [00:00<00:09, 17.96it/s]\u001b[A\n",
            "  6%|▌         | 10/178 [00:00<00:09, 17.98it/s]\u001b[A\n",
            "  7%|▋         | 12/178 [00:00<00:09, 18.13it/s]\u001b[A\n",
            "  8%|▊         | 14/178 [00:00<00:09, 18.11it/s]\u001b[A\n",
            "  9%|▉         | 16/178 [00:00<00:09, 17.97it/s]\u001b[A\n",
            " 10%|█         | 18/178 [00:00<00:08, 17.99it/s]\u001b[A\n",
            " 11%|█         | 20/178 [00:01<00:08, 18.03it/s]\u001b[A\n",
            " 12%|█▏        | 22/178 [00:01<00:08, 18.01it/s]\u001b[A\n",
            " 13%|█▎        | 24/178 [00:01<00:08, 17.78it/s]\u001b[A\n",
            " 15%|█▍        | 26/178 [00:01<00:08, 17.84it/s]\u001b[A\n",
            " 16%|█▌        | 28/178 [00:01<00:08, 17.91it/s]\u001b[A\n",
            " 17%|█▋        | 30/178 [00:01<00:08, 18.06it/s]\u001b[A\n",
            " 18%|█▊        | 32/178 [00:01<00:08, 18.18it/s]\u001b[A\n",
            " 19%|█▉        | 34/178 [00:01<00:07, 18.09it/s]\u001b[A\n",
            " 20%|██        | 36/178 [00:01<00:07, 18.05it/s]\u001b[A\n",
            " 21%|██▏       | 38/178 [00:02<00:07, 18.15it/s]\u001b[A\n",
            " 22%|██▏       | 40/178 [00:02<00:07, 18.17it/s]\u001b[A\n",
            " 24%|██▎       | 42/178 [00:02<00:07, 18.03it/s]\u001b[A\n",
            " 25%|██▍       | 44/178 [00:02<00:07, 17.89it/s]\u001b[A\n",
            " 26%|██▌       | 46/178 [00:02<00:07, 17.99it/s]\u001b[A\n",
            " 27%|██▋       | 48/178 [00:02<00:07, 18.13it/s]\u001b[A\n",
            " 28%|██▊       | 50/178 [00:02<00:07, 18.12it/s]\u001b[A\n",
            " 29%|██▉       | 52/178 [00:02<00:06, 18.09it/s]\u001b[A\n",
            " 30%|███       | 54/178 [00:02<00:06, 17.96it/s]\u001b[A\n",
            " 31%|███▏      | 56/178 [00:03<00:06, 18.11it/s]\u001b[A\n",
            " 33%|███▎      | 58/178 [00:03<00:06, 18.14it/s]\u001b[A\n",
            " 34%|███▎      | 60/178 [00:03<00:06, 18.19it/s]\u001b[A\n",
            " 35%|███▍      | 62/178 [00:03<00:06, 18.24it/s]\u001b[A\n",
            " 36%|███▌      | 64/178 [00:03<00:06, 18.25it/s]\u001b[A\n",
            " 37%|███▋      | 66/178 [00:03<00:06, 18.24it/s]\u001b[A\n",
            " 38%|███▊      | 68/178 [00:03<00:06, 18.23it/s]\u001b[A\n",
            " 39%|███▉      | 70/178 [00:03<00:05, 18.14it/s]\u001b[A\n",
            " 40%|████      | 72/178 [00:03<00:05, 18.11it/s]\u001b[A\n",
            " 42%|████▏     | 74/178 [00:04<00:05, 18.20it/s]\u001b[A\n",
            " 43%|████▎     | 76/178 [00:04<00:05, 18.30it/s]\u001b[A\n",
            " 44%|████▍     | 78/178 [00:04<00:05, 18.35it/s]\u001b[A\n",
            " 45%|████▍     | 80/178 [00:04<00:05, 18.32it/s]\u001b[A\n",
            " 46%|████▌     | 82/178 [00:04<00:05, 18.33it/s]\u001b[A\n",
            " 47%|████▋     | 84/178 [00:04<00:05, 18.40it/s]\u001b[A\n",
            " 48%|████▊     | 86/178 [00:04<00:04, 18.50it/s]\u001b[A\n",
            " 49%|████▉     | 88/178 [00:04<00:04, 18.51it/s]\u001b[A\n",
            " 51%|█████     | 90/178 [00:04<00:04, 18.51it/s]\u001b[A\n",
            " 52%|█████▏    | 92/178 [00:05<00:04, 18.48it/s]\u001b[A\n",
            " 53%|█████▎    | 94/178 [00:05<00:04, 18.46it/s]\u001b[A\n",
            " 54%|█████▍    | 96/178 [00:05<00:04, 18.33it/s]\u001b[A\n",
            " 55%|█████▌    | 98/178 [00:05<00:04, 18.21it/s]\u001b[A\n",
            " 56%|█████▌    | 100/178 [00:05<00:04, 18.03it/s]\u001b[A\n",
            " 57%|█████▋    | 102/178 [00:05<00:04, 18.10it/s]\u001b[A\n",
            " 58%|█████▊    | 104/178 [00:05<00:04, 18.26it/s]\u001b[A\n",
            " 60%|█████▉    | 106/178 [00:05<00:03, 18.27it/s]\u001b[A\n",
            " 61%|██████    | 108/178 [00:05<00:03, 18.40it/s]\u001b[A\n",
            " 62%|██████▏   | 110/178 [00:06<00:03, 18.44it/s]\u001b[A\n",
            " 63%|██████▎   | 112/178 [00:06<00:03, 18.47it/s]\u001b[A\n",
            " 64%|██████▍   | 114/178 [00:06<00:03, 18.52it/s]\u001b[A\n",
            " 65%|██████▌   | 116/178 [00:06<00:03, 18.59it/s]\u001b[A\n",
            " 66%|██████▋   | 118/178 [00:06<00:03, 18.55it/s]\u001b[A\n",
            " 67%|██████▋   | 120/178 [00:06<00:03, 18.56it/s]\u001b[A\n",
            " 69%|██████▊   | 122/178 [00:06<00:03, 18.58it/s]\u001b[A\n",
            " 70%|██████▉   | 124/178 [00:06<00:02, 18.55it/s]\u001b[A\n",
            " 71%|███████   | 126/178 [00:06<00:02, 18.42it/s]\u001b[A\n",
            " 72%|███████▏  | 128/178 [00:07<00:02, 18.31it/s]\u001b[A\n",
            " 73%|███████▎  | 130/178 [00:07<00:02, 18.44it/s]\u001b[A\n",
            " 74%|███████▍  | 132/178 [00:07<00:02, 18.42it/s]\u001b[A\n",
            " 75%|███████▌  | 134/178 [00:07<00:02, 18.48it/s]\u001b[A\n",
            " 76%|███████▋  | 136/178 [00:07<00:02, 18.51it/s]\u001b[A\n",
            " 78%|███████▊  | 138/178 [00:07<00:02, 18.48it/s]\u001b[A\n",
            " 79%|███████▊  | 140/178 [00:07<00:02, 18.52it/s]\u001b[A\n",
            " 80%|███████▉  | 142/178 [00:07<00:01, 18.47it/s]\u001b[A\n",
            " 81%|████████  | 144/178 [00:07<00:01, 18.42it/s]\u001b[A\n",
            " 82%|████████▏ | 146/178 [00:08<00:01, 18.38it/s]\u001b[A\n",
            " 83%|████████▎ | 148/178 [00:08<00:01, 18.38it/s]\u001b[A\n",
            " 84%|████████▍ | 150/178 [00:08<00:01, 18.23it/s]\u001b[A\n",
            " 85%|████████▌ | 152/178 [00:08<00:01, 18.18it/s]\u001b[A\n",
            " 87%|████████▋ | 154/178 [00:08<00:01, 18.17it/s]\u001b[A\n",
            " 88%|████████▊ | 156/178 [00:08<00:01, 18.20it/s]\u001b[A\n",
            " 89%|████████▉ | 158/178 [00:08<00:01, 18.37it/s]\u001b[A\n",
            " 90%|████████▉ | 160/178 [00:08<00:00, 18.46it/s]\u001b[A\n",
            " 91%|█████████ | 162/178 [00:08<00:00, 18.45it/s]\u001b[A\n",
            " 92%|█████████▏| 164/178 [00:08<00:00, 18.41it/s]\u001b[A\n",
            " 93%|█████████▎| 166/178 [00:09<00:00, 18.20it/s]\u001b[A\n",
            " 94%|█████████▍| 168/178 [00:09<00:00, 18.05it/s]\u001b[A\n",
            " 96%|█████████▌| 170/178 [00:09<00:00, 18.00it/s]\u001b[A\n",
            " 97%|█████████▋| 172/178 [00:09<00:00, 18.04it/s]\u001b[A\n",
            " 98%|█████████▊| 174/178 [00:09<00:00, 18.18it/s]\u001b[A\n",
            "100%|██████████| 178/178 [00:09<00:00, 18.28it/s]\n",
            " 57%|█████▋    | 812/1422 [02:41<31:14,  3.07s/it]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            " 57%|█████▋    | 813/1422 [02:41<22:16,  2.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 0.3165 Val acc: 0.9043 Val f1: 0.9043 AUC: 0.5025\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 71%|███████▏  | 1014/1422 [03:12<01:00,  6.75it/s]\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 2/178 [00:00<00:09, 18.21it/s]\u001b[A\n",
            "  2%|▏         | 4/178 [00:00<00:09, 18.22it/s]\u001b[A\n",
            "  3%|▎         | 6/178 [00:00<00:09, 18.23it/s]\u001b[A\n",
            "  4%|▍         | 8/178 [00:00<00:09, 18.19it/s]\u001b[A\n",
            "  6%|▌         | 10/178 [00:00<00:09, 18.06it/s]\u001b[A\n",
            "  7%|▋         | 12/178 [00:00<00:09, 18.19it/s]\u001b[A\n",
            "  8%|▊         | 14/178 [00:00<00:08, 18.22it/s]\u001b[A\n",
            "  9%|▉         | 16/178 [00:00<00:08, 18.02it/s]\u001b[A\n",
            " 10%|█         | 18/178 [00:00<00:08, 17.98it/s]\u001b[A\n",
            " 11%|█         | 20/178 [00:01<00:08, 17.83it/s]\u001b[A\n",
            " 12%|█▏        | 22/178 [00:01<00:08, 17.96it/s]\u001b[A\n",
            " 13%|█▎        | 24/178 [00:01<00:08, 18.06it/s]\u001b[A\n",
            " 15%|█▍        | 26/178 [00:01<00:08, 18.14it/s]\u001b[A\n",
            " 16%|█▌        | 28/178 [00:01<00:08, 18.15it/s]\u001b[A\n",
            " 17%|█▋        | 30/178 [00:01<00:08, 18.19it/s]\u001b[A\n",
            " 18%|█▊        | 32/178 [00:01<00:08, 18.16it/s]\u001b[A\n",
            " 19%|█▉        | 34/178 [00:01<00:07, 18.19it/s]\u001b[A\n",
            " 20%|██        | 36/178 [00:01<00:07, 18.29it/s]\u001b[A\n",
            " 21%|██▏       | 38/178 [00:02<00:07, 18.20it/s]\u001b[A\n",
            " 22%|██▏       | 40/178 [00:02<00:07, 18.06it/s]\u001b[A\n",
            " 24%|██▎       | 42/178 [00:02<00:07, 17.86it/s]\u001b[A\n",
            " 25%|██▍       | 44/178 [00:02<00:07, 17.80it/s]\u001b[A\n",
            " 26%|██▌       | 46/178 [00:02<00:07, 17.76it/s]\u001b[A\n",
            " 27%|██▋       | 48/178 [00:02<00:07, 17.72it/s]\u001b[A\n",
            " 28%|██▊       | 50/178 [00:02<00:07, 17.73it/s]\u001b[A\n",
            " 29%|██▉       | 52/178 [00:02<00:07, 17.68it/s]\u001b[A\n",
            " 30%|███       | 54/178 [00:03<00:06, 17.73it/s]\u001b[A\n",
            " 31%|███▏      | 56/178 [00:03<00:06, 17.69it/s]\u001b[A\n",
            " 33%|███▎      | 58/178 [00:03<00:06, 17.74it/s]\u001b[A\n",
            " 34%|███▎      | 60/178 [00:03<00:06, 17.77it/s]\u001b[A\n",
            " 35%|███▍      | 62/178 [00:03<00:06, 17.83it/s]\u001b[A\n",
            " 36%|███▌      | 64/178 [00:03<00:06, 17.87it/s]\u001b[A\n",
            " 37%|███▋      | 66/178 [00:03<00:06, 17.87it/s]\u001b[A\n",
            " 38%|███▊      | 68/178 [00:03<00:06, 17.84it/s]\u001b[A\n",
            " 39%|███▉      | 70/178 [00:03<00:06, 17.83it/s]\u001b[A\n",
            " 40%|████      | 72/178 [00:04<00:05, 17.85it/s]\u001b[A\n",
            " 42%|████▏     | 74/178 [00:04<00:05, 17.79it/s]\u001b[A\n",
            " 43%|████▎     | 76/178 [00:04<00:05, 17.79it/s]\u001b[A\n",
            " 44%|████▍     | 78/178 [00:04<00:05, 17.83it/s]\u001b[A\n",
            " 45%|████▍     | 80/178 [00:04<00:05, 17.90it/s]\u001b[A\n",
            " 46%|████▌     | 82/178 [00:04<00:05, 17.90it/s]\u001b[A\n",
            " 47%|████▋     | 84/178 [00:04<00:05, 17.85it/s]\u001b[A\n",
            " 48%|████▊     | 86/178 [00:04<00:05, 17.83it/s]\u001b[A\n",
            " 49%|████▉     | 88/178 [00:04<00:05, 17.78it/s]\u001b[A\n",
            " 51%|█████     | 90/178 [00:05<00:04, 17.71it/s]\u001b[A\n",
            " 52%|█████▏    | 92/178 [00:05<00:04, 17.73it/s]\u001b[A\n",
            " 53%|█████▎    | 94/178 [00:05<00:04, 17.86it/s]\u001b[A\n",
            " 54%|█████▍    | 96/178 [00:05<00:04, 17.94it/s]\u001b[A\n",
            " 55%|█████▌    | 98/178 [00:05<00:04, 17.91it/s]\u001b[A\n",
            " 56%|█████▌    | 100/178 [00:05<00:04, 17.91it/s]\u001b[A\n",
            " 57%|█████▋    | 102/178 [00:05<00:04, 17.88it/s]\u001b[A\n",
            " 58%|█████▊    | 104/178 [00:05<00:04, 17.81it/s]\u001b[A\n",
            " 60%|█████▉    | 106/178 [00:05<00:04, 17.73it/s]\u001b[A\n",
            " 61%|██████    | 108/178 [00:06<00:03, 17.65it/s]\u001b[A\n",
            " 62%|██████▏   | 110/178 [00:06<00:03, 17.64it/s]\u001b[A\n",
            " 63%|██████▎   | 112/178 [00:06<00:03, 17.57it/s]\u001b[A\n",
            " 64%|██████▍   | 114/178 [00:06<00:03, 17.55it/s]\u001b[A\n",
            " 65%|██████▌   | 116/178 [00:06<00:03, 17.49it/s]\u001b[A\n",
            " 66%|██████▋   | 118/178 [00:06<00:03, 17.52it/s]\u001b[A\n",
            " 67%|██████▋   | 120/178 [00:06<00:03, 17.65it/s]\u001b[A\n",
            " 69%|██████▊   | 122/178 [00:06<00:03, 17.66it/s]\u001b[A\n",
            " 70%|██████▉   | 124/178 [00:06<00:03, 17.83it/s]\u001b[A\n",
            " 71%|███████   | 126/178 [00:07<00:02, 17.92it/s]\u001b[A\n",
            " 72%|███████▏  | 128/178 [00:07<00:02, 17.99it/s]\u001b[A\n",
            " 73%|███████▎  | 130/178 [00:07<00:02, 18.11it/s]\u001b[A\n",
            " 74%|███████▍  | 132/178 [00:07<00:02, 18.13it/s]\u001b[A\n",
            " 75%|███████▌  | 134/178 [00:07<00:02, 18.16it/s]\u001b[A\n",
            " 76%|███████▋  | 136/178 [00:07<00:02, 18.17it/s]\u001b[A\n",
            " 78%|███████▊  | 138/178 [00:07<00:02, 18.11it/s]\u001b[A\n",
            " 79%|███████▊  | 140/178 [00:07<00:02, 18.10it/s]\u001b[A\n",
            " 80%|███████▉  | 142/178 [00:07<00:01, 18.08it/s]\u001b[A\n",
            " 81%|████████  | 144/178 [00:08<00:01, 18.16it/s]\u001b[A\n",
            " 82%|████████▏ | 146/178 [00:08<00:01, 18.06it/s]\u001b[A\n",
            " 83%|████████▎ | 148/178 [00:08<00:01, 18.04it/s]\u001b[A\n",
            " 84%|████████▍ | 150/178 [00:08<00:01, 18.15it/s]\u001b[A\n",
            " 85%|████████▌ | 152/178 [00:08<00:01, 18.17it/s]\u001b[A\n",
            " 87%|████████▋ | 154/178 [00:08<00:01, 18.27it/s]\u001b[A\n",
            " 88%|████████▊ | 156/178 [00:08<00:01, 18.11it/s]\u001b[A\n",
            " 89%|████████▉ | 158/178 [00:08<00:01, 18.06it/s]\u001b[A\n",
            " 90%|████████▉ | 160/178 [00:08<00:01, 17.98it/s]\u001b[A\n",
            " 91%|█████████ | 162/178 [00:09<00:00, 18.01it/s]\u001b[A\n",
            " 92%|█████████▏| 164/178 [00:09<00:00, 18.11it/s]\u001b[A\n",
            " 93%|█████████▎| 166/178 [00:09<00:00, 18.14it/s]\u001b[A\n",
            " 94%|█████████▍| 168/178 [00:09<00:00, 18.14it/s]\u001b[A\n",
            " 96%|█████████▌| 170/178 [00:09<00:00, 18.19it/s]\u001b[A\n",
            " 97%|█████████▋| 172/178 [00:09<00:00, 18.18it/s]\u001b[A\n",
            " 98%|█████████▊| 174/178 [00:09<00:00, 18.27it/s]\u001b[A\n",
            "100%|██████████| 178/178 [00:09<00:00, 17.98it/s]\n",
            " 71%|███████▏  | 1015/1422 [03:22<21:10,  3.12s/it]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            " 71%|███████▏  | 1016/1422 [03:22<15:05,  2.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 0.3178 Val acc: 0.9043 Val f1: 0.9043 AUC: 0.5024\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 1217/1422 [03:52<00:30,  6.82it/s]\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 2/178 [00:00<00:09, 18.21it/s]\u001b[A\n",
            "  2%|▏         | 4/178 [00:00<00:09, 18.37it/s]\u001b[A\n",
            "  3%|▎         | 6/178 [00:00<00:09, 18.25it/s]\u001b[A\n",
            "  4%|▍         | 8/178 [00:00<00:09, 18.29it/s]\u001b[A\n",
            "  6%|▌         | 10/178 [00:00<00:09, 18.30it/s]\u001b[A\n",
            "  7%|▋         | 12/178 [00:00<00:09, 18.21it/s]\u001b[A\n",
            "  8%|▊         | 14/178 [00:00<00:09, 18.10it/s]\u001b[A\n",
            "  9%|▉         | 16/178 [00:00<00:08, 18.18it/s]\u001b[A\n",
            " 10%|█         | 18/178 [00:00<00:08, 18.17it/s]\u001b[A\n",
            " 11%|█         | 20/178 [00:01<00:08, 18.39it/s]\u001b[A\n",
            " 12%|█▏        | 22/178 [00:01<00:08, 18.38it/s]\u001b[A\n",
            " 13%|█▎        | 24/178 [00:01<00:08, 18.45it/s]\u001b[A\n",
            " 15%|█▍        | 26/178 [00:01<00:08, 18.41it/s]\u001b[A\n",
            " 16%|█▌        | 28/178 [00:01<00:08, 18.47it/s]\u001b[A\n",
            " 17%|█▋        | 30/178 [00:01<00:08, 18.43it/s]\u001b[A\n",
            " 18%|█▊        | 32/178 [00:01<00:07, 18.50it/s]\u001b[A\n",
            " 19%|█▉        | 34/178 [00:01<00:07, 18.52it/s]\u001b[A\n",
            " 20%|██        | 36/178 [00:01<00:07, 18.43it/s]\u001b[A\n",
            " 21%|██▏       | 38/178 [00:02<00:07, 18.47it/s]\u001b[A\n",
            " 22%|██▏       | 40/178 [00:02<00:07, 18.43it/s]\u001b[A\n",
            " 24%|██▎       | 42/178 [00:02<00:07, 18.45it/s]\u001b[A\n",
            " 25%|██▍       | 44/178 [00:02<00:07, 18.51it/s]\u001b[A\n",
            " 26%|██▌       | 46/178 [00:02<00:07, 18.48it/s]\u001b[A\n",
            " 27%|██▋       | 48/178 [00:02<00:07, 18.49it/s]\u001b[A\n",
            " 28%|██▊       | 50/178 [00:02<00:06, 18.51it/s]\u001b[A\n",
            " 29%|██▉       | 52/178 [00:02<00:06, 18.53it/s]\u001b[A\n",
            " 30%|███       | 54/178 [00:02<00:06, 18.52it/s]\u001b[A\n",
            " 31%|███▏      | 56/178 [00:03<00:06, 18.54it/s]\u001b[A\n",
            " 33%|███▎      | 58/178 [00:03<00:06, 18.43it/s]\u001b[A\n",
            " 34%|███▎      | 60/178 [00:03<00:06, 18.41it/s]\u001b[A\n",
            " 35%|███▍      | 62/178 [00:03<00:06, 18.42it/s]\u001b[A\n",
            " 36%|███▌      | 64/178 [00:03<00:06, 18.37it/s]\u001b[A\n",
            " 37%|███▋      | 66/178 [00:03<00:06, 18.31it/s]\u001b[A\n",
            " 38%|███▊      | 68/178 [00:03<00:06, 18.31it/s]\u001b[A\n",
            " 39%|███▉      | 70/178 [00:03<00:05, 18.28it/s]\u001b[A\n",
            " 40%|████      | 72/178 [00:03<00:05, 18.23it/s]\u001b[A\n",
            " 42%|████▏     | 74/178 [00:04<00:05, 18.29it/s]\u001b[A\n",
            " 43%|████▎     | 76/178 [00:04<00:05, 18.30it/s]\u001b[A\n",
            " 44%|████▍     | 78/178 [00:04<00:05, 18.30it/s]\u001b[A\n",
            " 45%|████▍     | 80/178 [00:04<00:05, 18.33it/s]\u001b[A\n",
            " 46%|████▌     | 82/178 [00:04<00:05, 18.25it/s]\u001b[A\n",
            " 47%|████▋     | 84/178 [00:04<00:05, 18.27it/s]\u001b[A\n",
            " 48%|████▊     | 86/178 [00:04<00:05, 18.30it/s]\u001b[A\n",
            " 49%|████▉     | 88/178 [00:04<00:04, 18.31it/s]\u001b[A\n",
            " 51%|█████     | 90/178 [00:04<00:04, 18.30it/s]\u001b[A\n",
            " 52%|█████▏    | 92/178 [00:05<00:04, 18.29it/s]\u001b[A\n",
            " 53%|█████▎    | 94/178 [00:05<00:04, 18.26it/s]\u001b[A\n",
            " 54%|█████▍    | 96/178 [00:05<00:04, 18.12it/s]\u001b[A\n",
            " 55%|█████▌    | 98/178 [00:05<00:04, 18.18it/s]\u001b[A\n",
            " 56%|█████▌    | 100/178 [00:05<00:04, 18.16it/s]\u001b[A\n",
            " 57%|█████▋    | 102/178 [00:05<00:04, 18.15it/s]\u001b[A\n",
            " 58%|█████▊    | 104/178 [00:05<00:04, 18.13it/s]\u001b[A\n",
            " 60%|█████▉    | 106/178 [00:05<00:03, 18.13it/s]\u001b[A\n",
            " 61%|██████    | 108/178 [00:05<00:03, 18.12it/s]\u001b[A\n",
            " 62%|██████▏   | 110/178 [00:06<00:03, 18.15it/s]\u001b[A\n",
            " 63%|██████▎   | 112/178 [00:06<00:03, 18.22it/s]\u001b[A\n",
            " 64%|██████▍   | 114/178 [00:06<00:03, 18.22it/s]\u001b[A\n",
            " 65%|██████▌   | 116/178 [00:06<00:03, 18.25it/s]\u001b[A\n",
            " 66%|██████▋   | 118/178 [00:06<00:03, 18.19it/s]\u001b[A\n",
            " 67%|██████▋   | 120/178 [00:06<00:03, 18.23it/s]\u001b[A\n",
            " 69%|██████▊   | 122/178 [00:06<00:03, 18.18it/s]\u001b[A\n",
            " 70%|██████▉   | 124/178 [00:06<00:02, 18.22it/s]\u001b[A\n",
            " 71%|███████   | 126/178 [00:06<00:02, 18.24it/s]\u001b[A\n",
            " 72%|███████▏  | 128/178 [00:06<00:02, 18.24it/s]\u001b[A\n",
            " 73%|███████▎  | 130/178 [00:07<00:02, 18.25it/s]\u001b[A\n",
            " 74%|███████▍  | 132/178 [00:07<00:02, 18.05it/s]\u001b[A\n",
            " 75%|███████▌  | 134/178 [00:07<00:02, 18.13it/s]\u001b[A\n",
            " 76%|███████▋  | 136/178 [00:07<00:02, 18.20it/s]\u001b[A\n",
            " 78%|███████▊  | 138/178 [00:07<00:02, 18.16it/s]\u001b[A\n",
            " 79%|███████▊  | 140/178 [00:07<00:02, 18.21it/s]\u001b[A\n",
            " 80%|███████▉  | 142/178 [00:07<00:01, 18.27it/s]\u001b[A\n",
            " 81%|████████  | 144/178 [00:07<00:01, 18.26it/s]\u001b[A\n",
            " 82%|████████▏ | 146/178 [00:07<00:01, 18.34it/s]\u001b[A\n",
            " 83%|████████▎ | 148/178 [00:08<00:01, 18.27it/s]\u001b[A\n",
            " 84%|████████▍ | 150/178 [00:08<00:01, 18.24it/s]\u001b[A\n",
            " 85%|████████▌ | 152/178 [00:08<00:01, 18.22it/s]\u001b[A\n",
            " 87%|████████▋ | 154/178 [00:08<00:01, 18.32it/s]\u001b[A\n",
            " 88%|████████▊ | 156/178 [00:08<00:01, 18.34it/s]\u001b[A\n",
            " 89%|████████▉ | 158/178 [00:08<00:01, 18.38it/s]\u001b[A\n",
            " 90%|████████▉ | 160/178 [00:08<00:00, 18.33it/s]\u001b[A\n",
            " 91%|█████████ | 162/178 [00:08<00:00, 18.42it/s]\u001b[A\n",
            " 92%|█████████▏| 164/178 [00:08<00:00, 18.36it/s]\u001b[A\n",
            " 93%|█████████▎| 166/178 [00:09<00:00, 18.27it/s]\u001b[A\n",
            " 94%|█████████▍| 168/178 [00:09<00:00, 18.26it/s]\u001b[A\n",
            " 96%|█████████▌| 170/178 [00:09<00:00, 18.20it/s]\u001b[A\n",
            " 97%|█████████▋| 172/178 [00:09<00:00, 18.25it/s]\u001b[A\n",
            " 98%|█████████▊| 174/178 [00:09<00:00, 18.31it/s]\u001b[A\n",
            "100%|██████████| 178/178 [00:09<00:00, 18.33it/s]\n",
            " 86%|████████▌ | 1218/1422 [04:02<10:24,  3.06s/it]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            " 86%|████████▌ | 1219/1422 [04:02<07:24,  2.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 0.3166 Val acc: 0.9043 Val f1: 0.9043 AUC: 0.5079\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 1420/1422 [04:33<00:00,  5.77it/s]\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 2/178 [00:00<00:09, 18.59it/s]\u001b[A\n",
            "  2%|▏         | 4/178 [00:00<00:09, 18.13it/s]\u001b[A\n",
            "  3%|▎         | 6/178 [00:00<00:09, 17.73it/s]\u001b[A\n",
            "  4%|▍         | 8/178 [00:00<00:09, 17.61it/s]\u001b[A\n",
            "  6%|▌         | 10/178 [00:00<00:09, 17.58it/s]\u001b[A\n",
            "  7%|▋         | 12/178 [00:00<00:09, 17.52it/s]\u001b[A\n",
            "  8%|▊         | 14/178 [00:00<00:09, 17.56it/s]\u001b[A\n",
            "  9%|▉         | 16/178 [00:00<00:09, 17.53it/s]\u001b[A\n",
            " 10%|█         | 18/178 [00:01<00:09, 17.58it/s]\u001b[A\n",
            " 11%|█         | 20/178 [00:01<00:08, 17.59it/s]\u001b[A\n",
            " 12%|█▏        | 22/178 [00:01<00:08, 17.51it/s]\u001b[A\n",
            " 13%|█▎        | 24/178 [00:01<00:08, 17.47it/s]\u001b[A\n",
            " 15%|█▍        | 26/178 [00:01<00:08, 17.65it/s]\u001b[A\n",
            " 16%|█▌        | 28/178 [00:01<00:08, 17.65it/s]\u001b[A\n",
            " 17%|█▋        | 30/178 [00:01<00:08, 17.63it/s]\u001b[A\n",
            " 18%|█▊        | 32/178 [00:01<00:08, 17.48it/s]\u001b[A\n",
            " 19%|█▉        | 34/178 [00:01<00:08, 17.49it/s]\u001b[A\n",
            " 20%|██        | 36/178 [00:02<00:08, 17.56it/s]\u001b[A\n",
            " 21%|██▏       | 38/178 [00:02<00:07, 17.57it/s]\u001b[A\n",
            " 22%|██▏       | 40/178 [00:02<00:07, 17.64it/s]\u001b[A\n",
            " 24%|██▎       | 42/178 [00:02<00:07, 17.62it/s]\u001b[A\n",
            " 25%|██▍       | 44/178 [00:02<00:07, 17.61it/s]\u001b[A\n",
            " 26%|██▌       | 46/178 [00:02<00:07, 17.51it/s]\u001b[A\n",
            " 27%|██▋       | 48/178 [00:02<00:07, 17.56it/s]\u001b[A\n",
            " 28%|██▊       | 50/178 [00:02<00:07, 17.53it/s]\u001b[A\n",
            " 29%|██▉       | 52/178 [00:02<00:07, 17.52it/s]\u001b[A\n",
            " 30%|███       | 54/178 [00:03<00:07, 17.59it/s]\u001b[A\n",
            " 31%|███▏      | 56/178 [00:03<00:06, 17.66it/s]\u001b[A\n",
            " 33%|███▎      | 58/178 [00:03<00:06, 17.65it/s]\u001b[A\n",
            " 34%|███▎      | 60/178 [00:03<00:06, 17.63it/s]\u001b[A\n",
            " 35%|███▍      | 62/178 [00:03<00:06, 17.60it/s]\u001b[A\n",
            " 36%|███▌      | 64/178 [00:03<00:06, 17.69it/s]\u001b[A\n",
            " 37%|███▋      | 66/178 [00:03<00:06, 17.66it/s]\u001b[A\n",
            " 38%|███▊      | 68/178 [00:03<00:06, 17.68it/s]\u001b[A\n",
            " 39%|███▉      | 70/178 [00:03<00:06, 17.79it/s]\u001b[A\n",
            " 40%|████      | 72/178 [00:04<00:05, 17.81it/s]\u001b[A\n",
            " 42%|████▏     | 74/178 [00:04<00:05, 17.77it/s]\u001b[A\n",
            " 43%|████▎     | 76/178 [00:04<00:05, 17.82it/s]\u001b[A\n",
            " 44%|████▍     | 78/178 [00:04<00:05, 17.86it/s]\u001b[A\n",
            " 45%|████▍     | 80/178 [00:04<00:05, 17.77it/s]\u001b[A\n",
            " 46%|████▌     | 82/178 [00:04<00:05, 17.68it/s]\u001b[A\n",
            " 47%|████▋     | 84/178 [00:04<00:05, 17.64it/s]\u001b[A\n",
            " 48%|████▊     | 86/178 [00:04<00:05, 17.68it/s]\u001b[A\n",
            " 49%|████▉     | 88/178 [00:04<00:05, 17.80it/s]\u001b[A\n",
            " 51%|█████     | 90/178 [00:05<00:04, 17.74it/s]\u001b[A\n",
            " 52%|█████▏    | 92/178 [00:05<00:04, 17.81it/s]\u001b[A\n",
            " 53%|█████▎    | 94/178 [00:05<00:04, 17.79it/s]\u001b[A\n",
            " 54%|█████▍    | 96/178 [00:05<00:04, 17.76it/s]\u001b[A\n",
            " 55%|█████▌    | 98/178 [00:05<00:04, 17.68it/s]\u001b[A\n",
            " 56%|█████▌    | 100/178 [00:05<00:04, 17.65it/s]\u001b[A\n",
            " 57%|█████▋    | 102/178 [00:05<00:04, 17.64it/s]\u001b[A\n",
            " 58%|█████▊    | 104/178 [00:05<00:04, 17.67it/s]\u001b[A\n",
            " 60%|█████▉    | 106/178 [00:06<00:04, 17.70it/s]\u001b[A\n",
            " 61%|██████    | 108/178 [00:06<00:03, 17.68it/s]\u001b[A\n",
            " 62%|██████▏   | 110/178 [00:06<00:03, 17.66it/s]\u001b[A\n",
            " 63%|██████▎   | 112/178 [00:06<00:03, 17.65it/s]\u001b[A\n",
            " 64%|██████▍   | 114/178 [00:06<00:03, 17.56it/s]\u001b[A\n",
            " 65%|██████▌   | 116/178 [00:06<00:03, 17.58it/s]\u001b[A\n",
            " 66%|██████▋   | 118/178 [00:06<00:03, 17.61it/s]\u001b[A\n",
            " 67%|██████▋   | 120/178 [00:06<00:03, 17.67it/s]\u001b[A\n",
            " 69%|██████▊   | 122/178 [00:06<00:03, 17.68it/s]\u001b[A\n",
            " 70%|██████▉   | 124/178 [00:07<00:03, 17.70it/s]\u001b[A\n",
            " 71%|███████   | 126/178 [00:07<00:02, 17.72it/s]\u001b[A\n",
            " 72%|███████▏  | 128/178 [00:07<00:02, 17.70it/s]\u001b[A\n",
            " 73%|███████▎  | 130/178 [00:07<00:02, 17.63it/s]\u001b[A\n",
            " 74%|███████▍  | 132/178 [00:07<00:02, 17.57it/s]\u001b[A\n",
            " 75%|███████▌  | 134/178 [00:07<00:02, 17.62it/s]\u001b[A\n",
            " 76%|███████▋  | 136/178 [00:07<00:02, 17.61it/s]\u001b[A\n",
            " 78%|███████▊  | 138/178 [00:07<00:02, 17.66it/s]\u001b[A\n",
            " 79%|███████▊  | 140/178 [00:07<00:02, 17.73it/s]\u001b[A\n",
            " 80%|███████▉  | 142/178 [00:08<00:02, 17.69it/s]\u001b[A\n",
            " 81%|████████  | 144/178 [00:08<00:01, 17.66it/s]\u001b[A\n",
            " 82%|████████▏ | 146/178 [00:08<00:01, 17.64it/s]\u001b[A\n",
            " 83%|████████▎ | 148/178 [00:08<00:01, 17.64it/s]\u001b[A\n",
            " 84%|████████▍ | 150/178 [00:08<00:01, 17.60it/s]\u001b[A\n",
            " 85%|████████▌ | 152/178 [00:08<00:01, 17.65it/s]\u001b[A\n",
            " 87%|████████▋ | 154/178 [00:08<00:01, 17.58it/s]\u001b[A\n",
            " 88%|████████▊ | 156/178 [00:08<00:01, 17.53it/s]\u001b[A\n",
            " 89%|████████▉ | 158/178 [00:08<00:01, 17.53it/s]\u001b[A\n",
            " 90%|████████▉ | 160/178 [00:09<00:01, 17.38it/s]\u001b[A\n",
            " 91%|█████████ | 162/178 [00:09<00:00, 17.45it/s]\u001b[A\n",
            " 92%|█████████▏| 164/178 [00:09<00:00, 17.52it/s]\u001b[A\n",
            " 93%|█████████▎| 166/178 [00:09<00:00, 17.53it/s]\u001b[A\n",
            " 94%|█████████▍| 168/178 [00:09<00:00, 17.59it/s]\u001b[A\n",
            " 96%|█████████▌| 170/178 [00:09<00:00, 17.71it/s]\u001b[A\n",
            " 97%|█████████▋| 172/178 [00:09<00:00, 17.79it/s]\u001b[A\n",
            " 98%|█████████▊| 174/178 [00:09<00:00, 17.85it/s]\u001b[A\n",
            "100%|██████████| 178/178 [00:10<00:00, 17.68it/s]\n",
            "100%|█████████▉| 1421/1422 [04:43<00:03,  3.19s/it]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100%|██████████| 1422/1422 [04:43<00:00,  5.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 0.3227 Val acc: 0.9043 Val f1: 0.9043 AUC: 0.4770\n",
            "\n",
            "\n",
            "Epoch 4 from 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 202/1422 [00:30<03:15,  6.25it/s]\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 2/178 [00:00<00:09, 18.06it/s]\u001b[A\n",
            "  2%|▏         | 4/178 [00:00<00:09, 18.02it/s]\u001b[A\n",
            "  3%|▎         | 6/178 [00:00<00:09, 18.15it/s]\u001b[A\n",
            "  4%|▍         | 8/178 [00:00<00:09, 18.11it/s]\u001b[A\n",
            "  6%|▌         | 10/178 [00:00<00:09, 18.06it/s]\u001b[A\n",
            "  7%|▋         | 12/178 [00:00<00:09, 18.09it/s]\u001b[A\n",
            "  8%|▊         | 14/178 [00:00<00:09, 17.99it/s]\u001b[A\n",
            "  9%|▉         | 16/178 [00:00<00:09, 17.87it/s]\u001b[A\n",
            " 10%|█         | 18/178 [00:01<00:08, 17.85it/s]\u001b[A\n",
            " 11%|█         | 20/178 [00:01<00:08, 17.84it/s]\u001b[A\n",
            " 12%|█▏        | 22/178 [00:01<00:08, 17.95it/s]\u001b[A\n",
            " 13%|█▎        | 24/178 [00:01<00:08, 18.09it/s]\u001b[A\n",
            " 15%|█▍        | 26/178 [00:01<00:08, 18.18it/s]\u001b[A\n",
            " 16%|█▌        | 28/178 [00:01<00:08, 18.05it/s]\u001b[A\n",
            " 17%|█▋        | 30/178 [00:01<00:08, 18.10it/s]\u001b[A\n",
            " 18%|█▊        | 32/178 [00:01<00:08, 18.12it/s]\u001b[A\n",
            " 19%|█▉        | 34/178 [00:01<00:07, 18.11it/s]\u001b[A\n",
            " 20%|██        | 36/178 [00:01<00:07, 18.04it/s]\u001b[A\n",
            " 21%|██▏       | 38/178 [00:02<00:07, 18.09it/s]\u001b[A\n",
            " 22%|██▏       | 40/178 [00:02<00:07, 18.16it/s]\u001b[A\n",
            " 24%|██▎       | 42/178 [00:02<00:07, 18.19it/s]\u001b[A\n",
            " 25%|██▍       | 44/178 [00:02<00:07, 18.24it/s]\u001b[A\n",
            " 26%|██▌       | 46/178 [00:02<00:07, 18.07it/s]\u001b[A\n",
            " 27%|██▋       | 48/178 [00:02<00:07, 18.01it/s]\u001b[A\n",
            " 28%|██▊       | 50/178 [00:02<00:07, 18.06it/s]\u001b[A\n",
            " 29%|██▉       | 52/178 [00:02<00:07, 18.00it/s]\u001b[A\n",
            " 30%|███       | 54/178 [00:02<00:06, 18.05it/s]\u001b[A\n",
            " 31%|███▏      | 56/178 [00:03<00:06, 18.14it/s]\u001b[A\n",
            " 33%|███▎      | 58/178 [00:03<00:06, 18.13it/s]\u001b[A\n",
            " 34%|███▎      | 60/178 [00:03<00:06, 18.13it/s]\u001b[A\n",
            " 35%|███▍      | 62/178 [00:03<00:06, 18.15it/s]\u001b[A\n",
            " 36%|███▌      | 64/178 [00:03<00:06, 18.18it/s]\u001b[A\n",
            " 37%|███▋      | 66/178 [00:03<00:06, 18.22it/s]\u001b[A\n",
            " 38%|███▊      | 68/178 [00:03<00:06, 18.22it/s]\u001b[A\n",
            " 39%|███▉      | 70/178 [00:03<00:05, 18.19it/s]\u001b[A\n",
            " 40%|████      | 72/178 [00:03<00:05, 18.19it/s]\u001b[A\n",
            " 42%|████▏     | 74/178 [00:04<00:05, 18.22it/s]\u001b[A\n",
            " 43%|████▎     | 76/178 [00:04<00:05, 18.25it/s]\u001b[A\n",
            " 44%|████▍     | 78/178 [00:04<00:05, 18.22it/s]\u001b[A\n",
            " 45%|████▍     | 80/178 [00:04<00:05, 18.19it/s]\u001b[A\n",
            " 46%|████▌     | 82/178 [00:04<00:05, 18.15it/s]\u001b[A\n",
            " 47%|████▋     | 84/178 [00:04<00:05, 18.09it/s]\u001b[A\n",
            " 48%|████▊     | 86/178 [00:04<00:05, 18.22it/s]\u001b[A\n",
            " 49%|████▉     | 88/178 [00:04<00:04, 18.23it/s]\u001b[A\n",
            " 51%|█████     | 90/178 [00:04<00:04, 18.17it/s]\u001b[A\n",
            " 52%|█████▏    | 92/178 [00:05<00:04, 18.22it/s]\u001b[A\n",
            " 53%|█████▎    | 94/178 [00:05<00:04, 18.03it/s]\u001b[A\n",
            " 54%|█████▍    | 96/178 [00:05<00:04, 18.09it/s]\u001b[A\n",
            " 55%|█████▌    | 98/178 [00:05<00:04, 18.10it/s]\u001b[A\n",
            " 56%|█████▌    | 100/178 [00:05<00:04, 18.15it/s]\u001b[A\n",
            " 57%|█████▋    | 102/178 [00:05<00:04, 18.08it/s]\u001b[A\n",
            " 58%|█████▊    | 104/178 [00:05<00:04, 18.03it/s]\u001b[A\n",
            " 60%|█████▉    | 106/178 [00:05<00:03, 18.02it/s]\u001b[A\n",
            " 61%|██████    | 108/178 [00:05<00:03, 18.03it/s]\u001b[A\n",
            " 62%|██████▏   | 110/178 [00:06<00:03, 17.96it/s]\u001b[A\n",
            " 63%|██████▎   | 112/178 [00:06<00:03, 18.10it/s]\u001b[A\n",
            " 64%|██████▍   | 114/178 [00:06<00:03, 18.25it/s]\u001b[A\n",
            " 65%|██████▌   | 116/178 [00:06<00:03, 18.27it/s]\u001b[A\n",
            " 66%|██████▋   | 118/178 [00:06<00:03, 18.33it/s]\u001b[A\n",
            " 67%|██████▋   | 120/178 [00:06<00:03, 18.31it/s]\u001b[A\n",
            " 69%|██████▊   | 122/178 [00:06<00:03, 18.24it/s]\u001b[A\n",
            " 70%|██████▉   | 124/178 [00:06<00:02, 18.34it/s]\u001b[A\n",
            " 71%|███████   | 126/178 [00:06<00:02, 18.30it/s]\u001b[A\n",
            " 72%|███████▏  | 128/178 [00:07<00:02, 18.23it/s]\u001b[A\n",
            " 73%|███████▎  | 130/178 [00:07<00:02, 18.17it/s]\u001b[A\n",
            " 74%|███████▍  | 132/178 [00:07<00:02, 18.21it/s]\u001b[A\n",
            " 75%|███████▌  | 134/178 [00:07<00:02, 18.23it/s]\u001b[A\n",
            " 76%|███████▋  | 136/178 [00:07<00:02, 18.26it/s]\u001b[A\n",
            " 78%|███████▊  | 138/178 [00:07<00:02, 18.26it/s]\u001b[A\n",
            " 79%|███████▊  | 140/178 [00:07<00:02, 18.28it/s]\u001b[A\n",
            " 80%|███████▉  | 142/178 [00:07<00:01, 18.25it/s]\u001b[A\n",
            " 81%|████████  | 144/178 [00:07<00:01, 18.29it/s]\u001b[A\n",
            " 82%|████████▏ | 146/178 [00:08<00:01, 18.18it/s]\u001b[A\n",
            " 83%|████████▎ | 148/178 [00:08<00:01, 18.19it/s]\u001b[A\n",
            " 84%|████████▍ | 150/178 [00:08<00:01, 18.26it/s]\u001b[A\n",
            " 85%|████████▌ | 152/178 [00:08<00:01, 18.25it/s]\u001b[A\n",
            " 87%|████████▋ | 154/178 [00:08<00:01, 18.24it/s]\u001b[A\n",
            " 88%|████████▊ | 156/178 [00:08<00:01, 18.24it/s]\u001b[A\n",
            " 89%|████████▉ | 158/178 [00:08<00:01, 18.14it/s]\u001b[A\n",
            " 90%|████████▉ | 160/178 [00:08<00:00, 18.06it/s]\u001b[A\n",
            " 91%|█████████ | 162/178 [00:08<00:00, 18.02it/s]\u001b[A\n",
            " 92%|█████████▏| 164/178 [00:09<00:00, 18.06it/s]\u001b[A\n",
            " 93%|█████████▎| 166/178 [00:09<00:00, 18.20it/s]\u001b[A\n",
            " 94%|█████████▍| 168/178 [00:09<00:00, 18.15it/s]\u001b[A\n",
            " 96%|█████████▌| 170/178 [00:09<00:00, 18.14it/s]\u001b[A\n",
            " 97%|█████████▋| 172/178 [00:09<00:00, 18.14it/s]\u001b[A\n",
            " 98%|█████████▊| 174/178 [00:09<00:00, 18.21it/s]\u001b[A\n",
            "100%|██████████| 178/178 [00:09<00:00, 18.18it/s]\n",
            " 14%|█▍        | 203/1422 [00:40<1:02:56,  3.10s/it]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            " 14%|█▍        | 204/1422 [00:40<44:55,  2.21s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 0.3200 Val acc: 0.9043 Val f1: 0.9043 AUC: 0.5282\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 405/1422 [01:11<02:33,  6.61it/s]\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 2/178 [00:00<00:09, 18.14it/s]\u001b[A\n",
            "  2%|▏         | 4/178 [00:00<00:09, 18.18it/s]\u001b[A\n",
            "  3%|▎         | 6/178 [00:00<00:09, 18.18it/s]\u001b[A\n",
            "  4%|▍         | 8/178 [00:00<00:09, 18.11it/s]\u001b[A\n",
            "  6%|▌         | 10/178 [00:00<00:09, 17.99it/s]\u001b[A\n",
            "  7%|▋         | 12/178 [00:00<00:09, 18.18it/s]\u001b[A\n",
            "  8%|▊         | 14/178 [00:00<00:08, 18.28it/s]\u001b[A\n",
            "  9%|▉         | 16/178 [00:00<00:08, 18.32it/s]\u001b[A\n",
            " 10%|█         | 18/178 [00:00<00:08, 18.09it/s]\u001b[A\n",
            " 11%|█         | 20/178 [00:01<00:08, 18.09it/s]\u001b[A\n",
            " 12%|█▏        | 22/178 [00:01<00:08, 17.97it/s]\u001b[A\n",
            " 13%|█▎        | 24/178 [00:01<00:08, 18.00it/s]\u001b[A\n",
            " 15%|█▍        | 26/178 [00:01<00:08, 18.03it/s]\u001b[A\n",
            " 16%|█▌        | 28/178 [00:01<00:08, 18.07it/s]\u001b[A\n",
            " 17%|█▋        | 30/178 [00:01<00:08, 18.14it/s]\u001b[A\n",
            " 18%|█▊        | 32/178 [00:01<00:08, 18.18it/s]\u001b[A\n",
            " 19%|█▉        | 34/178 [00:01<00:07, 18.09it/s]\u001b[A\n",
            " 20%|██        | 36/178 [00:01<00:07, 18.05it/s]\u001b[A\n",
            " 21%|██▏       | 38/178 [00:02<00:07, 18.08it/s]\u001b[A\n",
            " 22%|██▏       | 40/178 [00:02<00:07, 18.04it/s]\u001b[A\n",
            " 24%|██▎       | 42/178 [00:02<00:07, 18.01it/s]\u001b[A\n",
            " 25%|██▍       | 44/178 [00:02<00:07, 18.09it/s]\u001b[A\n",
            " 26%|██▌       | 46/178 [00:02<00:07, 18.16it/s]\u001b[A\n",
            " 27%|██▋       | 48/178 [00:02<00:07, 18.27it/s]\u001b[A\n",
            " 28%|██▊       | 50/178 [00:02<00:07, 18.28it/s]\u001b[A\n",
            " 29%|██▉       | 52/178 [00:02<00:06, 18.26it/s]\u001b[A\n",
            " 30%|███       | 54/178 [00:02<00:06, 18.32it/s]\u001b[A\n",
            " 31%|███▏      | 56/178 [00:03<00:06, 18.16it/s]\u001b[A\n",
            " 33%|███▎      | 58/178 [00:03<00:06, 18.19it/s]\u001b[A\n",
            " 34%|███▎      | 60/178 [00:03<00:06, 18.09it/s]\u001b[A\n",
            " 35%|███▍      | 62/178 [00:03<00:06, 17.98it/s]\u001b[A\n",
            " 36%|███▌      | 64/178 [00:03<00:06, 18.03it/s]\u001b[A\n",
            " 37%|███▋      | 66/178 [00:03<00:06, 18.00it/s]\u001b[A\n",
            " 38%|███▊      | 68/178 [00:03<00:06, 18.03it/s]\u001b[A\n",
            " 39%|███▉      | 70/178 [00:03<00:05, 18.07it/s]\u001b[A\n",
            " 40%|████      | 72/178 [00:03<00:05, 18.12it/s]\u001b[A\n",
            " 42%|████▏     | 74/178 [00:04<00:05, 18.22it/s]\u001b[A\n",
            " 43%|████▎     | 76/178 [00:04<00:05, 18.14it/s]\u001b[A\n",
            " 44%|████▍     | 78/178 [00:04<00:05, 17.93it/s]\u001b[A\n",
            " 45%|████▍     | 80/178 [00:04<00:05, 17.99it/s]\u001b[A\n",
            " 46%|████▌     | 82/178 [00:04<00:05, 18.07it/s]\u001b[A\n",
            " 47%|████▋     | 84/178 [00:04<00:05, 18.20it/s]\u001b[A\n",
            " 48%|████▊     | 86/178 [00:04<00:05, 18.18it/s]\u001b[A\n",
            " 49%|████▉     | 88/178 [00:04<00:04, 18.26it/s]\u001b[A\n",
            " 51%|█████     | 90/178 [00:04<00:04, 18.32it/s]\u001b[A\n",
            " 52%|█████▏    | 92/178 [00:05<00:04, 18.29it/s]\u001b[A\n",
            " 53%|█████▎    | 94/178 [00:05<00:04, 18.18it/s]\u001b[A\n",
            " 54%|█████▍    | 96/178 [00:05<00:04, 18.18it/s]\u001b[A\n",
            " 55%|█████▌    | 98/178 [00:05<00:04, 18.16it/s]\u001b[A\n",
            " 56%|█████▌    | 100/178 [00:05<00:04, 18.15it/s]\u001b[A\n",
            " 57%|█████▋    | 102/178 [00:05<00:04, 18.03it/s]\u001b[A\n",
            " 58%|█████▊    | 104/178 [00:05<00:04, 18.15it/s]\u001b[A\n",
            " 60%|█████▉    | 106/178 [00:05<00:03, 18.21it/s]\u001b[A\n",
            " 61%|██████    | 108/178 [00:05<00:03, 18.18it/s]\u001b[A\n",
            " 62%|██████▏   | 110/178 [00:06<00:03, 17.97it/s]\u001b[A\n",
            " 63%|██████▎   | 112/178 [00:06<00:03, 18.10it/s]\u001b[A\n",
            " 64%|██████▍   | 114/178 [00:06<00:03, 18.05it/s]\u001b[A\n",
            " 65%|██████▌   | 116/178 [00:06<00:03, 18.05it/s]\u001b[A\n",
            " 66%|██████▋   | 118/178 [00:06<00:03, 18.01it/s]\u001b[A\n",
            " 67%|██████▋   | 120/178 [00:06<00:03, 18.10it/s]\u001b[A\n",
            " 69%|██████▊   | 122/178 [00:06<00:03, 18.17it/s]\u001b[A\n",
            " 70%|██████▉   | 124/178 [00:06<00:02, 18.16it/s]\u001b[A\n",
            " 71%|███████   | 126/178 [00:06<00:02, 18.27it/s]\u001b[A\n",
            " 72%|███████▏  | 128/178 [00:07<00:02, 18.20it/s]\u001b[A\n",
            " 73%|███████▎  | 130/178 [00:07<00:02, 18.11it/s]\u001b[A\n",
            " 74%|███████▍  | 132/178 [00:07<00:02, 18.08it/s]\u001b[A\n",
            " 75%|███████▌  | 134/178 [00:07<00:02, 18.10it/s]\u001b[A\n",
            " 76%|███████▋  | 136/178 [00:07<00:02, 18.08it/s]\u001b[A\n",
            " 78%|███████▊  | 138/178 [00:07<00:02, 18.08it/s]\u001b[A\n",
            " 79%|███████▊  | 140/178 [00:07<00:02, 18.14it/s]\u001b[A\n",
            " 80%|███████▉  | 142/178 [00:07<00:01, 18.11it/s]\u001b[A\n",
            " 81%|████████  | 144/178 [00:07<00:01, 18.14it/s]\u001b[A\n",
            " 82%|████████▏ | 146/178 [00:08<00:01, 18.10it/s]\u001b[A\n",
            " 83%|████████▎ | 148/178 [00:08<00:01, 17.93it/s]\u001b[A\n",
            " 84%|████████▍ | 150/178 [00:08<00:01, 17.94it/s]\u001b[A\n",
            " 85%|████████▌ | 152/178 [00:08<00:01, 17.94it/s]\u001b[A\n",
            " 87%|████████▋ | 154/178 [00:08<00:01, 18.08it/s]\u001b[A\n",
            " 88%|████████▊ | 156/178 [00:08<00:01, 18.03it/s]\u001b[A\n",
            " 89%|████████▉ | 158/178 [00:08<00:01, 18.00it/s]\u001b[A\n",
            " 90%|████████▉ | 160/178 [00:08<00:00, 18.06it/s]\u001b[A\n",
            " 91%|█████████ | 162/178 [00:08<00:00, 17.99it/s]\u001b[A\n",
            " 92%|█████████▏| 164/178 [00:09<00:00, 17.83it/s]\u001b[A\n",
            " 93%|█████████▎| 166/178 [00:09<00:00, 17.89it/s]\u001b[A\n",
            " 94%|█████████▍| 168/178 [00:09<00:00, 18.04it/s]\u001b[A\n",
            " 96%|█████████▌| 170/178 [00:09<00:00, 17.94it/s]\u001b[A\n",
            " 97%|█████████▋| 172/178 [00:09<00:00, 18.04it/s]\u001b[A\n",
            " 98%|█████████▊| 174/178 [00:09<00:00, 18.06it/s]\u001b[A\n",
            "100%|██████████| 178/178 [00:09<00:00, 18.13it/s]\n",
            " 29%|██▊       | 406/1422 [01:21<52:28,  3.10s/it]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            " 29%|██▊       | 407/1422 [01:21<37:27,  2.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 0.3170 Val acc: 0.9043 Val f1: 0.9043 AUC: 0.5585\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 608/1422 [01:51<02:01,  6.71it/s]\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 2/178 [00:00<00:09, 18.46it/s]\u001b[A\n",
            "  2%|▏         | 4/178 [00:00<00:09, 18.27it/s]\u001b[A\n",
            "  3%|▎         | 6/178 [00:00<00:09, 18.13it/s]\u001b[A\n",
            "  4%|▍         | 8/178 [00:00<00:09, 18.22it/s]\u001b[A\n",
            "  6%|▌         | 10/178 [00:00<00:09, 18.19it/s]\u001b[A\n",
            "  7%|▋         | 12/178 [00:00<00:09, 18.22it/s]\u001b[A\n",
            "  8%|▊         | 14/178 [00:00<00:09, 18.09it/s]\u001b[A\n",
            "  9%|▉         | 16/178 [00:00<00:08, 18.19it/s]\u001b[A\n",
            " 10%|█         | 18/178 [00:00<00:08, 18.21it/s]\u001b[A\n",
            " 11%|█         | 20/178 [00:01<00:08, 18.16it/s]\u001b[A\n",
            " 12%|█▏        | 22/178 [00:01<00:08, 18.16it/s]\u001b[A\n",
            " 13%|█▎        | 24/178 [00:01<00:08, 18.16it/s]\u001b[A\n",
            " 15%|█▍        | 26/178 [00:01<00:08, 18.05it/s]\u001b[A\n",
            " 16%|█▌        | 28/178 [00:01<00:08, 17.96it/s]\u001b[A\n",
            " 17%|█▋        | 30/178 [00:01<00:08, 18.02it/s]\u001b[A\n",
            " 18%|█▊        | 32/178 [00:01<00:08, 18.03it/s]\u001b[A\n",
            " 19%|█▉        | 34/178 [00:01<00:07, 18.05it/s]\u001b[A\n",
            " 20%|██        | 36/178 [00:01<00:07, 18.06it/s]\u001b[A\n",
            " 21%|██▏       | 38/178 [00:02<00:07, 18.15it/s]\u001b[A\n",
            " 22%|██▏       | 40/178 [00:02<00:07, 18.13it/s]\u001b[A\n",
            " 24%|██▎       | 42/178 [00:02<00:07, 18.08it/s]\u001b[A\n",
            " 25%|██▍       | 44/178 [00:02<00:07, 18.12it/s]\u001b[A\n",
            " 26%|██▌       | 46/178 [00:02<00:07, 18.17it/s]\u001b[A\n",
            " 27%|██▋       | 48/178 [00:02<00:07, 18.17it/s]\u001b[A\n",
            " 28%|██▊       | 50/178 [00:02<00:07, 18.10it/s]\u001b[A\n",
            " 29%|██▉       | 52/178 [00:02<00:06, 18.13it/s]\u001b[A\n",
            " 30%|███       | 54/178 [00:02<00:06, 18.15it/s]\u001b[A\n",
            " 31%|███▏      | 56/178 [00:03<00:06, 18.17it/s]\u001b[A\n",
            " 33%|███▎      | 58/178 [00:03<00:06, 18.14it/s]\u001b[A\n",
            " 34%|███▎      | 60/178 [00:03<00:06, 18.12it/s]\u001b[A\n",
            " 35%|███▍      | 62/178 [00:03<00:06, 18.08it/s]\u001b[A\n",
            " 36%|███▌      | 64/178 [00:03<00:06, 18.03it/s]\u001b[A\n",
            " 37%|███▋      | 66/178 [00:03<00:06, 17.88it/s]\u001b[A\n",
            " 38%|███▊      | 68/178 [00:03<00:06, 18.02it/s]\u001b[A\n",
            " 39%|███▉      | 70/178 [00:03<00:05, 18.16it/s]\u001b[A\n",
            " 40%|████      | 72/178 [00:03<00:05, 18.08it/s]\u001b[A\n",
            " 42%|████▏     | 74/178 [00:04<00:05, 18.11it/s]\u001b[A\n",
            " 43%|████▎     | 76/178 [00:04<00:05, 18.17it/s]\u001b[A\n",
            " 44%|████▍     | 78/178 [00:04<00:05, 18.25it/s]\u001b[A\n",
            " 45%|████▍     | 80/178 [00:04<00:05, 17.94it/s]\u001b[A\n",
            " 46%|████▌     | 82/178 [00:04<00:05, 17.94it/s]\u001b[A\n",
            " 47%|████▋     | 84/178 [00:04<00:05, 17.90it/s]\u001b[A\n",
            " 48%|████▊     | 86/178 [00:04<00:05, 17.91it/s]\u001b[A\n",
            " 49%|████▉     | 88/178 [00:04<00:05, 17.88it/s]\u001b[A\n",
            " 51%|█████     | 90/178 [00:04<00:04, 17.89it/s]\u001b[A\n",
            " 52%|█████▏    | 92/178 [00:05<00:04, 17.88it/s]\u001b[A\n",
            " 53%|█████▎    | 94/178 [00:05<00:04, 17.95it/s]\u001b[A\n",
            " 54%|█████▍    | 96/178 [00:05<00:04, 17.92it/s]\u001b[A\n",
            " 55%|█████▌    | 98/178 [00:05<00:04, 18.00it/s]\u001b[A\n",
            " 56%|█████▌    | 100/178 [00:05<00:04, 18.03it/s]\u001b[A\n",
            " 57%|█████▋    | 102/178 [00:05<00:04, 18.09it/s]\u001b[A\n",
            " 58%|█████▊    | 104/178 [00:05<00:04, 18.12it/s]\u001b[A\n",
            " 60%|█████▉    | 106/178 [00:05<00:03, 18.17it/s]\u001b[A\n",
            " 61%|██████    | 108/178 [00:05<00:03, 18.10it/s]\u001b[A\n",
            " 62%|██████▏   | 110/178 [00:06<00:03, 18.14it/s]\u001b[A\n",
            " 63%|██████▎   | 112/178 [00:06<00:03, 18.14it/s]\u001b[A\n",
            " 64%|██████▍   | 114/178 [00:06<00:03, 18.15it/s]\u001b[A\n",
            " 65%|██████▌   | 116/178 [00:06<00:03, 18.18it/s]\u001b[A\n",
            " 66%|██████▋   | 118/178 [00:06<00:03, 18.25it/s]\u001b[A\n",
            " 67%|██████▋   | 120/178 [00:06<00:03, 18.19it/s]\u001b[A\n",
            " 69%|██████▊   | 122/178 [00:06<00:03, 18.16it/s]\u001b[A\n",
            " 70%|██████▉   | 124/178 [00:06<00:02, 18.14it/s]\u001b[A\n",
            " 71%|███████   | 126/178 [00:06<00:02, 18.14it/s]\u001b[A\n",
            " 72%|███████▏  | 128/178 [00:07<00:02, 18.16it/s]\u001b[A\n",
            " 73%|███████▎  | 130/178 [00:07<00:02, 18.19it/s]\u001b[A\n",
            " 74%|███████▍  | 132/178 [00:07<00:02, 18.18it/s]\u001b[A\n",
            " 75%|███████▌  | 134/178 [00:07<00:02, 18.16it/s]\u001b[A\n",
            " 76%|███████▋  | 136/178 [00:07<00:02, 18.03it/s]\u001b[A\n",
            " 78%|███████▊  | 138/178 [00:07<00:02, 17.99it/s]\u001b[A\n",
            " 79%|███████▊  | 140/178 [00:07<00:02, 18.05it/s]\u001b[A\n",
            " 80%|███████▉  | 142/178 [00:07<00:01, 18.05it/s]\u001b[A\n",
            " 81%|████████  | 144/178 [00:07<00:01, 18.21it/s]\u001b[A\n",
            " 82%|████████▏ | 146/178 [00:08<00:01, 18.30it/s]\u001b[A\n",
            " 83%|████████▎ | 148/178 [00:08<00:01, 18.37it/s]\u001b[A\n",
            " 84%|████████▍ | 150/178 [00:08<00:01, 18.36it/s]\u001b[A\n",
            " 85%|████████▌ | 152/178 [00:08<00:01, 18.42it/s]\u001b[A\n",
            " 87%|████████▋ | 154/178 [00:08<00:01, 18.35it/s]\u001b[A\n",
            " 88%|████████▊ | 156/178 [00:08<00:01, 18.46it/s]\u001b[A\n",
            " 89%|████████▉ | 158/178 [00:08<00:01, 18.34it/s]\u001b[A\n",
            " 90%|████████▉ | 160/178 [00:08<00:00, 18.37it/s]\u001b[A\n",
            " 91%|█████████ | 162/178 [00:08<00:00, 18.34it/s]\u001b[A\n",
            " 92%|█████████▏| 164/178 [00:09<00:00, 18.36it/s]\u001b[A\n",
            " 93%|█████████▎| 166/178 [00:09<00:00, 18.36it/s]\u001b[A\n",
            " 94%|█████████▍| 168/178 [00:09<00:00, 18.37it/s]\u001b[A\n",
            " 96%|█████████▌| 170/178 [00:09<00:00, 18.39it/s]\u001b[A\n",
            " 97%|█████████▋| 172/178 [00:09<00:00, 18.30it/s]\u001b[A\n",
            " 98%|█████████▊| 174/178 [00:09<00:00, 18.28it/s]\u001b[A\n",
            "100%|██████████| 178/178 [00:09<00:00, 18.17it/s]\n",
            " 43%|████▎     | 609/1422 [02:01<41:52,  3.09s/it]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            " 43%|████▎     | 610/1422 [02:01<29:52,  2.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 0.3178 Val acc: 0.9043 Val f1: 0.9043 AUC: 0.4674\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 811/1422 [02:32<01:29,  6.79it/s]\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 2/178 [00:00<00:09, 18.91it/s]\u001b[A\n",
            "  2%|▏         | 4/178 [00:00<00:09, 18.62it/s]\u001b[A\n",
            "  3%|▎         | 6/178 [00:00<00:09, 18.33it/s]\u001b[A\n",
            "  4%|▍         | 8/178 [00:00<00:09, 18.13it/s]\u001b[A\n",
            "  6%|▌         | 10/178 [00:00<00:09, 18.12it/s]\u001b[A\n",
            "  7%|▋         | 12/178 [00:00<00:09, 18.10it/s]\u001b[A\n",
            "  8%|▊         | 14/178 [00:00<00:09, 18.06it/s]\u001b[A\n",
            "  9%|▉         | 16/178 [00:00<00:08, 18.09it/s]\u001b[A\n",
            " 10%|█         | 18/178 [00:00<00:08, 18.04it/s]\u001b[A\n",
            " 11%|█         | 20/178 [00:01<00:08, 18.14it/s]\u001b[A\n",
            " 12%|█▏        | 22/178 [00:01<00:08, 18.16it/s]\u001b[A\n",
            " 13%|█▎        | 24/178 [00:01<00:08, 18.19it/s]\u001b[A\n",
            " 15%|█▍        | 26/178 [00:01<00:08, 18.14it/s]\u001b[A\n",
            " 16%|█▌        | 28/178 [00:01<00:08, 18.17it/s]\u001b[A\n",
            " 17%|█▋        | 30/178 [00:01<00:08, 18.31it/s]\u001b[A\n",
            " 18%|█▊        | 32/178 [00:01<00:08, 18.21it/s]\u001b[A\n",
            " 19%|█▉        | 34/178 [00:01<00:07, 18.20it/s]\u001b[A\n",
            " 20%|██        | 36/178 [00:01<00:07, 18.19it/s]\u001b[A\n",
            " 21%|██▏       | 38/178 [00:02<00:07, 18.15it/s]\u001b[A\n",
            " 22%|██▏       | 40/178 [00:02<00:07, 18.23it/s]\u001b[A\n",
            " 24%|██▎       | 42/178 [00:02<00:07, 18.24it/s]\u001b[A\n",
            " 25%|██▍       | 44/178 [00:02<00:07, 18.17it/s]\u001b[A\n",
            " 26%|██▌       | 46/178 [00:02<00:07, 18.00it/s]\u001b[A\n",
            " 27%|██▋       | 48/178 [00:02<00:07, 18.02it/s]\u001b[A\n",
            " 28%|██▊       | 50/178 [00:02<00:07, 18.06it/s]\u001b[A\n",
            " 29%|██▉       | 52/178 [00:02<00:06, 18.13it/s]\u001b[A\n",
            " 30%|███       | 54/178 [00:02<00:06, 18.12it/s]\u001b[A\n",
            " 31%|███▏      | 56/178 [00:03<00:06, 18.10it/s]\u001b[A\n",
            " 33%|███▎      | 58/178 [00:03<00:06, 18.07it/s]\u001b[A\n",
            " 34%|███▎      | 60/178 [00:03<00:06, 18.14it/s]\u001b[A\n",
            " 35%|███▍      | 62/178 [00:03<00:06, 18.08it/s]\u001b[A\n",
            " 36%|███▌      | 64/178 [00:03<00:06, 18.05it/s]\u001b[A\n",
            " 37%|███▋      | 66/178 [00:03<00:06, 18.11it/s]\u001b[A\n",
            " 38%|███▊      | 68/178 [00:03<00:06, 18.13it/s]\u001b[A\n",
            " 39%|███▉      | 70/178 [00:03<00:05, 18.16it/s]\u001b[A\n",
            " 40%|████      | 72/178 [00:03<00:05, 18.16it/s]\u001b[A\n",
            " 42%|████▏     | 74/178 [00:04<00:05, 18.16it/s]\u001b[A\n",
            " 43%|████▎     | 76/178 [00:04<00:05, 18.20it/s]\u001b[A\n",
            " 44%|████▍     | 78/178 [00:04<00:05, 18.21it/s]\u001b[A\n",
            " 45%|████▍     | 80/178 [00:04<00:05, 18.10it/s]\u001b[A\n",
            " 46%|████▌     | 82/178 [00:04<00:05, 18.13it/s]\u001b[A\n",
            " 47%|████▋     | 84/178 [00:04<00:05, 18.18it/s]\u001b[A\n",
            " 48%|████▊     | 86/178 [00:04<00:05, 18.25it/s]\u001b[A\n",
            " 49%|████▉     | 88/178 [00:04<00:04, 18.25it/s]\u001b[A\n",
            " 51%|█████     | 90/178 [00:04<00:04, 18.34it/s]\u001b[A\n",
            " 52%|█████▏    | 92/178 [00:05<00:04, 18.26it/s]\u001b[A\n",
            " 53%|█████▎    | 94/178 [00:05<00:04, 18.24it/s]\u001b[A\n",
            " 54%|█████▍    | 96/178 [00:05<00:04, 18.30it/s]\u001b[A\n",
            " 55%|█████▌    | 98/178 [00:05<00:04, 18.16it/s]\u001b[A\n",
            " 56%|█████▌    | 100/178 [00:05<00:04, 18.08it/s]\u001b[A\n",
            " 57%|█████▋    | 102/178 [00:05<00:04, 18.18it/s]\u001b[A\n",
            " 58%|█████▊    | 104/178 [00:05<00:04, 18.14it/s]\u001b[A\n",
            " 60%|█████▉    | 106/178 [00:05<00:03, 18.12it/s]\u001b[A\n",
            " 61%|██████    | 108/178 [00:05<00:03, 18.23it/s]\u001b[A\n",
            " 62%|██████▏   | 110/178 [00:06<00:03, 18.23it/s]\u001b[A\n",
            " 63%|██████▎   | 112/178 [00:06<00:03, 18.30it/s]\u001b[A\n",
            " 64%|██████▍   | 114/178 [00:06<00:03, 18.28it/s]\u001b[A\n",
            " 65%|██████▌   | 116/178 [00:06<00:03, 18.20it/s]\u001b[A\n",
            " 66%|██████▋   | 118/178 [00:06<00:03, 18.19it/s]\u001b[A\n",
            " 67%|██████▋   | 120/178 [00:06<00:03, 18.08it/s]\u001b[A\n",
            " 69%|██████▊   | 122/178 [00:06<00:03, 17.97it/s]\u001b[A\n",
            " 70%|██████▉   | 124/178 [00:06<00:02, 18.02it/s]\u001b[A\n",
            " 71%|███████   | 126/178 [00:06<00:02, 18.03it/s]\u001b[A\n",
            " 72%|███████▏  | 128/178 [00:07<00:02, 17.95it/s]\u001b[A\n",
            " 73%|███████▎  | 130/178 [00:07<00:02, 18.01it/s]\u001b[A\n",
            " 74%|███████▍  | 132/178 [00:07<00:02, 18.06it/s]\u001b[A\n",
            " 75%|███████▌  | 134/178 [00:07<00:02, 18.11it/s]\u001b[A\n",
            " 76%|███████▋  | 136/178 [00:07<00:02, 18.16it/s]\u001b[A\n",
            " 78%|███████▊  | 138/178 [00:07<00:02, 17.97it/s]\u001b[A\n",
            " 79%|███████▊  | 140/178 [00:07<00:02, 18.07it/s]\u001b[A\n",
            " 80%|███████▉  | 142/178 [00:07<00:01, 18.04it/s]\u001b[A\n",
            " 81%|████████  | 144/178 [00:07<00:01, 18.10it/s]\u001b[A\n",
            " 82%|████████▏ | 146/178 [00:08<00:01, 18.17it/s]\u001b[A\n",
            " 83%|████████▎ | 148/178 [00:08<00:01, 18.12it/s]\u001b[A\n",
            " 84%|████████▍ | 150/178 [00:08<00:01, 18.13it/s]\u001b[A\n",
            " 85%|████████▌ | 152/178 [00:08<00:01, 18.13it/s]\u001b[A\n",
            " 87%|████████▋ | 154/178 [00:08<00:01, 18.07it/s]\u001b[A\n",
            " 88%|████████▊ | 156/178 [00:08<00:01, 18.04it/s]\u001b[A\n",
            " 89%|████████▉ | 158/178 [00:08<00:01, 18.08it/s]\u001b[A\n",
            " 90%|████████▉ | 160/178 [00:08<00:00, 18.05it/s]\u001b[A\n",
            " 91%|█████████ | 162/178 [00:08<00:00, 18.18it/s]\u001b[A\n",
            " 92%|█████████▏| 164/178 [00:09<00:00, 18.12it/s]\u001b[A\n",
            " 93%|█████████▎| 166/178 [00:09<00:00, 18.22it/s]\u001b[A\n",
            " 94%|█████████▍| 168/178 [00:09<00:00, 18.27it/s]\u001b[A\n",
            " 96%|█████████▌| 170/178 [00:09<00:00, 18.20it/s]\u001b[A\n",
            " 97%|█████████▋| 172/178 [00:09<00:00, 18.16it/s]\u001b[A\n",
            " 98%|█████████▊| 174/178 [00:09<00:00, 18.09it/s]\u001b[A\n",
            "100%|██████████| 178/178 [00:09<00:00, 18.17it/s]\n",
            " 57%|█████▋    | 812/1422 [02:42<31:24,  3.09s/it]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            " 57%|█████▋    | 813/1422 [02:42<22:23,  2.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 0.3161 Val acc: 0.9043 Val f1: 0.9043 AUC: 0.4829\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 71%|███████▏  | 1014/1422 [03:12<01:00,  6.79it/s]\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 2/178 [00:00<00:09, 18.32it/s]\u001b[A\n",
            "  2%|▏         | 4/178 [00:00<00:09, 17.87it/s]\u001b[A\n",
            "  3%|▎         | 6/178 [00:00<00:09, 17.84it/s]\u001b[A\n",
            "  4%|▍         | 8/178 [00:00<00:09, 17.90it/s]\u001b[A\n",
            "  6%|▌         | 10/178 [00:00<00:09, 17.65it/s]\u001b[A\n",
            "  7%|▋         | 12/178 [00:00<00:09, 17.75it/s]\u001b[A\n",
            "  8%|▊         | 14/178 [00:00<00:09, 17.71it/s]\u001b[A\n",
            "  9%|▉         | 16/178 [00:00<00:09, 17.74it/s]\u001b[A\n",
            " 10%|█         | 18/178 [00:01<00:09, 17.76it/s]\u001b[A\n",
            " 11%|█         | 20/178 [00:01<00:08, 17.78it/s]\u001b[A\n",
            " 12%|█▏        | 22/178 [00:01<00:08, 17.80it/s]\u001b[A\n",
            " 13%|█▎        | 24/178 [00:01<00:08, 17.81it/s]\u001b[A\n",
            " 15%|█▍        | 26/178 [00:01<00:08, 17.85it/s]\u001b[A\n",
            " 16%|█▌        | 28/178 [00:01<00:08, 17.63it/s]\u001b[A\n",
            " 17%|█▋        | 30/178 [00:01<00:08, 17.63it/s]\u001b[A\n",
            " 18%|█▊        | 32/178 [00:01<00:08, 17.62it/s]\u001b[A\n",
            " 19%|█▉        | 34/178 [00:01<00:08, 17.66it/s]\u001b[A\n",
            " 20%|██        | 36/178 [00:02<00:07, 17.77it/s]\u001b[A\n",
            " 21%|██▏       | 38/178 [00:02<00:07, 17.82it/s]\u001b[A\n",
            " 22%|██▏       | 40/178 [00:02<00:07, 17.81it/s]\u001b[A\n",
            " 24%|██▎       | 42/178 [00:02<00:07, 17.73it/s]\u001b[A\n",
            " 25%|██▍       | 44/178 [00:02<00:07, 17.62it/s]\u001b[A\n",
            " 26%|██▌       | 46/178 [00:02<00:07, 17.59it/s]\u001b[A\n",
            " 27%|██▋       | 48/178 [00:02<00:07, 17.57it/s]\u001b[A\n",
            " 28%|██▊       | 50/178 [00:02<00:07, 17.68it/s]\u001b[A\n",
            " 29%|██▉       | 52/178 [00:02<00:07, 17.75it/s]\u001b[A\n",
            " 30%|███       | 54/178 [00:03<00:07, 17.71it/s]\u001b[A\n",
            " 31%|███▏      | 56/178 [00:03<00:06, 17.66it/s]\u001b[A\n",
            " 33%|███▎      | 58/178 [00:03<00:06, 17.66it/s]\u001b[A\n",
            " 34%|███▎      | 60/178 [00:03<00:06, 17.69it/s]\u001b[A\n",
            " 35%|███▍      | 62/178 [00:03<00:06, 17.75it/s]\u001b[A\n",
            " 36%|███▌      | 64/178 [00:03<00:06, 17.63it/s]\u001b[A\n",
            " 37%|███▋      | 66/178 [00:03<00:06, 17.56it/s]\u001b[A\n",
            " 38%|███▊      | 68/178 [00:03<00:06, 17.45it/s]\u001b[A\n",
            " 39%|███▉      | 70/178 [00:03<00:06, 17.52it/s]\u001b[A\n",
            " 40%|████      | 72/178 [00:04<00:06, 17.53it/s]\u001b[A\n",
            " 42%|████▏     | 74/178 [00:04<00:05, 17.59it/s]\u001b[A\n",
            " 43%|████▎     | 76/178 [00:04<00:05, 17.60it/s]\u001b[A\n",
            " 44%|████▍     | 78/178 [00:04<00:05, 17.64it/s]\u001b[A\n",
            " 45%|████▍     | 80/178 [00:04<00:05, 17.67it/s]\u001b[A\n",
            " 46%|████▌     | 82/178 [00:04<00:05, 17.69it/s]\u001b[A\n",
            " 47%|████▋     | 84/178 [00:04<00:05, 17.74it/s]\u001b[A\n",
            " 48%|████▊     | 86/178 [00:04<00:05, 17.78it/s]\u001b[A\n",
            " 49%|████▉     | 88/178 [00:04<00:05, 17.84it/s]\u001b[A\n",
            " 51%|█████     | 90/178 [00:05<00:04, 17.84it/s]\u001b[A\n",
            " 52%|█████▏    | 92/178 [00:05<00:04, 17.82it/s]\u001b[A\n",
            " 53%|█████▎    | 94/178 [00:05<00:04, 17.76it/s]\u001b[A\n",
            " 54%|█████▍    | 96/178 [00:05<00:04, 17.75it/s]\u001b[A\n",
            " 55%|█████▌    | 98/178 [00:05<00:04, 17.73it/s]\u001b[A\n",
            " 56%|█████▌    | 100/178 [00:05<00:04, 17.76it/s]\u001b[A\n",
            " 57%|█████▋    | 102/178 [00:05<00:04, 17.78it/s]\u001b[A\n",
            " 58%|█████▊    | 104/178 [00:05<00:04, 17.82it/s]\u001b[A\n",
            " 60%|█████▉    | 106/178 [00:05<00:04, 17.73it/s]\u001b[A\n",
            " 61%|██████    | 108/178 [00:06<00:03, 17.73it/s]\u001b[A\n",
            " 62%|██████▏   | 110/178 [00:06<00:03, 17.64it/s]\u001b[A\n",
            " 63%|██████▎   | 112/178 [00:06<00:03, 17.76it/s]\u001b[A\n",
            " 64%|██████▍   | 114/178 [00:06<00:03, 17.79it/s]\u001b[A\n",
            " 65%|██████▌   | 116/178 [00:06<00:03, 17.78it/s]\u001b[A\n",
            " 66%|██████▋   | 118/178 [00:06<00:03, 17.69it/s]\u001b[A\n",
            " 67%|██████▋   | 120/178 [00:06<00:03, 17.70it/s]\u001b[A\n",
            " 69%|██████▊   | 122/178 [00:06<00:03, 17.71it/s]\u001b[A\n",
            " 70%|██████▉   | 124/178 [00:07<00:03, 17.72it/s]\u001b[A\n",
            " 71%|███████   | 126/178 [00:07<00:02, 17.66it/s]\u001b[A\n",
            " 72%|███████▏  | 128/178 [00:07<00:02, 17.67it/s]\u001b[A\n",
            " 73%|███████▎  | 130/178 [00:07<00:02, 17.71it/s]\u001b[A\n",
            " 74%|███████▍  | 132/178 [00:07<00:02, 17.81it/s]\u001b[A\n",
            " 75%|███████▌  | 134/178 [00:07<00:02, 17.85it/s]\u001b[A\n",
            " 76%|███████▋  | 136/178 [00:07<00:02, 17.81it/s]\u001b[A\n",
            " 78%|███████▊  | 138/178 [00:07<00:02, 17.85it/s]\u001b[A\n",
            " 79%|███████▊  | 140/178 [00:07<00:02, 17.82it/s]\u001b[A\n",
            " 80%|███████▉  | 142/178 [00:08<00:02, 17.73it/s]\u001b[A\n",
            " 81%|████████  | 144/178 [00:08<00:01, 17.78it/s]\u001b[A\n",
            " 82%|████████▏ | 146/178 [00:08<00:01, 17.77it/s]\u001b[A\n",
            " 83%|████████▎ | 148/178 [00:08<00:01, 17.77it/s]\u001b[A\n",
            " 84%|████████▍ | 150/178 [00:08<00:01, 17.79it/s]\u001b[A\n",
            " 85%|████████▌ | 152/178 [00:08<00:01, 17.74it/s]\u001b[A\n",
            " 87%|████████▋ | 154/178 [00:08<00:01, 17.67it/s]\u001b[A\n",
            " 88%|████████▊ | 156/178 [00:08<00:01, 17.72it/s]\u001b[A\n",
            " 89%|████████▉ | 158/178 [00:08<00:01, 17.74it/s]\u001b[A\n",
            " 90%|████████▉ | 160/178 [00:09<00:01, 17.80it/s]\u001b[A\n",
            " 91%|█████████ | 162/178 [00:09<00:00, 17.84it/s]\u001b[A\n",
            " 92%|█████████▏| 164/178 [00:09<00:00, 17.87it/s]\u001b[A\n",
            " 93%|█████████▎| 166/178 [00:09<00:00, 17.87it/s]\u001b[A\n",
            " 94%|█████████▍| 168/178 [00:09<00:00, 17.90it/s]\u001b[A\n",
            " 96%|█████████▌| 170/178 [00:09<00:00, 17.79it/s]\u001b[A\n",
            " 97%|█████████▋| 172/178 [00:09<00:00, 17.80it/s]\u001b[A\n",
            " 98%|█████████▊| 174/178 [00:09<00:00, 17.76it/s]\u001b[A\n",
            "100%|██████████| 178/178 [00:10<00:00, 17.76it/s]\n",
            " 71%|███████▏  | 1015/1422 [03:22<21:24,  3.16s/it]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            " 71%|███████▏  | 1016/1422 [03:23<15:15,  2.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 0.3154 Val acc: 0.9043 Val f1: 0.9043 AUC: 0.5249\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 1217/1422 [03:53<00:30,  6.79it/s]\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 2/178 [00:00<00:09, 18.63it/s]\u001b[A\n",
            "  2%|▏         | 4/178 [00:00<00:09, 18.16it/s]\u001b[A\n",
            "  3%|▎         | 6/178 [00:00<00:09, 18.10it/s]\u001b[A\n",
            "  4%|▍         | 8/178 [00:00<00:09, 17.88it/s]\u001b[A\n",
            "  6%|▌         | 10/178 [00:00<00:09, 17.94it/s]\u001b[A\n",
            "  7%|▋         | 12/178 [00:00<00:09, 17.85it/s]\u001b[A\n",
            "  8%|▊         | 14/178 [00:00<00:09, 17.84it/s]\u001b[A\n",
            "  9%|▉         | 16/178 [00:00<00:09, 17.68it/s]\u001b[A\n",
            " 10%|█         | 18/178 [00:01<00:08, 17.79it/s]\u001b[A\n",
            " 11%|█         | 20/178 [00:01<00:08, 17.80it/s]\u001b[A\n",
            " 12%|█▏        | 22/178 [00:01<00:08, 17.87it/s]\u001b[A\n",
            " 13%|█▎        | 24/178 [00:01<00:08, 18.02it/s]\u001b[A\n",
            " 15%|█▍        | 26/178 [00:01<00:08, 17.89it/s]\u001b[A\n",
            " 16%|█▌        | 28/178 [00:01<00:08, 17.93it/s]\u001b[A\n",
            " 17%|█▋        | 30/178 [00:01<00:08, 17.92it/s]\u001b[A\n",
            " 18%|█▊        | 32/178 [00:01<00:08, 18.04it/s]\u001b[A\n",
            " 19%|█▉        | 34/178 [00:01<00:08, 17.82it/s]\u001b[A\n",
            " 20%|██        | 36/178 [00:02<00:07, 17.87it/s]\u001b[A\n",
            " 21%|██▏       | 38/178 [00:02<00:07, 17.94it/s]\u001b[A\n",
            " 22%|██▏       | 40/178 [00:02<00:07, 17.99it/s]\u001b[A\n",
            " 24%|██▎       | 42/178 [00:02<00:07, 17.91it/s]\u001b[A\n",
            " 25%|██▍       | 44/178 [00:02<00:07, 17.91it/s]\u001b[A\n",
            " 26%|██▌       | 46/178 [00:02<00:07, 17.90it/s]\u001b[A\n",
            " 27%|██▋       | 48/178 [00:02<00:07, 17.89it/s]\u001b[A\n",
            " 28%|██▊       | 50/178 [00:02<00:07, 17.72it/s]\u001b[A\n",
            " 29%|██▉       | 52/178 [00:02<00:07, 17.82it/s]\u001b[A\n",
            " 30%|███       | 54/178 [00:03<00:06, 17.79it/s]\u001b[A\n",
            " 31%|███▏      | 56/178 [00:03<00:06, 17.74it/s]\u001b[A\n",
            " 33%|███▎      | 58/178 [00:03<00:06, 17.93it/s]\u001b[A\n",
            " 34%|███▎      | 60/178 [00:03<00:06, 17.90it/s]\u001b[A\n",
            " 35%|███▍      | 62/178 [00:03<00:06, 17.93it/s]\u001b[A\n",
            " 36%|███▌      | 64/178 [00:03<00:06, 17.87it/s]\u001b[A\n",
            " 37%|███▋      | 66/178 [00:03<00:06, 17.88it/s]\u001b[A\n",
            " 38%|███▊      | 68/178 [00:03<00:06, 17.93it/s]\u001b[A\n",
            " 39%|███▉      | 70/178 [00:03<00:06, 17.85it/s]\u001b[A\n",
            " 40%|████      | 72/178 [00:04<00:05, 17.91it/s]\u001b[A\n",
            " 42%|████▏     | 74/178 [00:04<00:05, 17.91it/s]\u001b[A\n",
            " 43%|████▎     | 76/178 [00:04<00:05, 17.98it/s]\u001b[A\n",
            " 44%|████▍     | 78/178 [00:04<00:05, 17.91it/s]\u001b[A\n",
            " 45%|████▍     | 80/178 [00:04<00:05, 17.86it/s]\u001b[A\n",
            " 46%|████▌     | 82/178 [00:04<00:05, 17.87it/s]\u001b[A\n",
            " 47%|████▋     | 84/178 [00:04<00:05, 17.86it/s]\u001b[A\n",
            " 48%|████▊     | 86/178 [00:04<00:05, 17.91it/s]\u001b[A\n",
            " 49%|████▉     | 88/178 [00:04<00:05, 17.99it/s]\u001b[A\n",
            " 51%|█████     | 90/178 [00:05<00:04, 17.95it/s]\u001b[A\n",
            " 52%|█████▏    | 92/178 [00:05<00:04, 17.94it/s]\u001b[A\n",
            " 53%|█████▎    | 94/178 [00:05<00:04, 18.03it/s]\u001b[A\n",
            " 54%|█████▍    | 96/178 [00:05<00:04, 18.04it/s]\u001b[A\n",
            " 55%|█████▌    | 98/178 [00:05<00:04, 18.05it/s]\u001b[A\n",
            " 56%|█████▌    | 100/178 [00:05<00:04, 18.07it/s]\u001b[A\n",
            " 57%|█████▋    | 102/178 [00:05<00:04, 18.03it/s]\u001b[A\n",
            " 58%|█████▊    | 104/178 [00:05<00:04, 18.00it/s]\u001b[A\n",
            " 60%|█████▉    | 106/178 [00:05<00:03, 18.06it/s]\u001b[A\n",
            " 61%|██████    | 108/178 [00:06<00:03, 17.99it/s]\u001b[A\n",
            " 62%|██████▏   | 110/178 [00:06<00:03, 18.05it/s]\u001b[A\n",
            " 63%|██████▎   | 112/178 [00:06<00:03, 18.05it/s]\u001b[A\n",
            " 64%|██████▍   | 114/178 [00:06<00:03, 17.97it/s]\u001b[A\n",
            " 65%|██████▌   | 116/178 [00:06<00:03, 17.93it/s]\u001b[A\n",
            " 66%|██████▋   | 118/178 [00:06<00:03, 17.79it/s]\u001b[A\n",
            " 67%|██████▋   | 120/178 [00:06<00:03, 17.79it/s]\u001b[A\n",
            " 69%|██████▊   | 122/178 [00:06<00:03, 17.92it/s]\u001b[A\n",
            " 70%|██████▉   | 124/178 [00:06<00:03, 17.99it/s]\u001b[A\n",
            " 71%|███████   | 126/178 [00:07<00:02, 18.01it/s]\u001b[A\n",
            " 72%|███████▏  | 128/178 [00:07<00:02, 17.98it/s]\u001b[A\n",
            " 73%|███████▎  | 130/178 [00:07<00:02, 17.91it/s]\u001b[A\n",
            " 74%|███████▍  | 132/178 [00:07<00:02, 18.00it/s]\u001b[A\n",
            " 75%|███████▌  | 134/178 [00:07<00:02, 18.00it/s]\u001b[A\n",
            " 76%|███████▋  | 136/178 [00:07<00:02, 18.12it/s]\u001b[A\n",
            " 78%|███████▊  | 138/178 [00:07<00:02, 17.90it/s]\u001b[A\n",
            " 79%|███████▊  | 140/178 [00:07<00:02, 17.93it/s]\u001b[A\n",
            " 80%|███████▉  | 142/178 [00:07<00:02, 17.92it/s]\u001b[A\n",
            " 81%|████████  | 144/178 [00:08<00:01, 17.95it/s]\u001b[A\n",
            " 82%|████████▏ | 146/178 [00:08<00:01, 17.99it/s]\u001b[A\n",
            " 83%|████████▎ | 148/178 [00:08<00:01, 18.12it/s]\u001b[A\n",
            " 84%|████████▍ | 150/178 [00:08<00:01, 18.15it/s]\u001b[A\n",
            " 85%|████████▌ | 152/178 [00:08<00:01, 18.04it/s]\u001b[A\n",
            " 87%|████████▋ | 154/178 [00:08<00:01, 18.08it/s]\u001b[A\n",
            " 88%|████████▊ | 156/178 [00:08<00:01, 18.07it/s]\u001b[A\n",
            " 89%|████████▉ | 158/178 [00:08<00:01, 18.12it/s]\u001b[A\n",
            " 90%|████████▉ | 160/178 [00:08<00:00, 18.16it/s]\u001b[A\n",
            " 91%|█████████ | 162/178 [00:09<00:00, 18.16it/s]\u001b[A\n",
            " 92%|█████████▏| 164/178 [00:09<00:00, 18.23it/s]\u001b[A\n",
            " 93%|█████████▎| 166/178 [00:09<00:00, 18.15it/s]\u001b[A\n",
            " 94%|█████████▍| 168/178 [00:09<00:00, 18.15it/s]\u001b[A\n",
            " 96%|█████████▌| 170/178 [00:09<00:00, 18.24it/s]\u001b[A\n",
            " 97%|█████████▋| 172/178 [00:09<00:00, 18.23it/s]\u001b[A\n",
            " 98%|█████████▊| 174/178 [00:09<00:00, 18.10it/s]\u001b[A\n",
            "100%|██████████| 178/178 [00:09<00:00, 18.00it/s]\n",
            " 86%|████████▌ | 1218/1422 [04:03<10:36,  3.12s/it]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            " 86%|████████▌ | 1219/1422 [04:03<07:32,  2.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 0.3195 Val acc: 0.9043 Val f1: 0.9043 AUC: 0.4975\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 1420/1422 [04:34<00:00,  5.77it/s]\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 2/178 [00:00<00:09, 18.57it/s]\u001b[A\n",
            "  2%|▏         | 4/178 [00:00<00:09, 18.25it/s]\u001b[A\n",
            "  3%|▎         | 6/178 [00:00<00:09, 18.11it/s]\u001b[A\n",
            "  4%|▍         | 8/178 [00:00<00:09, 18.11it/s]\u001b[A\n",
            "  6%|▌         | 10/178 [00:00<00:09, 18.15it/s]\u001b[A\n",
            "  7%|▋         | 12/178 [00:00<00:09, 18.02it/s]\u001b[A\n",
            "  8%|▊         | 14/178 [00:00<00:09, 17.97it/s]\u001b[A\n",
            "  9%|▉         | 16/178 [00:00<00:08, 18.01it/s]\u001b[A\n",
            " 10%|█         | 18/178 [00:00<00:08, 17.97it/s]\u001b[A\n",
            " 11%|█         | 20/178 [00:01<00:08, 18.06it/s]\u001b[A\n",
            " 12%|█▏        | 22/178 [00:01<00:08, 18.08it/s]\u001b[A\n",
            " 13%|█▎        | 24/178 [00:01<00:08, 18.11it/s]\u001b[A\n",
            " 15%|█▍        | 26/178 [00:01<00:08, 18.06it/s]\u001b[A\n",
            " 16%|█▌        | 28/178 [00:01<00:08, 18.21it/s]\u001b[A\n",
            " 17%|█▋        | 30/178 [00:01<00:08, 18.31it/s]\u001b[A\n",
            " 18%|█▊        | 32/178 [00:01<00:07, 18.30it/s]\u001b[A\n",
            " 19%|█▉        | 34/178 [00:01<00:07, 18.20it/s]\u001b[A\n",
            " 20%|██        | 36/178 [00:01<00:07, 18.15it/s]\u001b[A\n",
            " 21%|██▏       | 38/178 [00:02<00:07, 18.07it/s]\u001b[A\n",
            " 22%|██▏       | 40/178 [00:02<00:07, 18.13it/s]\u001b[A\n",
            " 24%|██▎       | 42/178 [00:02<00:07, 18.10it/s]\u001b[A\n",
            " 25%|██▍       | 44/178 [00:02<00:07, 18.16it/s]\u001b[A\n",
            " 26%|██▌       | 46/178 [00:02<00:07, 18.30it/s]\u001b[A\n",
            " 27%|██▋       | 48/178 [00:02<00:07, 18.28it/s]\u001b[A\n",
            " 28%|██▊       | 50/178 [00:02<00:06, 18.29it/s]\u001b[A\n",
            " 29%|██▉       | 52/178 [00:02<00:06, 18.25it/s]\u001b[A\n",
            " 30%|███       | 54/178 [00:02<00:06, 18.35it/s]\u001b[A\n",
            " 31%|███▏      | 56/178 [00:03<00:06, 18.20it/s]\u001b[A\n",
            " 33%|███▎      | 58/178 [00:03<00:06, 18.11it/s]\u001b[A\n",
            " 34%|███▎      | 60/178 [00:03<00:06, 18.02it/s]\u001b[A\n",
            " 35%|███▍      | 62/178 [00:03<00:06, 18.01it/s]\u001b[A\n",
            " 36%|███▌      | 64/178 [00:03<00:06, 18.04it/s]\u001b[A\n",
            " 37%|███▋      | 66/178 [00:03<00:06, 18.10it/s]\u001b[A\n",
            " 38%|███▊      | 68/178 [00:03<00:06, 18.17it/s]\u001b[A\n",
            " 39%|███▉      | 70/178 [00:03<00:05, 18.23it/s]\u001b[A\n",
            " 40%|████      | 72/178 [00:03<00:05, 18.20it/s]\u001b[A\n",
            " 42%|████▏     | 74/178 [00:04<00:05, 18.26it/s]\u001b[A\n",
            " 43%|████▎     | 76/178 [00:04<00:05, 18.16it/s]\u001b[A\n",
            " 44%|████▍     | 78/178 [00:04<00:05, 18.03it/s]\u001b[A\n",
            " 45%|████▍     | 80/178 [00:04<00:05, 17.83it/s]\u001b[A\n",
            " 46%|████▌     | 82/178 [00:04<00:05, 17.89it/s]\u001b[A\n",
            " 47%|████▋     | 84/178 [00:04<00:05, 18.00it/s]\u001b[A\n",
            " 48%|████▊     | 86/178 [00:04<00:05, 18.05it/s]\u001b[A\n",
            " 49%|████▉     | 88/178 [00:04<00:04, 18.11it/s]\u001b[A\n",
            " 51%|█████     | 90/178 [00:04<00:04, 18.27it/s]\u001b[A\n",
            " 52%|█████▏    | 92/178 [00:05<00:04, 18.18it/s]\u001b[A\n",
            " 53%|█████▎    | 94/178 [00:05<00:04, 18.11it/s]\u001b[A\n",
            " 54%|█████▍    | 96/178 [00:05<00:04, 18.15it/s]\u001b[A\n",
            " 55%|█████▌    | 98/178 [00:05<00:04, 18.21it/s]\u001b[A\n",
            " 56%|█████▌    | 100/178 [00:05<00:04, 18.19it/s]\u001b[A\n",
            " 57%|█████▋    | 102/178 [00:05<00:04, 18.12it/s]\u001b[A\n",
            " 58%|█████▊    | 104/178 [00:05<00:04, 18.16it/s]\u001b[A\n",
            " 60%|█████▉    | 106/178 [00:05<00:03, 18.21it/s]\u001b[A\n",
            " 61%|██████    | 108/178 [00:05<00:03, 18.22it/s]\u001b[A\n",
            " 62%|██████▏   | 110/178 [00:06<00:03, 18.28it/s]\u001b[A\n",
            " 63%|██████▎   | 112/178 [00:06<00:03, 18.26it/s]\u001b[A\n",
            " 64%|██████▍   | 114/178 [00:06<00:03, 18.16it/s]\u001b[A\n",
            " 65%|██████▌   | 116/178 [00:06<00:03, 18.15it/s]\u001b[A\n",
            " 66%|██████▋   | 118/178 [00:06<00:03, 18.08it/s]\u001b[A\n",
            " 67%|██████▋   | 120/178 [00:06<00:03, 18.18it/s]\u001b[A\n",
            " 69%|██████▊   | 122/178 [00:06<00:03, 18.17it/s]\u001b[A\n",
            " 70%|██████▉   | 124/178 [00:06<00:02, 18.18it/s]\u001b[A\n",
            " 71%|███████   | 126/178 [00:06<00:02, 18.15it/s]\u001b[A\n",
            " 72%|███████▏  | 128/178 [00:07<00:02, 18.20it/s]\u001b[A\n",
            " 73%|███████▎  | 130/178 [00:07<00:02, 18.25it/s]\u001b[A\n",
            " 74%|███████▍  | 132/178 [00:07<00:02, 18.28it/s]\u001b[A\n",
            " 75%|███████▌  | 134/178 [00:07<00:02, 18.23it/s]\u001b[A\n",
            " 76%|███████▋  | 136/178 [00:07<00:02, 18.08it/s]\u001b[A\n",
            " 78%|███████▊  | 138/178 [00:07<00:02, 18.09it/s]\u001b[A\n",
            " 79%|███████▊  | 140/178 [00:07<00:02, 18.01it/s]\u001b[A\n",
            " 80%|███████▉  | 142/178 [00:07<00:01, 18.00it/s]\u001b[A\n",
            " 81%|████████  | 144/178 [00:07<00:01, 18.09it/s]\u001b[A\n",
            " 82%|████████▏ | 146/178 [00:08<00:01, 18.22it/s]\u001b[A\n",
            " 83%|████████▎ | 148/178 [00:08<00:01, 18.23it/s]\u001b[A\n",
            " 84%|████████▍ | 150/178 [00:08<00:01, 18.28it/s]\u001b[A\n",
            " 85%|████████▌ | 152/178 [00:08<00:01, 18.19it/s]\u001b[A\n",
            " 87%|████████▋ | 154/178 [00:08<00:01, 18.16it/s]\u001b[A\n",
            " 88%|████████▊ | 156/178 [00:08<00:01, 18.18it/s]\u001b[A\n",
            " 89%|████████▉ | 158/178 [00:08<00:01, 18.23it/s]\u001b[A\n",
            " 90%|████████▉ | 160/178 [00:08<00:00, 18.27it/s]\u001b[A\n",
            " 91%|█████████ | 162/178 [00:08<00:00, 18.28it/s]\u001b[A\n",
            " 92%|█████████▏| 164/178 [00:09<00:00, 18.32it/s]\u001b[A\n",
            " 93%|█████████▎| 166/178 [00:09<00:00, 18.25it/s]\u001b[A\n",
            " 94%|█████████▍| 168/178 [00:09<00:00, 18.33it/s]\u001b[A\n",
            " 96%|█████████▌| 170/178 [00:09<00:00, 18.29it/s]\u001b[A\n",
            " 97%|█████████▋| 172/178 [00:09<00:00, 18.28it/s]\u001b[A\n",
            " 98%|█████████▊| 174/178 [00:09<00:00, 18.11it/s]\u001b[A\n",
            "100%|██████████| 178/178 [00:09<00:00, 18.20it/s]\n",
            "100%|█████████▉| 1421/1422 [04:44<00:03,  3.10s/it]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100%|██████████| 1422/1422 [04:44<00:00,  5.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 0.3168 Val acc: 0.9043 Val f1: 0.9043 AUC: 0.5237\n",
            "\n",
            "\n",
            "Epoch 5 from 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 202/1422 [00:30<03:13,  6.30it/s]\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 2/178 [00:00<00:09, 18.36it/s]\u001b[A\n",
            "  2%|▏         | 4/178 [00:00<00:09, 18.36it/s]\u001b[A\n",
            "  3%|▎         | 6/178 [00:00<00:09, 18.40it/s]\u001b[A\n",
            "  4%|▍         | 8/178 [00:00<00:09, 18.33it/s]\u001b[A\n",
            "  6%|▌         | 10/178 [00:00<00:09, 18.11it/s]\u001b[A\n",
            "  7%|▋         | 12/178 [00:00<00:09, 18.29it/s]\u001b[A\n",
            "  8%|▊         | 14/178 [00:00<00:08, 18.32it/s]\u001b[A\n",
            "  9%|▉         | 16/178 [00:00<00:08, 18.30it/s]\u001b[A\n",
            " 10%|█         | 18/178 [00:00<00:08, 18.36it/s]\u001b[A\n",
            " 11%|█         | 20/178 [00:01<00:08, 18.36it/s]\u001b[A\n",
            " 12%|█▏        | 22/178 [00:01<00:08, 18.29it/s]\u001b[A\n",
            " 13%|█▎        | 24/178 [00:01<00:08, 18.35it/s]\u001b[A\n",
            " 15%|█▍        | 26/178 [00:01<00:08, 18.37it/s]\u001b[A\n",
            " 16%|█▌        | 28/178 [00:01<00:08, 18.33it/s]\u001b[A\n",
            " 17%|█▋        | 30/178 [00:01<00:08, 18.20it/s]\u001b[A\n",
            " 18%|█▊        | 32/178 [00:01<00:08, 18.04it/s]\u001b[A\n",
            " 19%|█▉        | 34/178 [00:01<00:08, 17.89it/s]\u001b[A\n",
            " 20%|██        | 36/178 [00:01<00:07, 17.98it/s]\u001b[A\n",
            " 21%|██▏       | 38/178 [00:02<00:07, 17.92it/s]\u001b[A\n",
            " 22%|██▏       | 40/178 [00:02<00:07, 17.97it/s]\u001b[A\n",
            " 24%|██▎       | 42/178 [00:02<00:07, 18.09it/s]\u001b[A\n",
            " 25%|██▍       | 44/178 [00:02<00:07, 18.09it/s]\u001b[A\n",
            " 26%|██▌       | 46/178 [00:02<00:07, 18.18it/s]\u001b[A\n",
            " 27%|██▋       | 48/178 [00:02<00:07, 18.08it/s]\u001b[A\n",
            " 28%|██▊       | 50/178 [00:02<00:07, 18.16it/s]\u001b[A\n",
            " 29%|██▉       | 52/178 [00:02<00:06, 18.24it/s]\u001b[A\n",
            " 30%|███       | 54/178 [00:02<00:06, 18.15it/s]\u001b[A\n",
            " 31%|███▏      | 56/178 [00:03<00:06, 18.21it/s]\u001b[A\n",
            " 33%|███▎      | 58/178 [00:03<00:06, 18.21it/s]\u001b[A\n",
            " 34%|███▎      | 60/178 [00:03<00:06, 18.06it/s]\u001b[A\n",
            " 35%|███▍      | 62/178 [00:03<00:06, 18.06it/s]\u001b[A\n",
            " 36%|███▌      | 64/178 [00:03<00:06, 17.99it/s]\u001b[A\n",
            " 37%|███▋      | 66/178 [00:03<00:06, 18.01it/s]\u001b[A\n",
            " 38%|███▊      | 68/178 [00:03<00:06, 18.02it/s]\u001b[A\n",
            " 39%|███▉      | 70/178 [00:03<00:06, 17.99it/s]\u001b[A\n",
            " 40%|████      | 72/178 [00:03<00:05, 18.09it/s]\u001b[A\n",
            " 42%|████▏     | 74/178 [00:04<00:05, 18.05it/s]\u001b[A\n",
            " 43%|████▎     | 76/178 [00:04<00:05, 18.19it/s]\u001b[A\n",
            " 44%|████▍     | 78/178 [00:04<00:05, 18.17it/s]\u001b[A\n",
            " 45%|████▍     | 80/178 [00:04<00:05, 18.20it/s]\u001b[A\n",
            " 46%|████▌     | 82/178 [00:04<00:05, 18.20it/s]\u001b[A\n",
            " 47%|████▋     | 84/178 [00:04<00:05, 18.05it/s]\u001b[A\n",
            " 48%|████▊     | 86/178 [00:04<00:05, 18.06it/s]\u001b[A\n",
            " 49%|████▉     | 88/178 [00:04<00:04, 18.11it/s]\u001b[A\n",
            " 51%|█████     | 90/178 [00:04<00:04, 18.08it/s]\u001b[A\n",
            " 52%|█████▏    | 92/178 [00:05<00:04, 18.14it/s]\u001b[A\n",
            " 53%|█████▎    | 94/178 [00:05<00:04, 18.24it/s]\u001b[A\n",
            " 54%|█████▍    | 96/178 [00:05<00:04, 18.30it/s]\u001b[A\n",
            " 55%|█████▌    | 98/178 [00:05<00:04, 18.33it/s]\u001b[A\n",
            " 56%|█████▌    | 100/178 [00:05<00:04, 18.22it/s]\u001b[A\n",
            " 57%|█████▋    | 102/178 [00:05<00:04, 18.34it/s]\u001b[A\n",
            " 58%|█████▊    | 104/178 [00:05<00:04, 18.30it/s]\u001b[A\n",
            " 60%|█████▉    | 106/178 [00:05<00:03, 18.34it/s]\u001b[A\n",
            " 61%|██████    | 108/178 [00:05<00:03, 18.35it/s]\u001b[A\n",
            " 62%|██████▏   | 110/178 [00:06<00:03, 18.32it/s]\u001b[A\n",
            " 63%|██████▎   | 112/178 [00:06<00:03, 18.32it/s]\u001b[A\n",
            " 64%|██████▍   | 114/178 [00:06<00:03, 18.16it/s]\u001b[A\n",
            " 65%|██████▌   | 116/178 [00:06<00:03, 18.11it/s]\u001b[A\n",
            " 66%|██████▋   | 118/178 [00:06<00:03, 18.12it/s]\u001b[A\n",
            " 67%|██████▋   | 120/178 [00:06<00:03, 18.16it/s]\u001b[A\n",
            " 69%|██████▊   | 122/178 [00:06<00:03, 18.08it/s]\u001b[A\n",
            " 70%|██████▉   | 124/178 [00:06<00:02, 18.17it/s]\u001b[A\n",
            " 71%|███████   | 126/178 [00:06<00:02, 18.20it/s]\u001b[A\n",
            " 72%|███████▏  | 128/178 [00:07<00:02, 18.25it/s]\u001b[A\n",
            " 73%|███████▎  | 130/178 [00:07<00:02, 18.21it/s]\u001b[A\n",
            " 74%|███████▍  | 132/178 [00:07<00:02, 18.29it/s]\u001b[A\n",
            " 75%|███████▌  | 134/178 [00:07<00:02, 18.28it/s]\u001b[A\n",
            " 76%|███████▋  | 136/178 [00:07<00:02, 18.42it/s]\u001b[A\n",
            " 78%|███████▊  | 138/178 [00:07<00:02, 18.45it/s]\u001b[A\n",
            " 79%|███████▊  | 140/178 [00:07<00:02, 18.34it/s]\u001b[A\n",
            " 80%|███████▉  | 142/178 [00:07<00:01, 18.25it/s]\u001b[A\n",
            " 81%|████████  | 144/178 [00:07<00:01, 18.22it/s]\u001b[A\n",
            " 82%|████████▏ | 146/178 [00:08<00:01, 18.17it/s]\u001b[A\n",
            " 83%|████████▎ | 148/178 [00:08<00:01, 18.22it/s]\u001b[A\n",
            " 84%|████████▍ | 150/178 [00:08<00:01, 18.22it/s]\u001b[A\n",
            " 85%|████████▌ | 152/178 [00:08<00:01, 18.25it/s]\u001b[A\n",
            " 87%|████████▋ | 154/178 [00:08<00:01, 18.17it/s]\u001b[A\n",
            " 88%|████████▊ | 156/178 [00:08<00:01, 18.16it/s]\u001b[A\n",
            " 89%|████████▉ | 158/178 [00:08<00:01, 18.00it/s]\u001b[A\n",
            " 90%|████████▉ | 160/178 [00:08<00:00, 18.19it/s]\u001b[A\n",
            " 91%|█████████ | 162/178 [00:08<00:00, 18.17it/s]\u001b[A\n",
            " 92%|█████████▏| 164/178 [00:09<00:00, 18.25it/s]\u001b[A\n",
            " 93%|█████████▎| 166/178 [00:09<00:00, 18.23it/s]\u001b[A\n",
            " 94%|█████████▍| 168/178 [00:09<00:00, 18.28it/s]\u001b[A\n",
            " 96%|█████████▌| 170/178 [00:09<00:00, 18.17it/s]\u001b[A\n",
            " 97%|█████████▋| 172/178 [00:09<00:00, 18.24it/s]\u001b[A\n",
            " 98%|█████████▊| 174/178 [00:09<00:00, 18.14it/s]\u001b[A\n",
            "100%|██████████| 178/178 [00:09<00:00, 18.21it/s]\n",
            " 14%|█▍        | 203/1422 [00:40<1:02:46,  3.09s/it]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            " 14%|█▍        | 204/1422 [00:40<44:48,  2.21s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 0.3177 Val acc: 0.9043 Val f1: 0.9043 AUC: 0.4912\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 405/1422 [01:10<02:34,  6.60it/s]\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 2/178 [00:00<00:09, 18.52it/s]\u001b[A\n",
            "  2%|▏         | 4/178 [00:00<00:09, 18.03it/s]\u001b[A\n",
            "  3%|▎         | 6/178 [00:00<00:09, 17.62it/s]\u001b[A\n",
            "  4%|▍         | 8/178 [00:00<00:09, 17.64it/s]\u001b[A\n",
            "  6%|▌         | 10/178 [00:00<00:09, 17.71it/s]\u001b[A\n",
            "  7%|▋         | 12/178 [00:00<00:09, 17.77it/s]\u001b[A\n",
            "  8%|▊         | 14/178 [00:00<00:09, 17.68it/s]\u001b[A\n",
            "  9%|▉         | 16/178 [00:00<00:09, 17.83it/s]\u001b[A\n",
            " 10%|█         | 18/178 [00:01<00:08, 17.78it/s]\u001b[A\n",
            " 11%|█         | 20/178 [00:01<00:08, 17.83it/s]\u001b[A\n",
            " 12%|█▏        | 22/178 [00:01<00:08, 17.84it/s]\u001b[A\n",
            " 13%|█▎        | 24/178 [00:01<00:08, 17.86it/s]\u001b[A\n",
            " 15%|█▍        | 26/178 [00:01<00:08, 17.93it/s]\u001b[A\n",
            " 16%|█▌        | 28/178 [00:01<00:08, 17.83it/s]\u001b[A\n",
            " 17%|█▋        | 30/178 [00:01<00:08, 17.85it/s]\u001b[A\n",
            " 18%|█▊        | 32/178 [00:01<00:08, 17.83it/s]\u001b[A\n",
            " 19%|█▉        | 34/178 [00:01<00:08, 17.88it/s]\u001b[A\n",
            " 20%|██        | 36/178 [00:02<00:07, 17.96it/s]\u001b[A\n",
            " 21%|██▏       | 38/178 [00:02<00:07, 17.98it/s]\u001b[A\n",
            " 22%|██▏       | 40/178 [00:02<00:07, 17.91it/s]\u001b[A\n",
            " 24%|██▎       | 42/178 [00:02<00:07, 17.92it/s]\u001b[A\n",
            " 25%|██▍       | 44/178 [00:02<00:07, 17.88it/s]\u001b[A\n",
            " 26%|██▌       | 46/178 [00:02<00:07, 17.89it/s]\u001b[A\n",
            " 27%|██▋       | 48/178 [00:02<00:07, 17.86it/s]\u001b[A\n",
            " 28%|██▊       | 50/178 [00:02<00:07, 17.72it/s]\u001b[A\n",
            " 29%|██▉       | 52/178 [00:02<00:07, 17.83it/s]\u001b[A\n",
            " 30%|███       | 54/178 [00:03<00:06, 17.84it/s]\u001b[A\n",
            " 31%|███▏      | 56/178 [00:03<00:06, 17.90it/s]\u001b[A\n",
            " 33%|███▎      | 58/178 [00:03<00:06, 17.94it/s]\u001b[A\n",
            " 34%|███▎      | 60/178 [00:03<00:06, 18.04it/s]\u001b[A\n",
            " 35%|███▍      | 62/178 [00:03<00:06, 18.08it/s]\u001b[A\n",
            " 36%|███▌      | 64/178 [00:03<00:06, 18.04it/s]\u001b[A\n",
            " 37%|███▋      | 66/178 [00:03<00:06, 18.09it/s]\u001b[A\n",
            " 38%|███▊      | 68/178 [00:03<00:06, 18.08it/s]\u001b[A\n",
            " 39%|███▉      | 70/178 [00:03<00:06, 17.95it/s]\u001b[A\n",
            " 40%|████      | 72/178 [00:04<00:05, 17.97it/s]\u001b[A\n",
            " 42%|████▏     | 74/178 [00:04<00:05, 17.80it/s]\u001b[A\n",
            " 43%|████▎     | 76/178 [00:04<00:05, 17.93it/s]\u001b[A\n",
            " 44%|████▍     | 78/178 [00:04<00:05, 17.95it/s]\u001b[A\n",
            " 45%|████▍     | 80/178 [00:04<00:05, 17.93it/s]\u001b[A\n",
            " 46%|████▌     | 82/178 [00:04<00:05, 17.95it/s]\u001b[A\n",
            " 47%|████▋     | 84/178 [00:04<00:05, 18.04it/s]\u001b[A\n",
            " 48%|████▊     | 86/178 [00:04<00:05, 18.02it/s]\u001b[A\n",
            " 49%|████▉     | 88/178 [00:04<00:05, 17.98it/s]\u001b[A\n",
            " 51%|█████     | 90/178 [00:05<00:04, 17.94it/s]\u001b[A\n",
            " 52%|█████▏    | 92/178 [00:05<00:04, 17.90it/s]\u001b[A\n",
            " 53%|█████▎    | 94/178 [00:05<00:04, 17.88it/s]\u001b[A\n",
            " 54%|█████▍    | 96/178 [00:05<00:04, 17.85it/s]\u001b[A\n",
            " 55%|█████▌    | 98/178 [00:05<00:04, 17.89it/s]\u001b[A\n",
            " 56%|█████▌    | 100/178 [00:05<00:04, 17.89it/s]\u001b[A\n",
            " 57%|█████▋    | 102/178 [00:05<00:04, 17.85it/s]\u001b[A\n",
            " 58%|█████▊    | 104/178 [00:05<00:04, 17.82it/s]\u001b[A\n",
            " 60%|█████▉    | 106/178 [00:05<00:04, 17.89it/s]\u001b[A\n",
            " 61%|██████    | 108/178 [00:06<00:03, 17.79it/s]\u001b[A\n",
            " 62%|██████▏   | 110/178 [00:06<00:03, 17.60it/s]\u001b[A\n",
            " 63%|██████▎   | 112/178 [00:06<00:03, 17.68it/s]\u001b[A\n",
            " 64%|██████▍   | 114/178 [00:06<00:03, 17.67it/s]\u001b[A\n",
            " 65%|██████▌   | 116/178 [00:06<00:03, 17.68it/s]\u001b[A\n",
            " 66%|██████▋   | 118/178 [00:06<00:03, 17.81it/s]\u001b[A\n",
            " 67%|██████▋   | 120/178 [00:06<00:03, 17.82it/s]\u001b[A\n",
            " 69%|██████▊   | 122/178 [00:06<00:03, 17.85it/s]\u001b[A\n",
            " 70%|██████▉   | 124/178 [00:06<00:03, 17.89it/s]\u001b[A\n",
            " 71%|███████   | 126/178 [00:07<00:02, 17.85it/s]\u001b[A\n",
            " 72%|███████▏  | 128/178 [00:07<00:02, 17.94it/s]\u001b[A\n",
            " 73%|███████▎  | 130/178 [00:07<00:02, 17.89it/s]\u001b[A\n",
            " 74%|███████▍  | 132/178 [00:07<00:02, 17.88it/s]\u001b[A\n",
            " 75%|███████▌  | 134/178 [00:07<00:02, 17.94it/s]\u001b[A\n",
            " 76%|███████▋  | 136/178 [00:07<00:02, 17.96it/s]\u001b[A\n",
            " 78%|███████▊  | 138/178 [00:07<00:02, 17.98it/s]\u001b[A\n",
            " 79%|███████▊  | 140/178 [00:07<00:02, 17.88it/s]\u001b[A\n",
            " 80%|███████▉  | 142/178 [00:07<00:02, 17.98it/s]\u001b[A\n",
            " 81%|████████  | 144/178 [00:08<00:01, 17.88it/s]\u001b[A\n",
            " 82%|████████▏ | 146/178 [00:08<00:01, 17.85it/s]\u001b[A\n",
            " 83%|████████▎ | 148/178 [00:08<00:01, 17.86it/s]\u001b[A\n",
            " 84%|████████▍ | 150/178 [00:08<00:01, 17.88it/s]\u001b[A\n",
            " 85%|████████▌ | 152/178 [00:08<00:01, 17.92it/s]\u001b[A\n",
            " 87%|████████▋ | 154/178 [00:08<00:01, 18.00it/s]\u001b[A\n",
            " 88%|████████▊ | 156/178 [00:08<00:01, 17.93it/s]\u001b[A\n",
            " 89%|████████▉ | 158/178 [00:08<00:01, 17.86it/s]\u001b[A\n",
            " 90%|████████▉ | 160/178 [00:08<00:01, 17.92it/s]\u001b[A\n",
            " 91%|█████████ | 162/178 [00:09<00:00, 17.86it/s]\u001b[A\n",
            " 92%|█████████▏| 164/178 [00:09<00:00, 17.90it/s]\u001b[A\n",
            " 93%|█████████▎| 166/178 [00:09<00:00, 17.91it/s]\u001b[A\n",
            " 94%|█████████▍| 168/178 [00:09<00:00, 17.80it/s]\u001b[A\n",
            " 96%|█████████▌| 170/178 [00:09<00:00, 17.76it/s]\u001b[A\n",
            " 97%|█████████▋| 172/178 [00:09<00:00, 17.72it/s]\u001b[A\n",
            " 98%|█████████▊| 174/178 [00:09<00:00, 17.88it/s]\u001b[A\n",
            "100%|██████████| 178/178 [00:09<00:00, 17.90it/s]\n",
            " 29%|██▊       | 406/1422 [01:21<53:06,  3.14s/it]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            " 29%|██▊       | 407/1422 [01:21<37:53,  2.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 0.3167 Val acc: 0.9043 Val f1: 0.9043 AUC: 0.5321\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 608/1422 [01:51<02:01,  6.72it/s]\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 2/178 [00:00<00:09, 19.14it/s]\u001b[A\n",
            "  2%|▏         | 4/178 [00:00<00:09, 18.51it/s]\u001b[A\n",
            "  3%|▎         | 6/178 [00:00<00:09, 18.47it/s]\u001b[A\n",
            "  4%|▍         | 8/178 [00:00<00:09, 18.43it/s]\u001b[A\n",
            "  6%|▌         | 10/178 [00:00<00:09, 18.47it/s]\u001b[A\n",
            "  7%|▋         | 12/178 [00:00<00:08, 18.50it/s]\u001b[A\n",
            "  8%|▊         | 14/178 [00:00<00:09, 18.17it/s]\u001b[A\n",
            "  9%|▉         | 16/178 [00:00<00:08, 18.07it/s]\u001b[A\n",
            " 10%|█         | 18/178 [00:00<00:08, 18.13it/s]\u001b[A\n",
            " 11%|█         | 20/178 [00:01<00:08, 18.25it/s]\u001b[A\n",
            " 12%|█▏        | 22/178 [00:01<00:08, 18.36it/s]\u001b[A\n",
            " 13%|█▎        | 24/178 [00:01<00:08, 18.32it/s]\u001b[A\n",
            " 15%|█▍        | 26/178 [00:01<00:08, 18.39it/s]\u001b[A\n",
            " 16%|█▌        | 28/178 [00:01<00:08, 18.40it/s]\u001b[A\n",
            " 17%|█▋        | 30/178 [00:01<00:08, 18.43it/s]\u001b[A\n",
            " 18%|█▊        | 32/178 [00:01<00:07, 18.43it/s]\u001b[A\n",
            " 19%|█▉        | 34/178 [00:01<00:07, 18.40it/s]\u001b[A\n",
            " 20%|██        | 36/178 [00:01<00:07, 18.29it/s]\u001b[A\n",
            " 21%|██▏       | 38/178 [00:02<00:07, 18.40it/s]\u001b[A\n",
            " 22%|██▏       | 40/178 [00:02<00:07, 18.36it/s]\u001b[A\n",
            " 24%|██▎       | 42/178 [00:02<00:07, 18.46it/s]\u001b[A\n",
            " 25%|██▍       | 44/178 [00:02<00:07, 18.41it/s]\u001b[A\n",
            " 26%|██▌       | 46/178 [00:02<00:07, 18.45it/s]\u001b[A\n",
            " 27%|██▋       | 48/178 [00:02<00:07, 18.47it/s]\u001b[A\n",
            " 28%|██▊       | 50/178 [00:02<00:06, 18.40it/s]\u001b[A\n",
            " 29%|██▉       | 52/178 [00:02<00:06, 18.39it/s]\u001b[A\n",
            " 30%|███       | 54/178 [00:02<00:06, 18.30it/s]\u001b[A\n",
            " 31%|███▏      | 56/178 [00:03<00:06, 18.34it/s]\u001b[A\n",
            " 33%|███▎      | 58/178 [00:03<00:06, 18.40it/s]\u001b[A\n",
            " 34%|███▎      | 60/178 [00:03<00:06, 18.30it/s]\u001b[A\n",
            " 35%|███▍      | 62/178 [00:03<00:06, 18.19it/s]\u001b[A\n",
            " 36%|███▌      | 64/178 [00:03<00:06, 18.28it/s]\u001b[A\n",
            " 37%|███▋      | 66/178 [00:03<00:06, 18.35it/s]\u001b[A\n",
            " 38%|███▊      | 68/178 [00:03<00:06, 18.30it/s]\u001b[A\n",
            " 39%|███▉      | 70/178 [00:03<00:05, 18.24it/s]\u001b[A\n",
            " 40%|████      | 72/178 [00:03<00:05, 18.36it/s]\u001b[A\n",
            " 42%|████▏     | 74/178 [00:04<00:05, 18.36it/s]\u001b[A\n",
            " 43%|████▎     | 76/178 [00:04<00:05, 18.37it/s]\u001b[A\n",
            " 44%|████▍     | 78/178 [00:04<00:05, 18.29it/s]\u001b[A\n",
            " 45%|████▍     | 80/178 [00:04<00:05, 18.28it/s]\u001b[A\n",
            " 46%|████▌     | 82/178 [00:04<00:05, 18.24it/s]\u001b[A\n",
            " 47%|████▋     | 84/178 [00:04<00:05, 18.36it/s]\u001b[A\n",
            " 48%|████▊     | 86/178 [00:04<00:05, 18.33it/s]\u001b[A\n",
            " 49%|████▉     | 88/178 [00:04<00:04, 18.13it/s]\u001b[A\n",
            " 51%|█████     | 90/178 [00:04<00:04, 18.28it/s]\u001b[A\n",
            " 52%|█████▏    | 92/178 [00:05<00:04, 18.38it/s]\u001b[A\n",
            " 53%|█████▎    | 94/178 [00:05<00:04, 18.46it/s]\u001b[A\n",
            " 54%|█████▍    | 96/178 [00:05<00:04, 18.51it/s]\u001b[A\n",
            " 55%|█████▌    | 98/178 [00:05<00:04, 18.30it/s]\u001b[A\n",
            " 56%|█████▌    | 100/178 [00:05<00:04, 18.40it/s]\u001b[A\n",
            " 57%|█████▋    | 102/178 [00:05<00:04, 18.49it/s]\u001b[A\n",
            " 58%|█████▊    | 104/178 [00:05<00:03, 18.56it/s]\u001b[A\n",
            " 60%|█████▉    | 106/178 [00:05<00:03, 18.58it/s]\u001b[A\n",
            " 61%|██████    | 108/178 [00:05<00:03, 18.69it/s]\u001b[A\n",
            " 62%|██████▏   | 110/178 [00:05<00:03, 18.61it/s]\u001b[A\n",
            " 63%|██████▎   | 112/178 [00:06<00:03, 18.57it/s]\u001b[A\n",
            " 64%|██████▍   | 114/178 [00:06<00:03, 18.57it/s]\u001b[A\n",
            " 65%|██████▌   | 116/178 [00:06<00:03, 18.55it/s]\u001b[A\n",
            " 66%|██████▋   | 118/178 [00:06<00:03, 18.70it/s]\u001b[A\n",
            " 67%|██████▋   | 120/178 [00:06<00:03, 18.72it/s]\u001b[A\n",
            " 69%|██████▊   | 122/178 [00:06<00:02, 18.77it/s]\u001b[A\n",
            " 70%|██████▉   | 124/178 [00:06<00:02, 18.79it/s]\u001b[A\n",
            " 71%|███████   | 126/178 [00:06<00:02, 18.70it/s]\u001b[A\n",
            " 72%|███████▏  | 128/178 [00:06<00:02, 18.58it/s]\u001b[A\n",
            " 73%|███████▎  | 130/178 [00:07<00:02, 18.59it/s]\u001b[A\n",
            " 74%|███████▍  | 132/178 [00:07<00:02, 18.68it/s]\u001b[A\n",
            " 75%|███████▌  | 134/178 [00:07<00:02, 18.72it/s]\u001b[A\n",
            " 76%|███████▋  | 136/178 [00:07<00:02, 18.62it/s]\u001b[A\n",
            " 78%|███████▊  | 138/178 [00:07<00:02, 18.62it/s]\u001b[A\n",
            " 79%|███████▊  | 140/178 [00:07<00:02, 18.57it/s]\u001b[A\n",
            " 80%|███████▉  | 142/178 [00:07<00:01, 18.63it/s]\u001b[A\n",
            " 81%|████████  | 144/178 [00:07<00:01, 18.47it/s]\u001b[A\n",
            " 82%|████████▏ | 146/178 [00:07<00:01, 18.57it/s]\u001b[A\n",
            " 83%|████████▎ | 148/178 [00:08<00:01, 18.52it/s]\u001b[A\n",
            " 84%|████████▍ | 150/178 [00:08<00:01, 18.52it/s]\u001b[A\n",
            " 85%|████████▌ | 152/178 [00:08<00:01, 18.57it/s]\u001b[A\n",
            " 87%|████████▋ | 154/178 [00:08<00:01, 18.44it/s]\u001b[A\n",
            " 88%|████████▊ | 156/178 [00:08<00:01, 18.42it/s]\u001b[A\n",
            " 89%|████████▉ | 158/178 [00:08<00:01, 18.43it/s]\u001b[A\n",
            " 90%|████████▉ | 160/178 [00:08<00:00, 18.41it/s]\u001b[A\n",
            " 91%|█████████ | 162/178 [00:08<00:00, 18.33it/s]\u001b[A\n",
            " 92%|█████████▏| 164/178 [00:08<00:00, 18.19it/s]\u001b[A\n",
            " 93%|█████████▎| 166/178 [00:09<00:00, 18.18it/s]\u001b[A\n",
            " 94%|█████████▍| 168/178 [00:09<00:00, 18.23it/s]\u001b[A\n",
            " 96%|█████████▌| 170/178 [00:09<00:00, 18.18it/s]\u001b[A\n",
            " 97%|█████████▋| 172/178 [00:09<00:00, 18.17it/s]\u001b[A\n",
            " 98%|█████████▊| 174/178 [00:09<00:00, 18.22it/s]\u001b[A\n",
            "100%|██████████| 178/178 [00:09<00:00, 18.45it/s]\n",
            " 43%|████▎     | 609/1422 [02:01<41:16,  3.05s/it]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            " 43%|████▎     | 610/1422 [02:01<29:27,  2.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 0.3183 Val acc: 0.9043 Val f1: 0.9043 AUC: 0.4511\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 811/1422 [02:31<01:29,  6.79it/s]\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 2/178 [00:00<00:09, 19.14it/s]\u001b[A\n",
            "  2%|▏         | 4/178 [00:00<00:09, 18.41it/s]\u001b[A\n",
            "  3%|▎         | 6/178 [00:00<00:09, 18.31it/s]\u001b[A\n",
            "  4%|▍         | 8/178 [00:00<00:09, 18.10it/s]\u001b[A\n",
            "  6%|▌         | 10/178 [00:00<00:09, 18.18it/s]\u001b[A\n",
            "  7%|▋         | 12/178 [00:00<00:09, 18.22it/s]\u001b[A\n",
            "  8%|▊         | 14/178 [00:00<00:09, 18.07it/s]\u001b[A\n",
            "  9%|▉         | 16/178 [00:00<00:08, 18.09it/s]\u001b[A\n",
            " 10%|█         | 18/178 [00:00<00:08, 18.11it/s]\u001b[A\n",
            " 11%|█         | 20/178 [00:01<00:08, 18.12it/s]\u001b[A\n",
            " 12%|█▏        | 22/178 [00:01<00:08, 18.06it/s]\u001b[A\n",
            " 13%|█▎        | 24/178 [00:01<00:08, 18.15it/s]\u001b[A\n",
            " 15%|█▍        | 26/178 [00:01<00:08, 18.25it/s]\u001b[A\n",
            " 16%|█▌        | 28/178 [00:01<00:08, 18.34it/s]\u001b[A\n",
            " 17%|█▋        | 30/178 [00:01<00:08, 18.31it/s]\u001b[A\n",
            " 18%|█▊        | 32/178 [00:01<00:07, 18.43it/s]\u001b[A\n",
            " 19%|█▉        | 34/178 [00:01<00:07, 18.35it/s]\u001b[A\n",
            " 20%|██        | 36/178 [00:01<00:07, 18.36it/s]\u001b[A\n",
            " 21%|██▏       | 38/178 [00:02<00:07, 18.36it/s]\u001b[A\n",
            " 22%|██▏       | 40/178 [00:02<00:07, 18.41it/s]\u001b[A\n",
            " 24%|██▎       | 42/178 [00:02<00:07, 18.35it/s]\u001b[A\n",
            " 25%|██▍       | 44/178 [00:02<00:07, 18.04it/s]\u001b[A\n",
            " 26%|██▌       | 46/178 [00:02<00:07, 18.15it/s]\u001b[A\n",
            " 27%|██▋       | 48/178 [00:02<00:07, 18.17it/s]\u001b[A\n",
            " 28%|██▊       | 50/178 [00:02<00:07, 18.16it/s]\u001b[A\n",
            " 29%|██▉       | 52/178 [00:02<00:06, 18.31it/s]\u001b[A\n",
            " 30%|███       | 54/178 [00:02<00:06, 18.33it/s]\u001b[A\n",
            " 31%|███▏      | 56/178 [00:03<00:06, 18.47it/s]\u001b[A\n",
            " 33%|███▎      | 58/178 [00:03<00:06, 18.42it/s]\u001b[A\n",
            " 34%|███▎      | 60/178 [00:03<00:06, 18.41it/s]\u001b[A\n",
            " 35%|███▍      | 62/178 [00:03<00:06, 18.18it/s]\u001b[A\n",
            " 36%|███▌      | 64/178 [00:03<00:06, 18.13it/s]\u001b[A\n",
            " 37%|███▋      | 66/178 [00:03<00:06, 18.23it/s]\u001b[A\n",
            " 38%|███▊      | 68/178 [00:03<00:06, 18.29it/s]\u001b[A\n",
            " 39%|███▉      | 70/178 [00:03<00:05, 18.31it/s]\u001b[A\n",
            " 40%|████      | 72/178 [00:03<00:05, 18.42it/s]\u001b[A\n",
            " 42%|████▏     | 74/178 [00:04<00:05, 18.31it/s]\u001b[A\n",
            " 43%|████▎     | 76/178 [00:04<00:05, 18.35it/s]\u001b[A\n",
            " 44%|████▍     | 78/178 [00:04<00:05, 18.27it/s]\u001b[A\n",
            " 45%|████▍     | 80/178 [00:04<00:05, 18.27it/s]\u001b[A\n",
            " 46%|████▌     | 82/178 [00:04<00:05, 18.24it/s]\u001b[A\n",
            " 47%|████▋     | 84/178 [00:04<00:05, 18.29it/s]\u001b[A\n",
            " 48%|████▊     | 86/178 [00:04<00:05, 18.30it/s]\u001b[A\n",
            " 49%|████▉     | 88/178 [00:04<00:04, 18.27it/s]\u001b[A\n",
            " 51%|█████     | 90/178 [00:04<00:04, 18.22it/s]\u001b[A\n",
            " 52%|█████▏    | 92/178 [00:05<00:04, 18.12it/s]\u001b[A\n",
            " 53%|█████▎    | 94/178 [00:05<00:04, 18.19it/s]\u001b[A\n",
            " 54%|█████▍    | 96/178 [00:05<00:04, 18.05it/s]\u001b[A\n",
            " 55%|█████▌    | 98/178 [00:05<00:04, 18.17it/s]\u001b[A\n",
            " 56%|█████▌    | 100/178 [00:05<00:04, 18.21it/s]\u001b[A\n",
            " 57%|█████▋    | 102/178 [00:05<00:04, 18.25it/s]\u001b[A\n",
            " 58%|█████▊    | 104/178 [00:05<00:04, 18.24it/s]\u001b[A\n",
            " 60%|█████▉    | 106/178 [00:05<00:03, 18.19it/s]\u001b[A\n",
            " 61%|██████    | 108/178 [00:05<00:03, 18.20it/s]\u001b[A\n",
            " 62%|██████▏   | 110/178 [00:06<00:03, 18.22it/s]\u001b[A\n",
            " 63%|██████▎   | 112/178 [00:06<00:03, 18.23it/s]\u001b[A\n",
            " 64%|██████▍   | 114/178 [00:06<00:03, 18.29it/s]\u001b[A\n",
            " 65%|██████▌   | 116/178 [00:06<00:03, 18.33it/s]\u001b[A\n",
            " 66%|██████▋   | 118/178 [00:06<00:03, 18.35it/s]\u001b[A\n",
            " 67%|██████▋   | 120/178 [00:06<00:03, 18.35it/s]\u001b[A\n",
            " 69%|██████▊   | 122/178 [00:06<00:03, 18.42it/s]\u001b[A\n",
            " 70%|██████▉   | 124/178 [00:06<00:02, 18.39it/s]\u001b[A\n",
            " 71%|███████   | 126/178 [00:06<00:02, 18.39it/s]\u001b[A\n",
            " 72%|███████▏  | 128/178 [00:07<00:02, 18.39it/s]\u001b[A\n",
            " 73%|███████▎  | 130/178 [00:07<00:02, 18.24it/s]\u001b[A\n",
            " 74%|███████▍  | 132/178 [00:07<00:02, 18.32it/s]\u001b[A\n",
            " 75%|███████▌  | 134/178 [00:07<00:02, 18.22it/s]\u001b[A\n",
            " 76%|███████▋  | 136/178 [00:07<00:02, 18.21it/s]\u001b[A\n",
            " 78%|███████▊  | 138/178 [00:07<00:02, 18.13it/s]\u001b[A\n",
            " 79%|███████▊  | 140/178 [00:07<00:02, 18.05it/s]\u001b[A\n",
            " 80%|███████▉  | 142/178 [00:07<00:01, 18.04it/s]\u001b[A\n",
            " 81%|████████  | 144/178 [00:07<00:01, 18.15it/s]\u001b[A\n",
            " 82%|████████▏ | 146/178 [00:08<00:01, 18.13it/s]\u001b[A\n",
            " 83%|████████▎ | 148/178 [00:08<00:01, 18.22it/s]\u001b[A\n",
            " 84%|████████▍ | 150/178 [00:08<00:01, 18.31it/s]\u001b[A\n",
            " 85%|████████▌ | 152/178 [00:08<00:01, 18.32it/s]\u001b[A\n",
            " 87%|████████▋ | 154/178 [00:08<00:01, 18.23it/s]\u001b[A\n",
            " 88%|████████▊ | 156/178 [00:08<00:01, 18.25it/s]\u001b[A\n",
            " 89%|████████▉ | 158/178 [00:08<00:01, 18.30it/s]\u001b[A\n",
            " 90%|████████▉ | 160/178 [00:08<00:00, 18.32it/s]\u001b[A\n",
            " 91%|█████████ | 162/178 [00:08<00:00, 18.37it/s]\u001b[A\n",
            " 92%|█████████▏| 164/178 [00:08<00:00, 18.18it/s]\u001b[A\n",
            " 93%|█████████▎| 166/178 [00:09<00:00, 18.16it/s]\u001b[A\n",
            " 94%|█████████▍| 168/178 [00:09<00:00, 18.26it/s]\u001b[A\n",
            " 96%|█████████▌| 170/178 [00:09<00:00, 18.26it/s]\u001b[A\n",
            " 97%|█████████▋| 172/178 [00:09<00:00, 18.29it/s]\u001b[A\n",
            " 98%|█████████▊| 174/178 [00:09<00:00, 18.41it/s]\u001b[A\n",
            "100%|██████████| 178/178 [00:09<00:00, 18.29it/s]\n",
            " 57%|█████▋    | 812/1422 [02:41<31:12,  3.07s/it]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            " 57%|█████▋    | 813/1422 [02:41<22:15,  2.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 0.3159 Val acc: 0.9043 Val f1: 0.9043 AUC: 0.5080\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 71%|███████▏  | 1014/1422 [03:12<00:59,  6.80it/s]\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 2/178 [00:00<00:09, 18.01it/s]\u001b[A\n",
            "  2%|▏         | 4/178 [00:00<00:09, 17.76it/s]\u001b[A\n",
            "  3%|▎         | 6/178 [00:00<00:09, 17.72it/s]\u001b[A\n",
            "  4%|▍         | 8/178 [00:00<00:09, 17.80it/s]\u001b[A\n",
            "  6%|▌         | 10/178 [00:00<00:09, 17.75it/s]\u001b[A\n",
            "  7%|▋         | 12/178 [00:00<00:09, 17.72it/s]\u001b[A\n",
            "  8%|▊         | 14/178 [00:00<00:09, 17.70it/s]\u001b[A\n",
            "  9%|▉         | 16/178 [00:00<00:09, 17.80it/s]\u001b[A\n",
            " 10%|█         | 18/178 [00:01<00:08, 17.85it/s]\u001b[A\n",
            " 11%|█         | 20/178 [00:01<00:08, 17.88it/s]\u001b[A\n",
            " 12%|█▏        | 22/178 [00:01<00:08, 17.79it/s]\u001b[A\n",
            " 13%|█▎        | 24/178 [00:01<00:08, 17.83it/s]\u001b[A\n",
            " 15%|█▍        | 26/178 [00:01<00:08, 17.79it/s]\u001b[A\n",
            " 16%|█▌        | 28/178 [00:01<00:08, 17.74it/s]\u001b[A\n",
            " 17%|█▋        | 30/178 [00:01<00:08, 17.77it/s]\u001b[A\n",
            " 18%|█▊        | 32/178 [00:01<00:08, 17.70it/s]\u001b[A\n",
            " 19%|█▉        | 34/178 [00:01<00:08, 17.67it/s]\u001b[A\n",
            " 20%|██        | 36/178 [00:02<00:08, 17.71it/s]\u001b[A\n",
            " 21%|██▏       | 38/178 [00:02<00:07, 17.79it/s]\u001b[A\n",
            " 22%|██▏       | 40/178 [00:02<00:07, 17.87it/s]\u001b[A\n",
            " 24%|██▎       | 42/178 [00:02<00:07, 17.72it/s]\u001b[A\n",
            " 25%|██▍       | 44/178 [00:02<00:07, 17.67it/s]\u001b[A\n",
            " 26%|██▌       | 46/178 [00:02<00:07, 17.63it/s]\u001b[A\n",
            " 27%|██▋       | 48/178 [00:02<00:07, 17.71it/s]\u001b[A\n",
            " 28%|██▊       | 50/178 [00:02<00:07, 17.75it/s]\u001b[A\n",
            " 29%|██▉       | 52/178 [00:02<00:07, 17.72it/s]\u001b[A\n",
            " 30%|███       | 54/178 [00:03<00:06, 17.72it/s]\u001b[A\n",
            " 31%|███▏      | 56/178 [00:03<00:06, 17.71it/s]\u001b[A\n",
            " 33%|███▎      | 58/178 [00:03<00:06, 17.65it/s]\u001b[A\n",
            " 34%|███▎      | 60/178 [00:03<00:06, 17.61it/s]\u001b[A\n",
            " 35%|███▍      | 62/178 [00:03<00:06, 17.70it/s]\u001b[A\n",
            " 36%|███▌      | 64/178 [00:03<00:06, 17.64it/s]\u001b[A\n",
            " 37%|███▋      | 66/178 [00:03<00:06, 17.63it/s]\u001b[A\n",
            " 38%|███▊      | 68/178 [00:03<00:06, 17.42it/s]\u001b[A\n",
            " 39%|███▉      | 70/178 [00:03<00:06, 17.50it/s]\u001b[A\n",
            " 40%|████      | 72/178 [00:04<00:06, 17.49it/s]\u001b[A\n",
            " 42%|████▏     | 74/178 [00:04<00:05, 17.60it/s]\u001b[A\n",
            " 43%|████▎     | 76/178 [00:04<00:05, 17.64it/s]\u001b[A\n",
            " 44%|████▍     | 78/178 [00:04<00:05, 17.68it/s]\u001b[A\n",
            " 45%|████▍     | 80/178 [00:04<00:05, 17.69it/s]\u001b[A\n",
            " 46%|████▌     | 82/178 [00:04<00:05, 17.67it/s]\u001b[A\n",
            " 47%|████▋     | 84/178 [00:04<00:05, 17.63it/s]\u001b[A\n",
            " 48%|████▊     | 86/178 [00:04<00:05, 17.51it/s]\u001b[A\n",
            " 49%|████▉     | 88/178 [00:04<00:05, 17.52it/s]\u001b[A\n",
            " 51%|█████     | 90/178 [00:05<00:05, 17.47it/s]\u001b[A\n",
            " 52%|█████▏    | 92/178 [00:05<00:04, 17.53it/s]\u001b[A\n",
            " 53%|█████▎    | 94/178 [00:05<00:04, 17.61it/s]\u001b[A\n",
            " 54%|█████▍    | 96/178 [00:05<00:04, 17.76it/s]\u001b[A\n",
            " 55%|█████▌    | 98/178 [00:05<00:04, 17.90it/s]\u001b[A\n",
            " 56%|█████▌    | 100/178 [00:05<00:04, 17.81it/s]\u001b[A\n",
            " 57%|█████▋    | 102/178 [00:05<00:04, 17.64it/s]\u001b[A\n",
            " 58%|█████▊    | 104/178 [00:05<00:04, 17.56it/s]\u001b[A\n",
            " 60%|█████▉    | 106/178 [00:05<00:04, 17.50it/s]\u001b[A\n",
            " 61%|██████    | 108/178 [00:06<00:03, 17.61it/s]\u001b[A\n",
            " 62%|██████▏   | 110/178 [00:06<00:03, 17.52it/s]\u001b[A\n",
            " 63%|██████▎   | 112/178 [00:06<00:03, 17.67it/s]\u001b[A\n",
            " 64%|██████▍   | 114/178 [00:06<00:03, 17.78it/s]\u001b[A\n",
            " 65%|██████▌   | 116/178 [00:06<00:03, 17.74it/s]\u001b[A\n",
            " 66%|██████▋   | 118/178 [00:06<00:03, 17.82it/s]\u001b[A\n",
            " 67%|██████▋   | 120/178 [00:06<00:03, 17.85it/s]\u001b[A\n",
            " 69%|██████▊   | 122/178 [00:06<00:03, 17.91it/s]\u001b[A\n",
            " 70%|██████▉   | 124/178 [00:07<00:03, 17.81it/s]\u001b[A\n",
            " 71%|███████   | 126/178 [00:07<00:02, 17.80it/s]\u001b[A\n",
            " 72%|███████▏  | 128/178 [00:07<00:02, 17.71it/s]\u001b[A\n",
            " 73%|███████▎  | 130/178 [00:07<00:02, 17.83it/s]\u001b[A\n",
            " 74%|███████▍  | 132/178 [00:07<00:02, 17.86it/s]\u001b[A\n",
            " 75%|███████▌  | 134/178 [00:07<00:02, 17.84it/s]\u001b[A\n",
            " 76%|███████▋  | 136/178 [00:07<00:02, 17.75it/s]\u001b[A\n",
            " 78%|███████▊  | 138/178 [00:07<00:02, 17.67it/s]\u001b[A\n",
            " 79%|███████▊  | 140/178 [00:07<00:02, 17.76it/s]\u001b[A\n",
            " 80%|███████▉  | 142/178 [00:08<00:02, 17.82it/s]\u001b[A\n",
            " 81%|████████  | 144/178 [00:08<00:01, 17.83it/s]\u001b[A\n",
            " 82%|████████▏ | 146/178 [00:08<00:01, 17.63it/s]\u001b[A\n",
            " 83%|████████▎ | 148/178 [00:08<00:01, 17.60it/s]\u001b[A\n",
            " 84%|████████▍ | 150/178 [00:08<00:01, 17.69it/s]\u001b[A\n",
            " 85%|████████▌ | 152/178 [00:08<00:01, 17.84it/s]\u001b[A\n",
            " 87%|████████▋ | 154/178 [00:08<00:01, 17.89it/s]\u001b[A\n",
            " 88%|████████▊ | 156/178 [00:08<00:01, 17.90it/s]\u001b[A\n",
            " 89%|████████▉ | 158/178 [00:08<00:01, 17.90it/s]\u001b[A\n",
            " 90%|████████▉ | 160/178 [00:09<00:01, 17.95it/s]\u001b[A\n",
            " 91%|█████████ | 162/178 [00:09<00:00, 17.99it/s]\u001b[A\n",
            " 92%|█████████▏| 164/178 [00:09<00:00, 18.02it/s]\u001b[A\n",
            " 93%|█████████▎| 166/178 [00:09<00:00, 17.93it/s]\u001b[A\n",
            " 94%|█████████▍| 168/178 [00:09<00:00, 17.86it/s]\u001b[A\n",
            " 96%|█████████▌| 170/178 [00:09<00:00, 17.84it/s]\u001b[A\n",
            " 97%|█████████▋| 172/178 [00:09<00:00, 17.80it/s]\u001b[A\n",
            " 98%|█████████▊| 174/178 [00:09<00:00, 17.78it/s]\u001b[A\n",
            "100%|██████████| 178/178 [00:10<00:00, 17.75it/s]\n",
            " 71%|███████▏  | 1015/1422 [03:22<21:25,  3.16s/it]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            " 71%|███████▏  | 1016/1422 [03:22<15:16,  2.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 0.3177 Val acc: 0.9043 Val f1: 0.9043 AUC: 0.4914\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 1217/1422 [03:53<00:30,  6.80it/s]\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 2/178 [00:00<00:09, 18.89it/s]\u001b[A\n",
            "  2%|▏         | 4/178 [00:00<00:09, 18.49it/s]\u001b[A\n",
            "  3%|▎         | 6/178 [00:00<00:09, 18.41it/s]\u001b[A\n",
            "  4%|▍         | 8/178 [00:00<00:09, 18.08it/s]\u001b[A\n",
            "  6%|▌         | 10/178 [00:00<00:09, 18.07it/s]\u001b[A\n",
            "  7%|▋         | 12/178 [00:00<00:09, 18.26it/s]\u001b[A\n",
            "  8%|▊         | 14/178 [00:00<00:08, 18.37it/s]\u001b[A\n",
            "  9%|▉         | 16/178 [00:00<00:08, 18.20it/s]\u001b[A\n",
            " 10%|█         | 18/178 [00:00<00:08, 18.22it/s]\u001b[A\n",
            " 11%|█         | 20/178 [00:01<00:08, 18.32it/s]\u001b[A\n",
            " 12%|█▏        | 22/178 [00:01<00:08, 18.35it/s]\u001b[A\n",
            " 13%|█▎        | 24/178 [00:01<00:08, 18.20it/s]\u001b[A\n",
            " 15%|█▍        | 26/178 [00:01<00:08, 18.07it/s]\u001b[A\n",
            " 16%|█▌        | 28/178 [00:01<00:08, 18.08it/s]\u001b[A\n",
            " 17%|█▋        | 30/178 [00:01<00:08, 18.04it/s]\u001b[A\n",
            " 18%|█▊        | 32/178 [00:01<00:08, 18.11it/s]\u001b[A\n",
            " 19%|█▉        | 34/178 [00:01<00:07, 18.16it/s]\u001b[A\n",
            " 20%|██        | 36/178 [00:01<00:07, 18.23it/s]\u001b[A\n",
            " 21%|██▏       | 38/178 [00:02<00:07, 18.05it/s]\u001b[A\n",
            " 22%|██▏       | 40/178 [00:02<00:07, 18.14it/s]\u001b[A\n",
            " 24%|██▎       | 42/178 [00:02<00:07, 18.12it/s]\u001b[A\n",
            " 25%|██▍       | 44/178 [00:02<00:07, 18.14it/s]\u001b[A\n",
            " 26%|██▌       | 46/178 [00:02<00:07, 18.08it/s]\u001b[A\n",
            " 27%|██▋       | 48/178 [00:02<00:07, 18.13it/s]\u001b[A\n",
            " 28%|██▊       | 50/178 [00:02<00:07, 18.14it/s]\u001b[A\n",
            " 29%|██▉       | 52/178 [00:02<00:06, 18.11it/s]\u001b[A\n",
            " 30%|███       | 54/178 [00:02<00:06, 18.09it/s]\u001b[A\n",
            " 31%|███▏      | 56/178 [00:03<00:06, 18.23it/s]\u001b[A\n",
            " 33%|███▎      | 58/178 [00:03<00:06, 18.21it/s]\u001b[A\n",
            " 34%|███▎      | 60/178 [00:03<00:06, 18.33it/s]\u001b[A\n",
            " 35%|███▍      | 62/178 [00:03<00:06, 18.26it/s]\u001b[A\n",
            " 36%|███▌      | 64/178 [00:03<00:06, 18.30it/s]\u001b[A\n",
            " 37%|███▋      | 66/178 [00:03<00:06, 18.21it/s]\u001b[A\n",
            " 38%|███▊      | 68/178 [00:03<00:06, 18.14it/s]\u001b[A\n",
            " 39%|███▉      | 70/178 [00:03<00:05, 18.08it/s]\u001b[A\n",
            " 40%|████      | 72/178 [00:03<00:05, 18.15it/s]\u001b[A\n",
            " 42%|████▏     | 74/178 [00:04<00:05, 18.23it/s]\u001b[A\n",
            " 43%|████▎     | 76/178 [00:04<00:05, 18.23it/s]\u001b[A\n",
            " 44%|████▍     | 78/178 [00:04<00:05, 18.30it/s]\u001b[A\n",
            " 45%|████▍     | 80/178 [00:04<00:05, 18.26it/s]\u001b[A\n",
            " 46%|████▌     | 82/178 [00:04<00:05, 18.23it/s]\u001b[A\n",
            " 47%|████▋     | 84/178 [00:04<00:05, 18.21it/s]\u001b[A\n",
            " 48%|████▊     | 86/178 [00:04<00:05, 18.28it/s]\u001b[A\n",
            " 49%|████▉     | 88/178 [00:04<00:04, 18.30it/s]\u001b[A\n",
            " 51%|█████     | 90/178 [00:04<00:04, 18.19it/s]\u001b[A\n",
            " 52%|█████▏    | 92/178 [00:05<00:04, 18.23it/s]\u001b[A\n",
            " 53%|█████▎    | 94/178 [00:05<00:04, 18.21it/s]\u001b[A\n",
            " 54%|█████▍    | 96/178 [00:05<00:04, 18.22it/s]\u001b[A\n",
            " 55%|█████▌    | 98/178 [00:05<00:04, 18.22it/s]\u001b[A\n",
            " 56%|█████▌    | 100/178 [00:05<00:04, 18.21it/s]\u001b[A\n",
            " 57%|█████▋    | 102/178 [00:05<00:04, 18.29it/s]\u001b[A\n",
            " 58%|█████▊    | 104/178 [00:05<00:04, 18.26it/s]\u001b[A\n",
            " 60%|█████▉    | 106/178 [00:05<00:03, 18.29it/s]\u001b[A\n",
            " 61%|██████    | 108/178 [00:05<00:03, 18.19it/s]\u001b[A\n",
            " 62%|██████▏   | 110/178 [00:06<00:03, 18.26it/s]\u001b[A\n",
            " 63%|██████▎   | 112/178 [00:06<00:03, 18.21it/s]\u001b[A\n",
            " 64%|██████▍   | 114/178 [00:06<00:03, 18.19it/s]\u001b[A\n",
            " 65%|██████▌   | 116/178 [00:06<00:03, 18.22it/s]\u001b[A\n",
            " 66%|██████▋   | 118/178 [00:06<00:03, 18.01it/s]\u001b[A\n",
            " 67%|██████▋   | 120/178 [00:06<00:03, 18.03it/s]\u001b[A\n",
            " 69%|██████▊   | 122/178 [00:06<00:03, 17.98it/s]\u001b[A\n",
            " 70%|██████▉   | 124/178 [00:06<00:02, 18.03it/s]\u001b[A\n",
            " 71%|███████   | 126/178 [00:06<00:02, 17.89it/s]\u001b[A\n",
            " 72%|███████▏  | 128/178 [00:07<00:02, 17.81it/s]\u001b[A\n",
            " 73%|███████▎  | 130/178 [00:07<00:02, 17.89it/s]\u001b[A\n",
            " 74%|███████▍  | 132/178 [00:07<00:02, 17.96it/s]\u001b[A\n",
            " 75%|███████▌  | 134/178 [00:07<00:02, 18.03it/s]\u001b[A\n",
            " 76%|███████▋  | 136/178 [00:07<00:02, 17.92it/s]\u001b[A\n",
            " 78%|███████▊  | 138/178 [00:07<00:02, 17.94it/s]\u001b[A\n",
            " 79%|███████▊  | 140/178 [00:07<00:02, 17.83it/s]\u001b[A\n",
            " 80%|███████▉  | 142/178 [00:07<00:02, 17.80it/s]\u001b[A\n",
            " 81%|████████  | 144/178 [00:07<00:01, 17.86it/s]\u001b[A\n",
            " 82%|████████▏ | 146/178 [00:08<00:01, 17.99it/s]\u001b[A\n",
            " 83%|████████▎ | 148/178 [00:08<00:01, 17.87it/s]\u001b[A\n",
            " 84%|████████▍ | 150/178 [00:08<00:01, 17.93it/s]\u001b[A\n",
            " 85%|████████▌ | 152/178 [00:08<00:01, 18.08it/s]\u001b[A\n",
            " 87%|████████▋ | 154/178 [00:08<00:01, 18.21it/s]\u001b[A\n",
            " 88%|████████▊ | 156/178 [00:08<00:01, 18.25it/s]\u001b[A\n",
            " 89%|████████▉ | 158/178 [00:08<00:01, 18.11it/s]\u001b[A\n",
            " 90%|████████▉ | 160/178 [00:08<00:00, 18.07it/s]\u001b[A\n",
            " 91%|█████████ | 162/178 [00:08<00:00, 18.14it/s]\u001b[A\n",
            " 92%|█████████▏| 164/178 [00:09<00:00, 18.24it/s]\u001b[A\n",
            " 93%|█████████▎| 166/178 [00:09<00:00, 18.07it/s]\u001b[A\n",
            " 94%|█████████▍| 168/178 [00:09<00:00, 18.12it/s]\u001b[A\n",
            " 96%|█████████▌| 170/178 [00:09<00:00, 18.18it/s]\u001b[A\n",
            " 97%|█████████▋| 172/178 [00:09<00:00, 18.09it/s]\u001b[A\n",
            " 98%|█████████▊| 174/178 [00:09<00:00, 18.09it/s]\u001b[A\n",
            "100%|██████████| 178/178 [00:09<00:00, 18.16it/s]\n",
            " 86%|████████▌ | 1218/1422 [04:03<10:30,  3.09s/it]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            " 86%|████████▌ | 1219/1422 [04:03<07:28,  2.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 0.3179 Val acc: 0.9043 Val f1: 0.9043 AUC: 0.5284\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 1420/1422 [04:33<00:00,  5.76it/s]\n",
            "  0%|          | 0/178 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 2/178 [00:00<00:09, 18.27it/s]\u001b[A\n",
            "  2%|▏         | 4/178 [00:00<00:09, 18.22it/s]\u001b[A\n",
            "  3%|▎         | 6/178 [00:00<00:09, 18.30it/s]\u001b[A\n",
            "  4%|▍         | 8/178 [00:00<00:09, 18.32it/s]\u001b[A\n",
            "  6%|▌         | 10/178 [00:00<00:09, 18.07it/s]\u001b[A\n",
            "  7%|▋         | 12/178 [00:00<00:09, 18.12it/s]\u001b[A\n",
            "  8%|▊         | 14/178 [00:00<00:09, 18.15it/s]\u001b[A\n",
            "  9%|▉         | 16/178 [00:00<00:09, 17.90it/s]\u001b[A\n",
            " 10%|█         | 18/178 [00:00<00:08, 17.87it/s]\u001b[A\n",
            " 11%|█         | 20/178 [00:01<00:08, 17.95it/s]\u001b[A\n",
            " 12%|█▏        | 22/178 [00:01<00:08, 18.00it/s]\u001b[A\n",
            " 13%|█▎        | 24/178 [00:01<00:08, 18.09it/s]\u001b[A\n",
            " 15%|█▍        | 26/178 [00:01<00:08, 18.24it/s]\u001b[A\n",
            " 16%|█▌        | 28/178 [00:01<00:08, 18.33it/s]\u001b[A\n",
            " 17%|█▋        | 30/178 [00:01<00:08, 18.35it/s]\u001b[A\n",
            " 18%|█▊        | 32/178 [00:01<00:07, 18.32it/s]\u001b[A\n",
            " 19%|█▉        | 34/178 [00:01<00:07, 18.36it/s]\u001b[A\n",
            " 20%|██        | 36/178 [00:01<00:07, 18.26it/s]\u001b[A\n",
            " 21%|██▏       | 38/178 [00:02<00:07, 18.16it/s]\u001b[A\n",
            " 22%|██▏       | 40/178 [00:02<00:07, 18.00it/s]\u001b[A\n",
            " 24%|██▎       | 42/178 [00:02<00:07, 17.75it/s]\u001b[A\n",
            " 25%|██▍       | 44/178 [00:02<00:07, 17.92it/s]\u001b[A\n",
            " 26%|██▌       | 46/178 [00:02<00:07, 18.00it/s]\u001b[A\n",
            " 27%|██▋       | 48/178 [00:02<00:07, 18.09it/s]\u001b[A\n",
            " 28%|██▊       | 50/178 [00:02<00:07, 18.04it/s]\u001b[A\n",
            " 29%|██▉       | 52/178 [00:02<00:06, 18.08it/s]\u001b[A\n",
            " 30%|███       | 54/178 [00:02<00:06, 18.04it/s]\u001b[A\n",
            " 31%|███▏      | 56/178 [00:03<00:06, 18.22it/s]\u001b[A\n",
            " 33%|███▎      | 58/178 [00:03<00:06, 18.15it/s]\u001b[A\n",
            " 34%|███▎      | 60/178 [00:03<00:06, 18.21it/s]\u001b[A\n",
            " 35%|███▍      | 62/178 [00:03<00:06, 18.00it/s]\u001b[A\n",
            " 36%|███▌      | 64/178 [00:03<00:06, 17.93it/s]\u001b[A\n",
            " 37%|███▋      | 66/178 [00:03<00:06, 17.95it/s]\u001b[A\n",
            " 38%|███▊      | 68/178 [00:03<00:06, 18.04it/s]\u001b[A\n",
            " 39%|███▉      | 70/178 [00:03<00:05, 18.09it/s]\u001b[A\n",
            " 40%|████      | 72/178 [00:03<00:05, 18.14it/s]\u001b[A\n",
            " 42%|████▏     | 74/178 [00:04<00:05, 18.11it/s]\u001b[A\n",
            " 43%|████▎     | 76/178 [00:04<00:05, 18.17it/s]\u001b[A\n",
            " 44%|████▍     | 78/178 [00:04<00:05, 18.08it/s]\u001b[A\n",
            " 45%|████▍     | 80/178 [00:04<00:05, 18.09it/s]\u001b[A\n",
            " 46%|████▌     | 82/178 [00:04<00:05, 18.11it/s]\u001b[A\n",
            " 47%|████▋     | 84/178 [00:04<00:05, 18.21it/s]\u001b[A\n",
            " 48%|████▊     | 86/178 [00:04<00:05, 18.26it/s]\u001b[A\n",
            " 49%|████▉     | 88/178 [00:04<00:04, 18.25it/s]\u001b[A\n",
            " 51%|█████     | 90/178 [00:04<00:04, 18.23it/s]\u001b[A\n",
            " 52%|█████▏    | 92/178 [00:05<00:04, 18.28it/s]\u001b[A\n",
            " 53%|█████▎    | 94/178 [00:05<00:04, 18.25it/s]\u001b[A\n",
            " 54%|█████▍    | 96/178 [00:05<00:04, 18.27it/s]\u001b[A\n",
            " 55%|█████▌    | 98/178 [00:05<00:04, 18.28it/s]\u001b[A\n",
            " 56%|█████▌    | 100/178 [00:05<00:04, 18.23it/s]\u001b[A\n",
            " 57%|█████▋    | 102/178 [00:05<00:04, 18.27it/s]\u001b[A\n",
            " 58%|█████▊    | 104/178 [00:05<00:04, 18.36it/s]\u001b[A\n",
            " 60%|█████▉    | 106/178 [00:05<00:03, 18.21it/s]\u001b[A\n",
            " 61%|██████    | 108/178 [00:05<00:03, 18.24it/s]\u001b[A\n",
            " 62%|██████▏   | 110/178 [00:06<00:03, 18.33it/s]\u001b[A\n",
            " 63%|██████▎   | 112/178 [00:06<00:03, 18.14it/s]\u001b[A\n",
            " 64%|██████▍   | 114/178 [00:06<00:03, 18.26it/s]\u001b[A\n",
            " 65%|██████▌   | 116/178 [00:06<00:03, 18.26it/s]\u001b[A\n",
            " 66%|██████▋   | 118/178 [00:06<00:03, 18.26it/s]\u001b[A\n",
            " 67%|██████▋   | 120/178 [00:06<00:03, 18.23it/s]\u001b[A\n",
            " 69%|██████▊   | 122/178 [00:06<00:03, 18.04it/s]\u001b[A\n",
            " 70%|██████▉   | 124/178 [00:06<00:02, 18.07it/s]\u001b[A\n",
            " 71%|███████   | 126/178 [00:06<00:02, 18.18it/s]\u001b[A\n",
            " 72%|███████▏  | 128/178 [00:07<00:02, 18.26it/s]\u001b[A\n",
            " 73%|███████▎  | 130/178 [00:07<00:02, 18.27it/s]\u001b[A\n",
            " 74%|███████▍  | 132/178 [00:07<00:02, 18.19it/s]\u001b[A\n",
            " 75%|███████▌  | 134/178 [00:07<00:02, 18.08it/s]\u001b[A\n",
            " 76%|███████▋  | 136/178 [00:07<00:02, 18.17it/s]\u001b[A\n",
            " 78%|███████▊  | 138/178 [00:07<00:02, 18.05it/s]\u001b[A\n",
            " 79%|███████▊  | 140/178 [00:07<00:02, 18.16it/s]\u001b[A\n",
            " 80%|███████▉  | 142/178 [00:07<00:01, 18.28it/s]\u001b[A\n",
            " 81%|████████  | 144/178 [00:07<00:01, 18.26it/s]\u001b[A\n",
            " 82%|████████▏ | 146/178 [00:08<00:01, 18.23it/s]\u001b[A\n",
            " 83%|████████▎ | 148/178 [00:08<00:01, 18.29it/s]\u001b[A\n",
            " 84%|████████▍ | 150/178 [00:08<00:01, 18.35it/s]\u001b[A\n",
            " 85%|████████▌ | 152/178 [00:08<00:01, 18.35it/s]\u001b[A\n",
            " 87%|████████▋ | 154/178 [00:08<00:01, 18.24it/s]\u001b[A\n",
            " 88%|████████▊ | 156/178 [00:08<00:01, 18.27it/s]\u001b[A\n",
            " 89%|████████▉ | 158/178 [00:08<00:01, 18.11it/s]\u001b[A\n",
            " 90%|████████▉ | 160/178 [00:08<00:00, 18.02it/s]\u001b[A\n",
            " 91%|█████████ | 162/178 [00:08<00:00, 17.98it/s]\u001b[A\n",
            " 92%|█████████▏| 164/178 [00:09<00:00, 18.05it/s]\u001b[A\n",
            " 93%|█████████▎| 166/178 [00:09<00:00, 17.95it/s]\u001b[A\n",
            " 94%|█████████▍| 168/178 [00:09<00:00, 17.93it/s]\u001b[A\n",
            " 96%|█████████▌| 170/178 [00:09<00:00, 17.95it/s]\u001b[A\n",
            " 97%|█████████▋| 172/178 [00:09<00:00, 18.04it/s]\u001b[A\n",
            " 98%|█████████▊| 174/178 [00:09<00:00, 18.01it/s]\u001b[A\n",
            "100%|██████████| 178/178 [00:09<00:00, 18.17it/s]\n",
            "100%|█████████▉| 1421/1422 [04:43<00:03,  3.11s/it]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100%|██████████| 1422/1422 [04:43<00:00,  5.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 0.3167 Val acc: 0.9043 Val f1: 0.9043 AUC: 0.5265\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "optimizer_step = 0\n",
        "gradient_accumulation_steps=20\n",
        "max_grad_norm=1\n",
        "global_step = 0\n",
        "train_step = 0\n",
        "tr_loss, logging_loss = 0.0, 0.0\n",
        "best_valid_f1 = 0.73\n",
        "global_steps_list = []\n",
        "train_loss_list = []\n",
        "val_loss_list = []\n",
        "val_acc_list = []\n",
        "val_auc_list = []\n",
        "eval_every = len(training_loader) // 7\n",
        "running_loss = 0\n",
        "file_path='/content/drive/MyDrive/RajWorkspace/mytestresults'\n",
        "\n",
        "model.zero_grad()\n",
        "\n",
        "for i in range(num_train_epochs):\n",
        "    print(\"Epoch\", i+1, f\"from {num_train_epochs}\")\n",
        "    whole_y_pred=np.array([])\n",
        "    whole_y_t=np.array([])\n",
        "    for step, batch in enumerate(tqdm(training_loader)):\n",
        "        model.train()\n",
        "        ids = batch['ids'].to(device, dtype = torch.long)\n",
        "        mask = batch['mask'].to(device, dtype = torch.long)\n",
        "        token_type_ids = batch['token_type_ids'].to(device, dtype = torch.long)\n",
        "        targets = batch['targets']\n",
        "        targets=targets.view(targets.size(0),-1)\n",
        "        labels=targets.to(device, dtype = torch.float32)\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "        logits = outputs   # model outputs are always tuple in transformers (see doc)\n",
        "        loss = criterion(logits, labels) \n",
        "        \n",
        "        if gradient_accumulation_steps > 1:\n",
        "            loss = loss / gradient_accumulation_steps\n",
        "            \n",
        "        loss.backward()\n",
        "        \n",
        "        tr_loss += loss.item()\n",
        "        running_loss += loss.item()\n",
        "        global_step += 1\n",
        "        \n",
        "        if (step + 1) % gradient_accumulation_steps == 0:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "            optimizer.step()\n",
        "            scheduler.step()  # Update learning rate schedule         \n",
        "            \n",
        "            optimizer_step += 1\n",
        "            optimizer.zero_grad()   \n",
        "                        \n",
        "        if (step + 1) % eval_every == 0:\n",
        "            \n",
        "            average_train_loss = running_loss / eval_every\n",
        "            train_loss_list.append(average_train_loss)\n",
        "            global_steps_list.append(global_step)\n",
        "            running_loss = 0.0  \n",
        "            \n",
        "            val_result = evaluate(model,tqdm, tokenizer, criterion, testing_loader)\n",
        "            \n",
        "            # checkpoint\n",
        "            if val_result['micro_f1'] > best_valid_f1:\n",
        "                best_valid_auc = val_result['AUC']\n",
        "                val_loss = val_result['loss']\n",
        "                val_acc = val_result['accuracy']\n",
        "                best_valid_f1=val_result['micro_f1']\n",
        "                model_path = f'{file_path}/model-auc{best_valid_auc:.3f}-loss{val_loss:.3f}-acc{val_acc:.3f}.pt'\n",
        "                print(f\"AUC improved, so saving this model\")  \n",
        "                save_checkpoint(model_path, model, val_result['loss'])              \n",
        "            \n",
        "            print(  \"Val loss:\", f\"{val_result['loss']:.4f}\",\n",
        "                    \"Val acc:\", f\"{val_result['accuracy']:.4f}\",\n",
        "                    \"Val f1:\", f\"{val_result['micro_f1']:.4f}\",\n",
        "                    \"AUC:\", f\"{val_result['AUC']:.4f}\")   \n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53d5QnnNJj68"
      },
      "outputs": [],
      "source": [
        "def final_prediction(model, dataloader): \n",
        "        preds = None\n",
        "        proba = None\n",
        "        all_ids = None\n",
        "        for batch in tqdm(dataloader):\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                ids = batch['ids'].to(device, dtype = torch.long)\n",
        "                mask = batch['mask'].to(device, dtype = torch.long)\n",
        "                token_type_ids = batch['token_type_ids'].to(device, dtype = torch.long)\n",
        "                targets = batch['targets']\n",
        "                targets=targets.view(targets.size(0),-1)\n",
        "                labels=targets.to(device, dtype = torch.float32)\n",
        "                outputs = model(ids, mask, token_type_ids)\n",
        "                logits = outputs\n",
        "            if preds is None:\n",
        "                # all_ids = ids.detach().cpu().numpy()\n",
        "                preds = torch.sigmoid(logits).detach().cpu().numpy() > 0.5\n",
        "                proba = torch.sigmoid(logits).detach().cpu().numpy()            \n",
        "            else:  \n",
        "                # all_ids = np.append(all_ids, ids.detach().cpu().numpy(), axis=0)\n",
        "                preds = np.append(preds, torch.sigmoid(logits).detach().cpu().numpy() > 0.5, axis=0)\n",
        "                proba = np.append(proba, torch.sigmoid(logits).detach().cpu().numpy(), axis=0)\n",
        "\n",
        "        result = {\n",
        "            # \"ids\": all_ids,\n",
        "            \"preds\": preds,\n",
        "            \"probs\": proba,\n",
        "        }\n",
        "\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8yfWcb6DrGJ",
        "outputId": "e924efce-b90b-46f1-af10-791a29578a3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded from <== /content/drive/MyDrive/RajWorkspace/mytestresults/model-auc0.913-loss0.186-acc0.935.pt\n"
          ]
        }
      ],
      "source": [
        "path='/content/drive/MyDrive/RajWorkspace/mytestresults/model-auc0.913-loss0.186-acc0.935.pt'\n",
        "bestmodel_final=load_checkpoint(path,model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ARAHFMT51f3"
      },
      "outputs": [],
      "source": [
        "eval_params = {'batch_size': 1,\n",
        "                'shuffle': False,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "eval_loader = DataLoader(testing_set, **eval_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhjd_d2-J8L8",
        "outputId": "97d25c53-5e23-4d86-cc41-2a7fbe7565d9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/2841 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100%|██████████| 2841/2841 [00:49<00:00, 57.96it/s]\n"
          ]
        }
      ],
      "source": [
        "results_final=final_prediction(model, eval_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPaU9egjKC6S"
      },
      "outputs": [],
      "source": [
        "resf=pd.DataFrame(results_final['preds'])\n",
        "resf.columns=['label']\n",
        "resf.loc[resf['label']== True, \"label\"] = 1\n",
        "resf.loc[resf['label']== False, \"label\"] = 0\n",
        "resf['label']=resf['label'].astype(str).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5wnochqKMU9",
        "outputId": "58695b50-1e72-4f08-bd02-f0a5f105cf43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95      2569\n",
            "           1       0.00      0.00      0.00       272\n",
            "\n",
            "    accuracy                           0.90      2841\n",
            "   macro avg       0.45      0.50      0.47      2841\n",
            "weighted avg       0.82      0.90      0.86      2841\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(test.label, resf.label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3bKsHatKQmz",
        "outputId": "e8899cb9-9d9f-46bb-8849-e4016bb261b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "label\n",
              "0        2619\n",
              "1         222\n",
              "dtype: int64"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "resf.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYLZrk2_PzVq"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "HopeEDIFinal.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}